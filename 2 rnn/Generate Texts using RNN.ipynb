{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Texts using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "import collections\n",
    "import numpy as np\n",
    "import codecs\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_PATH = './data/诛仙.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function for reading data as chars\n",
    "def read_chars(path):\n",
    "    with codecs.open(path, 'r', encoding='utf-8') as f:\n",
    "        chars = f.read()\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 200 chars are : ['\\r\\n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '\\r\\n', '\\r\\n', '第一卷', ' ', '\\r\\n', '\\r\\n', '\\r\\n', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '\\r\\n', '\\r\\n', '序章', ' ', '\\r\\n', '\\r\\n', ' ', ' ', ' ', ' ', '诛仙', '_', '序章', '\\r\\n', '\\r\\n', ' ', ' ', ' ', ' ', '时间', '：', '不明', '，', '应该', '在', '很早', '、', '很早以前', '。', '\\r\\n', '\\r\\n', ' ', ' ', ' ', ' ', '地点', '：', '神州', '浩土', '。', '\\r\\n', '\\r\\n', ' ', ' ', ' ', ' ', '天地', '不', '仁', '，', '以', '万物', '为', '诌', '狗', '！', '\\r\\n', '\\r\\n', ' ', ' ', ' ', ' ', '这', '世间', '本是', '没有', '什么', '神仙', '的', '，', '但', '自', '太古', '以来', '，', '人类', '眼见', '周遭', '世界', '，', '诸般', '奇异', '之', '事', '，', '电闪雷鸣', '，', '狂风暴雨', '，', '又', '有', '天灾', '*', '*', '，', '伤亡', '无数', '，', '哀鸿遍野', '，', '决非', '人力', '所能', '为', '，', '所', '能', '抵挡', '。', '遂', '以为', '九天', '之上', '，', '有', '诸般', '神灵', '，', '九幽', '之下', '，', '亦', '是', '阴魂', '归处', '，', '阎罗', '殿堂', '。', '\\r\\n', '\\r\\n', ' ', ' ', ' ', ' ', '于是', '神仙', '之', '说', '，', '流传于世', '。', '无数', '人类', '子民', '，', '诚心', '叩拜', '，', '向着', '自己', '臆想', '创造', '出', '的', '各种', '神明', '顶礼膜拜', '，', '祈福', '诉苦', '，', '香火', '鼎盛', '。', '\\r\\n', '\\r\\n', ' ']\n"
     ]
    }
   ],
   "source": [
    "chars = read_chars(FILE_PATH)\n",
    "chars = list(jieba.cut(chars, cut_all=False))\n",
    "print(\"First 200 chars are :\", chars[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据\n",
    "- 获得所有的character的词库\n",
    "- 对词库建立索引：从 char -> index, index -> char 的索引\n",
    "- 将从文本中读取的 char 数据生成索引的序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成数据集\n",
    "def generate_dataset(chars):\n",
    "\n",
    "    vocabulary = collections.Counter(chars).keys()                            # 出现的所有 char 的 vocabulary\n",
    "    dictionary = dict(zip(vocabulary,range(len(vocabulary))))                 # char -> index 的索引\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))    # index -> char 的索引\n",
    "    char_index = np.array(list(map(dictionary.get,chars)))                    # 读出来的文本的 index 序列\n",
    "    \n",
    "    return char_index, vocabulary, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  0  0  2  3  0  0  0  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  0  0  4  3  0  0  3  3  3  3  5  6  4  0  0  3  3  3\n",
      "  3  7  8  9 10 11 12 13 14 15 16  0  0  3  3  3  3 17  8 18 19 16  0  0  3\n",
      "  3  3  3 20 21 22 10 23 24 25 26 27 28  0  0  3  3  3  3 29 30 31 32 33 34\n",
      " 35 10 36 37 38 39 10 40 41 42 43 10 44 45 46 47 10 48 10 49 10 50 51 52 53\n",
      " 53 10 54 55 10 56 10 57 58 59 25 10 60 61 62 16 63 64 65 66 10 51 44 67 10\n",
      " 68 69 10 70 71 72 73 10 74 75 16  0  0  3  3  3  3 76 34 46 77 10 78 16 55\n",
      " 40 79 10 80 81 10 82 83 84 85 86 35 87 88 89 10 90 91 10 92 93 16  0  0  3]\n"
     ]
    }
   ],
   "source": [
    "# 生成一下数据集\n",
    "char_index, vocabulary, dictionary, reverse_dictionary = generate_dataset(chars)\n",
    "# 看一下数据长什么样子\n",
    "print(char_index[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "SEQ_LENGTH = 50\n",
    "CHAR_LENGTH = char_index.size\n",
    "VOCAB_SIZE = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将 char index 切分成batch\n",
    "index = 0\n",
    "shift_index = BATCH_SIZE * SEQ_LENGTH\n",
    "\n",
    "# Return a batch of x_input, y_output\n",
    "def generate_batch(char_index):\n",
    "    \n",
    "    global index\n",
    "    \n",
    "    if index + shift_index + 1 >= CHAR_LENGTH:\n",
    "        index = 0\n",
    "    \n",
    "    # y_batch = x_batch -> 1 (shift right 1 position)\n",
    "    x_batch = char_index[index     : index + shift_index    ].reshape(BATCH_SIZE, -1)\n",
    "    y_batch = char_index[index + 1 : index + shift_index + 1].reshape(BATCH_SIZE, -1)\n",
    "    \n",
    "    index += shift_index\n",
    "    \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Input  Sequence Example : [0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 3 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 4 3 0\n",
      " 0 3 3 3 3 5 6 4 0 0 3 3 3]\n",
      "Y Output Sequence Example : [1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 3 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 4 3 0 0\n",
      " 3 3 3 3 5 6 4 0 0 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at how the batch is generated\n",
    "x_batch, y_batch = generate_batch(char_index)\n",
    "\n",
    "print('X Input  Sequence Example :', x_batch[0])\n",
    "print('Y Output Sequence Example :', y_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 定义 RNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, training=True):\n",
    "        \n",
    "        # 在每次初始化 model 的时候，先将 graph 里面的所有变量清空\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        \"\"\"\n",
    "            Parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        # 训练 batch 的大小 和 sequence 的长度\n",
    "        self.batch_size = 50\n",
    "        self.seq_length = 50\n",
    "        \n",
    "        # 如果不是在训练过程中，则都为1\n",
    "        if not training:\n",
    "            self.batch_size = 1\n",
    "            #self.seq_length = 1\n",
    "        \n",
    "        self.rnn_size = 128                      # RNN Cell 中 hidden layer 的 unit 的个数\n",
    "        self.num_layers = 2                      # RNN 中有多少层\n",
    "        self.input_keep_prob = 1.0               # 输入被保持的概率，用于 dropout\n",
    "        self.output_keep_prob = 1.0              # 输出被保持的概率，用于 dropout\n",
    "        self.grad_clip = 5.0                     # gradient clipping，用于防止梯度爆炸\n",
    "        self.training = 1\n",
    "        \n",
    "        \"\"\"\n",
    "            Build Cell\n",
    "        \"\"\"\n",
    "        # 最基本的 RNN Cell\n",
    "        cell_fn = rnn.BasicRNNCell\n",
    "\n",
    "        cells = []\n",
    "        for _ in range(self.num_layers):\n",
    "            cell = cell_fn(self.rnn_size)\n",
    "            # dropout\n",
    "            if training and (self.input_keep_prob < 1.0 or self.output_keep_prob < 1.0):\n",
    "                cell = rnn.DropoutWrapper(cell, input_keep_prob=self.input_keep_prob,\n",
    "                                         output_keep_prob=self.output_keep_prob)\n",
    "            cells.append(cell)\n",
    "\n",
    "        # 根据有多少层，就将多少个 cell 组合成一个 MultiRNNCell\n",
    "        self.cell = cell = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "        # placeholder for input and output\n",
    "        self.input_data  = tf.placeholder(tf.int32, [self.batch_size, self.seq_length])\n",
    "        self.output_data = tf.placeholder(tf.int32, [self.batch_size, self.seq_length])\n",
    "        self.initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "        \n",
    "        # 因为根据 softmax 来进行计算损失函数和预测 char，所以这里需要定义 softmax 矩阵 和 softmax 偏差\n",
    "        # 这里的 softmax 是最后输出结果的层\n",
    "        # 输出为一个一维的 array，array的个数为 词库的大小，每个地方对应的是预测是该 char 的概率\n",
    "        with tf.variable_scope(\"rnnlm\"):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [self.rnn_size, VOCAB_SIZE])\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [VOCAB_SIZE])\n",
    "        \n",
    "        # 生成一个 词向量的lookup table\n",
    "        # 每个单词对应的词向量的维度为 RNN Cell 中的 Hidden 层的大小\n",
    "        # 这个 embedding 也是在 RNN 中需要被训练的值\n",
    "        # 它用来将每一个 input 的单词转成 对应的词向量\n",
    "        embedding = tf.get_variable(\"embedding\", [VOCAB_SIZE, self.rnn_size])\n",
    "        inputs = tf.nn.embedding_lookup(embedding, self.input_data)\n",
    "        if training and self.output_keep_prob:\n",
    "            inputs = tf.nn.dropout(inputs, self.output_keep_prob)\n",
    "\n",
    "        inputs = tf.split(inputs, self.seq_length, 1) # returns self.seq_length Tensor objects\n",
    "        inputs = [tf.squeeze(input_, [1]) for input_ in inputs] # squeeze the first dimension, got [B * embed_size] * self.seq_length Tensor objects\n",
    "        \n",
    "        \"\"\"\n",
    "        def loop(prev, _):\n",
    "            prev = tf.matmul(prev, softmax_w) + softmax_b\n",
    "            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))\n",
    "            return tf.nn.embedding_lookup(embedding, prev_symbol)\n",
    "        \"\"\"\n",
    "        \n",
    "        # run an rnn on the sequence\n",
    "        outputs, last_state = legacy_seq2seq.rnn_decoder(inputs, self.initial_state, cell, \n",
    "                                                         #loop_function=loop if not training else None, scope=\"rnnlm\")\n",
    "                                                         loop_function=None, scope=\"rnnlm\")\n",
    "        output = tf.reshape(tf.concat(outputs, 1), [-1, self.rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        \n",
    "        # loss over the whole sequence\n",
    "        loss = legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                                                      [tf.reshape(self.output_data, [-1])],\n",
    "                                                      [tf.ones([self.batch_size * self.seq_length])])\n",
    "        with tf.name_scope(\"cost\"):\n",
    "            self.cost = tf.reduce_sum(loss) / self.batch_size / self.seq_length\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        # gradient clipping on trainable variables\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), self.grad_clip)\n",
    "\n",
    "        # optimizer and train\n",
    "        with tf.name_scope(\"optimizer\"):\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    def sample(self, sess, chars, dictionary, reverse_dictionary, num, prime):\n",
    "        \n",
    "        words = list(jieba.cut(prime, cut_all=False))\n",
    "        assert len(words) >= 50\n",
    "        \n",
    "        state = sess.run(self.cell.zero_state(1, tf.float32))\n",
    "        \n",
    "        chars = words[-51:-1]\n",
    "        x = np.array( [np.array([dictionary[char] for char in chars])])\n",
    "        feed = {self.input_data: x, self.initial_state: state}\n",
    "        [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return (int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "        ret = ''\n",
    "        for n in range(num):\n",
    "            x = np.array( [np.array([dictionary[char] for char in chars])])\n",
    "            feed = {self.input_data: x, self.initial_state: state}\n",
    "            [p, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = p[0]\n",
    "            sample = weighted_pick(p)\n",
    "            pred = reverse_dictionary[sample]\n",
    "            ret += pred\n",
    "            chars.append( pred )\n",
    "            chars = chars[-51:-1]\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 训练 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/model.ckpt-100\n",
      "Extract of training data : [492] [12]\n",
      "0/16406, train loss is 10.545, state is -0.0037854614201933146, time/batch=-5.354\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [505] [1177]\n",
      "1/16406, train loss is 10.545, state is -0.007012973073869944, time/batch=-4.366\n",
      "Extract of training data : [4853] [16]\n",
      "2/16406, train loss is 10.545, state is -0.009391740895807743, time/batch=-4.207\n",
      "Extract of training data : [46] [6974]\n",
      "3/16406, train loss is 10.545, state is -0.004563589580357075, time/batch=-4.310\n",
      "Extract of training data : [3328] [6399]\n",
      "4/16406, train loss is 10.545, state is 0.0022490646224468946, time/batch=-4.234\n",
      "Extract of training data : [3] [910]\n",
      "5/16406, train loss is 10.546, state is 0.012748200446367264, time/batch=-4.191\n",
      "Extract of training data : [699] [16]\n",
      "6/16406, train loss is 10.546, state is 0.00026419467758387327, time/batch=-4.297\n",
      "Extract of training data : [3758] [832]\n",
      "7/16406, train loss is 10.546, state is -0.013547354377806187, time/batch=-4.225\n",
      "Extract of training data : [10] [1489]\n",
      "8/16406, train loss is 10.545, state is -0.015497450716793537, time/batch=-4.206\n",
      "Extract of training data : [105] [371]\n",
      "9/16406, train loss is 10.545, state is -0.004773005843162537, time/batch=-4.281\n",
      "Extract of training data : [1167] [873]\n",
      "10/16406, train loss is 10.546, state is 0.004716816358268261, time/batch=-4.191\n",
      "Extract of training data : [910] [1803]\n",
      "11/16406, train loss is 10.545, state is -0.005001395475119352, time/batch=-4.217\n",
      "Extract of training data : [1021] [811]\n",
      "12/16406, train loss is 10.546, state is -0.003044955665245652, time/batch=-4.204\n",
      "Extract of training data : [0] [0]\n",
      "13/16406, train loss is 10.546, state is -0.01023157499730587, time/batch=-4.160\n",
      "Extract of training data : [280] [0]\n",
      "14/16406, train loss is 10.546, state is 0.010974030941724777, time/batch=-4.248\n",
      "Extract of training data : [16725] [14224]\n",
      "15/16406, train loss is 10.546, state is -0.010874971747398376, time/batch=-4.222\n",
      "Extract of training data : [284] [285]\n",
      "16/16406, train loss is 10.546, state is 0.008965777233242989, time/batch=-4.208\n",
      "Extract of training data : [0] [0]\n",
      "17/16406, train loss is 10.546, state is 2.3469094230677e-05, time/batch=-4.292\n",
      "Extract of training data : [11071] [35]\n",
      "18/16406, train loss is 10.546, state is -0.010406835936009884, time/batch=-4.301\n",
      "Extract of training data : [10] [17100]\n",
      "19/16406, train loss is 10.545, state is 0.016072988510131836, time/batch=-4.198\n",
      "Extract of training data : [10] [6402]\n",
      "20/16406, train loss is 10.545, state is -0.00045990737271495163, time/batch=-4.207\n",
      "Extract of training data : [14342] [17345]\n",
      "21/16406, train loss is 10.546, state is -0.006543128751218319, time/batch=-4.200\n",
      "Extract of training data : [17464] [559]\n",
      "22/16406, train loss is 10.545, state is -0.001895334804430604, time/batch=-4.169\n",
      "Extract of training data : [3516] [35]\n",
      "23/16406, train loss is 10.545, state is -0.023857660591602325, time/batch=-4.230\n",
      "Extract of training data : [910] [378]\n",
      "24/16406, train loss is 10.545, state is -0.008300624787807465, time/batch=-4.197\n",
      "Extract of training data : [3285] [1077]\n",
      "25/16406, train loss is 10.546, state is -0.016262182965874672, time/batch=-4.286\n",
      "Extract of training data : [559] [3105]\n",
      "26/16406, train loss is 10.546, state is -0.0033406305592507124, time/batch=-4.600\n",
      "Extract of training data : [10] [143]\n",
      "27/16406, train loss is 10.545, state is 0.004835234489291906, time/batch=-4.630\n",
      "Extract of training data : [3] [3]\n",
      "28/16406, train loss is 10.546, state is 0.006190972402691841, time/batch=-4.856\n",
      "Extract of training data : [1188] [12110]\n",
      "29/16406, train loss is 10.546, state is 0.005486587528139353, time/batch=-4.645\n",
      "Extract of training data : [16451] [164]\n",
      "30/16406, train loss is 10.545, state is -0.0035417473409324884, time/batch=-4.896\n",
      "Extract of training data : [3] [3]\n",
      "31/16406, train loss is 10.545, state is -0.003438139334321022, time/batch=-5.461\n",
      "Extract of training data : [0] [3]\n",
      "32/16406, train loss is 10.546, state is 0.004719607997685671, time/batch=-5.531\n",
      "Extract of training data : [3055] [10]\n",
      "33/16406, train loss is 10.546, state is -0.004902885761111975, time/batch=-4.904\n",
      "Extract of training data : [3] [3]\n",
      "34/16406, train loss is 10.546, state is -0.02049667201936245, time/batch=-5.193\n",
      "Extract of training data : [13381] [10]\n",
      "35/16406, train loss is 10.546, state is -0.002196365501731634, time/batch=-4.638\n",
      "Extract of training data : [3] [3]\n",
      "36/16406, train loss is 10.546, state is 0.0001981871173484251, time/batch=-4.571\n",
      "Extract of training data : [436] [283]\n",
      "37/16406, train loss is 10.546, state is -0.0030327634885907173, time/batch=-4.716\n",
      "Extract of training data : [1137] [28]\n",
      "38/16406, train loss is 10.546, state is 0.0032442857045680285, time/batch=-4.886\n",
      "Extract of training data : [413] [2442]\n",
      "39/16406, train loss is 10.546, state is -0.008947995491325855, time/batch=-5.231\n",
      "Extract of training data : [11953] [17849]\n",
      "40/16406, train loss is 10.545, state is 0.0006916298298165202, time/batch=-5.195\n",
      "Extract of training data : [3] [3]\n",
      "41/16406, train loss is 10.546, state is -0.014774939976632595, time/batch=-4.910\n",
      "Extract of training data : [3] [3]\n",
      "42/16406, train loss is 10.546, state is -0.004779044538736343, time/batch=-5.016\n",
      "Extract of training data : [10] [3860]\n",
      "43/16406, train loss is 10.545, state is 0.006809432525187731, time/batch=-4.852\n",
      "Extract of training data : [146] [8]\n",
      "44/16406, train loss is 10.546, state is -0.01302236970514059, time/batch=-4.876\n",
      "Extract of training data : [4873] [2924]\n",
      "45/16406, train loss is 10.546, state is -0.0020442320965230465, time/batch=-4.755\n",
      "Extract of training data : [10] [2398]\n",
      "46/16406, train loss is 10.545, state is 0.00034398259595036507, time/batch=-4.746\n",
      "Extract of training data : [245] [10]\n",
      "47/16406, train loss is 10.545, state is 0.009527900256216526, time/batch=-5.055\n",
      "Extract of training data : [561] [4309]\n",
      "48/16406, train loss is 10.546, state is -0.00350311491638422, time/batch=-4.717\n",
      "Extract of training data : [14] [17716]\n",
      "49/16406, train loss is 10.545, state is 0.00011707328667398542, time/batch=-4.831\n",
      "Extract of training data : [413] [17114]\n",
      "50/16406, train loss is 10.545, state is 0.011752516962587833, time/batch=-4.779\n",
      "Extract of training data : [972] [883]\n",
      "51/16406, train loss is 10.546, state is -0.005672984290868044, time/batch=-4.785\n",
      "Extract of training data : [1180] [35]\n",
      "52/16406, train loss is 10.545, state is 0.006937530357390642, time/batch=-4.789\n",
      "Extract of training data : [0] [0]\n",
      "53/16406, train loss is 10.545, state is 0.0059567950665950775, time/batch=-5.085\n",
      "Extract of training data : [3] [3]\n",
      "54/16406, train loss is 10.546, state is -0.008096210658550262, time/batch=-4.867\n",
      "Extract of training data : [6982] [688]\n",
      "55/16406, train loss is 10.546, state is -0.003960460424423218, time/batch=-5.076\n",
      "Extract of training data : [1185] [13445]\n",
      "56/16406, train loss is 10.546, state is 0.003403632901608944, time/batch=-5.118\n",
      "Extract of training data : [10] [753]\n",
      "57/16406, train loss is 10.545, state is 0.0013019901234656572, time/batch=-5.238\n",
      "Extract of training data : [533] [2221]\n",
      "58/16406, train loss is 10.546, state is 0.017430976033210754, time/batch=-5.028\n",
      "Extract of training data : [3] [3]\n",
      "59/16406, train loss is 10.546, state is 0.0054548573680222034, time/batch=-5.190\n",
      "Extract of training data : [1139] [10]\n",
      "60/16406, train loss is 10.546, state is -0.023102344945073128, time/batch=-4.905\n",
      "Extract of training data : [2611] [801]\n",
      "61/16406, train loss is 10.546, state is -0.013295862823724747, time/batch=-4.882\n",
      "Extract of training data : [0] [3]\n",
      "62/16406, train loss is 10.546, state is 0.006449043285101652, time/batch=-5.009\n",
      "Extract of training data : [3830] [478]\n",
      "63/16406, train loss is 10.546, state is 0.007272956892848015, time/batch=-5.001\n",
      "Extract of training data : [1426] [16]\n",
      "64/16406, train loss is 10.546, state is -0.005464424379169941, time/batch=-4.953\n",
      "Extract of training data : [422] [35]\n",
      "65/16406, train loss is 10.546, state is 0.009521003812551498, time/batch=-5.165\n",
      "Extract of training data : [873] [29]\n",
      "66/16406, train loss is 10.546, state is -0.003855601418763399, time/batch=-5.217\n",
      "Extract of training data : [19037] [21284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/16406, train loss is 10.545, state is 0.006762735079973936, time/batch=-5.151\n",
      "Extract of training data : [5214] [5809]\n",
      "68/16406, train loss is 10.546, state is -0.00023811226128600538, time/batch=-5.046\n",
      "Extract of training data : [11789] [2007]\n",
      "69/16406, train loss is 10.546, state is -0.02209370955824852, time/batch=-4.827\n",
      "Extract of training data : [1445] [9663]\n",
      "70/16406, train loss is 10.546, state is -0.001777855446562171, time/batch=-5.018\n",
      "Extract of training data : [35] [826]\n",
      "71/16406, train loss is 10.545, state is -0.00289031770080328, time/batch=-4.613\n",
      "Extract of training data : [10] [176]\n",
      "72/16406, train loss is 10.545, state is -0.0048805284313857555, time/batch=-4.294\n",
      "Extract of training data : [422] [1289]\n",
      "73/16406, train loss is 10.546, state is -0.004901772830635309, time/batch=-4.284\n",
      "Extract of training data : [0] [0]\n",
      "74/16406, train loss is 10.546, state is -0.010913760401308537, time/batch=-4.241\n",
      "Extract of training data : [413] [4311]\n",
      "75/16406, train loss is 10.545, state is 0.004289870150387287, time/batch=-4.369\n",
      "Extract of training data : [3] [3]\n",
      "76/16406, train loss is 10.546, state is -0.005277599208056927, time/batch=-4.695\n",
      "Extract of training data : [11483] [2508]\n",
      "77/16406, train loss is 10.546, state is 0.003697215346619487, time/batch=-4.837\n",
      "Extract of training data : [12] [972]\n",
      "78/16406, train loss is 10.546, state is 0.001725316746160388, time/batch=-4.826\n",
      "Extract of training data : [4378] [16249]\n",
      "79/16406, train loss is 10.546, state is -0.002846398623660207, time/batch=-4.482\n",
      "Extract of training data : [3] [3]\n",
      "80/16406, train loss is 10.546, state is 0.0020110481418669224, time/batch=-4.284\n",
      "Extract of training data : [12] [22382]\n",
      "81/16406, train loss is 10.546, state is -0.003492310643196106, time/batch=-4.215\n",
      "Extract of training data : [291] [495]\n",
      "82/16406, train loss is 10.546, state is 0.006883881986141205, time/batch=-4.192\n",
      "Extract of training data : [16] [0]\n",
      "83/16406, train loss is 10.546, state is 0.0070565687492489815, time/batch=-4.234\n",
      "Extract of training data : [22596] [12843]\n",
      "84/16406, train loss is 10.545, state is -0.0016319812275469303, time/batch=-4.194\n",
      "Extract of training data : [3] [3]\n",
      "85/16406, train loss is 10.545, state is -0.0062211682088673115, time/batch=-4.184\n",
      "Extract of training data : [3] [3]\n",
      "86/16406, train loss is 10.546, state is 0.01161174662411213, time/batch=-4.196\n",
      "Extract of training data : [20707] [720]\n",
      "87/16406, train loss is 10.546, state is 0.004867789801210165, time/batch=-4.197\n",
      "Extract of training data : [20510] [16]\n",
      "88/16406, train loss is 10.546, state is 0.02103324607014656, time/batch=-4.157\n",
      "Extract of training data : [559] [464]\n",
      "89/16406, train loss is 10.546, state is 0.000741019903216511, time/batch=-4.207\n",
      "Extract of training data : [5214] [1078]\n",
      "90/16406, train loss is 10.546, state is 0.0006514526903629303, time/batch=-4.175\n",
      "Extract of training data : [1458] [9701]\n",
      "91/16406, train loss is 10.546, state is -0.01851423643529415, time/batch=-4.206\n",
      "Extract of training data : [1234] [1842]\n",
      "92/16406, train loss is 10.546, state is 0.004851995036005974, time/batch=-4.197\n",
      "Extract of training data : [10] [4307]\n",
      "93/16406, train loss is 10.546, state is -0.018318599089980125, time/batch=-4.213\n",
      "Extract of training data : [105] [2045]\n",
      "94/16406, train loss is 10.546, state is -0.015225324779748917, time/batch=-4.240\n",
      "Extract of training data : [3202] [10]\n",
      "95/16406, train loss is 10.546, state is -0.015313719399273396, time/batch=-4.184\n",
      "Extract of training data : [23373] [16]\n",
      "96/16406, train loss is 10.546, state is -0.01783085986971855, time/batch=-4.223\n",
      "Extract of training data : [3] [3]\n",
      "97/16406, train loss is 10.546, state is -0.0004040659696329385, time/batch=-4.198\n",
      "Extract of training data : [2557] [3]\n",
      "98/16406, train loss is 10.545, state is 0.0020310983527451754, time/batch=-4.197\n",
      "Extract of training data : [5593] [2392]\n",
      "99/16406, train loss is 10.546, state is 0.005490757059305906, time/batch=-4.201\n",
      "Extract of training data : [1437] [16726]\n",
      "100/16406, train loss is 10.546, state is -0.017529066652059555, time/batch=-4.178\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1308] [5313]\n",
      "101/16406, train loss is 10.546, state is 0.011567101813852787, time/batch=-4.643\n",
      "Extract of training data : [280] [1228]\n",
      "102/16406, train loss is 10.546, state is -0.029143568128347397, time/batch=-4.228\n",
      "Extract of training data : [3] [277]\n",
      "103/16406, train loss is 10.546, state is -0.0033706538379192352, time/batch=-4.413\n",
      "Extract of training data : [13852] [2841]\n",
      "104/16406, train loss is 10.546, state is 0.0005928957252763212, time/batch=-4.487\n",
      "Extract of training data : [378] [327]\n",
      "105/16406, train loss is 10.546, state is 0.011276989243924618, time/batch=-4.644\n",
      "Extract of training data : [23552] [146]\n",
      "106/16406, train loss is 10.546, state is -0.006294067949056625, time/batch=-4.786\n",
      "Extract of training data : [10] [14699]\n",
      "107/16406, train loss is 10.546, state is -0.019905462861061096, time/batch=-4.826\n",
      "Extract of training data : [7937] [2082]\n",
      "108/16406, train loss is 10.546, state is 0.0066664512269198895, time/batch=-4.338\n",
      "Extract of training data : [2442] [21812]\n",
      "109/16406, train loss is 10.546, state is 0.00016386184142902493, time/batch=-4.423\n",
      "Extract of training data : [1575] [1419]\n",
      "110/16406, train loss is 10.546, state is -0.004870673641562462, time/batch=-4.641\n",
      "Extract of training data : [10] [6154]\n",
      "111/16406, train loss is 10.546, state is 0.009773899801075459, time/batch=-4.790\n",
      "Extract of training data : [3] [3]\n",
      "112/16406, train loss is 10.546, state is -0.003118748776614666, time/batch=-4.478\n",
      "Extract of training data : [2039] [10]\n",
      "113/16406, train loss is 10.546, state is -0.023193085566163063, time/batch=-4.259\n",
      "Extract of training data : [105] [16]\n",
      "114/16406, train loss is 10.546, state is 0.001457269536331296, time/batch=-4.287\n",
      "Extract of training data : [413] [473]\n",
      "115/16406, train loss is 10.546, state is -0.015276221558451653, time/batch=-4.310\n",
      "Extract of training data : [24668] [10]\n",
      "116/16406, train loss is 10.546, state is -0.01439331192523241, time/batch=-4.277\n",
      "Extract of training data : [2045] [877]\n",
      "117/16406, train loss is 10.546, state is 0.00816345401108265, time/batch=-4.262\n",
      "Extract of training data : [877] [877]\n",
      "118/16406, train loss is 10.546, state is 0.006832045968621969, time/batch=-4.300\n",
      "Extract of training data : [71] [33]\n",
      "119/16406, train loss is 10.546, state is -0.018114859238266945, time/batch=-4.316\n",
      "Extract of training data : [3] [3]\n",
      "120/16406, train loss is 10.546, state is 0.0034499638713896275, time/batch=-4.429\n",
      "Extract of training data : [256] [3247]\n",
      "121/16406, train loss is 10.546, state is 0.006636994890868664, time/batch=-4.365\n",
      "Extract of training data : [10] [3818]\n",
      "122/16406, train loss is 10.545, state is 0.0044290125370025635, time/batch=-4.493\n",
      "Extract of training data : [146] [8]\n",
      "123/16406, train loss is 10.546, state is 0.002944718347862363, time/batch=-4.548\n",
      "Extract of training data : [18743] [465]\n",
      "124/16406, train loss is 10.546, state is -0.007810760289430618, time/batch=-4.406\n",
      "Extract of training data : [25375] [10]\n",
      "125/16406, train loss is 10.545, state is -0.00012141910701757297, time/batch=-4.533\n",
      "Extract of training data : [1501] [10]\n",
      "126/16406, train loss is 10.546, state is -0.015395530499517918, time/batch=-4.655\n",
      "Extract of training data : [1577] [1176]\n",
      "127/16406, train loss is 10.546, state is 0.008844028227031231, time/batch=-4.705\n",
      "Extract of training data : [172] [10]\n",
      "128/16406, train loss is 10.546, state is 0.004217600915580988, time/batch=-4.993\n",
      "Extract of training data : [3728] [33]\n",
      "129/16406, train loss is 10.546, state is 0.0009552881238050759, time/batch=-4.580\n",
      "Extract of training data : [21] [10]\n",
      "130/16406, train loss is 10.546, state is 0.0484369695186615, time/batch=-4.299\n",
      "Extract of training data : [344] [3219]\n",
      "131/16406, train loss is 10.546, state is 0.014773616567254066, time/batch=-4.395\n",
      "Extract of training data : [1829] [1310]\n",
      "132/16406, train loss is 10.546, state is -0.020348209887742996, time/batch=-4.744\n",
      "Extract of training data : [3] [3]\n",
      "133/16406, train loss is 10.546, state is -0.0052412524819374084, time/batch=-4.755\n",
      "Extract of training data : [7051] [536]\n",
      "134/16406, train loss is 10.546, state is -0.0029565736185759306, time/batch=-4.693\n",
      "Extract of training data : [544] [372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/16406, train loss is 10.546, state is 0.00561227323487401, time/batch=-4.826\n",
      "Extract of training data : [4329] [35]\n",
      "136/16406, train loss is 10.545, state is -0.005487286485731602, time/batch=-4.454\n",
      "Extract of training data : [16] [280]\n",
      "137/16406, train loss is 10.545, state is 0.005231561604887247, time/batch=-4.524\n",
      "Extract of training data : [12504] [7071]\n",
      "138/16406, train loss is 10.546, state is -0.008014721795916557, time/batch=-4.616\n",
      "Extract of training data : [2305] [912]\n",
      "139/16406, train loss is 10.546, state is -0.019076772034168243, time/batch=-4.373\n",
      "Extract of training data : [1161] [1191]\n",
      "140/16406, train loss is 10.546, state is -0.014394979923963547, time/batch=-4.644\n",
      "Extract of training data : [12504] [7284]\n",
      "141/16406, train loss is 10.546, state is -0.007472638506442308, time/batch=-4.649\n",
      "Extract of training data : [8454] [16]\n",
      "142/16406, train loss is 10.546, state is 0.005311307497322559, time/batch=-4.390\n",
      "Extract of training data : [35] [3055]\n",
      "143/16406, train loss is 10.546, state is 0.0038134553469717503, time/batch=-4.393\n",
      "Extract of training data : [10] [26159]\n",
      "144/16406, train loss is 10.546, state is 0.000166494442964904, time/batch=-4.117\n",
      "Extract of training data : [699] [16]\n",
      "145/16406, train loss is 10.546, state is 0.0149306645616889, time/batch=-4.117\n",
      "Extract of training data : [24499] [12504]\n",
      "146/16406, train loss is 10.545, state is 0.001731770345941186, time/batch=-4.145\n",
      "Extract of training data : [275] [20945]\n",
      "147/16406, train loss is 10.546, state is -4.134304617764428e-05, time/batch=-4.132\n",
      "Extract of training data : [10] [12]\n",
      "148/16406, train loss is 10.546, state is -0.0023517291992902756, time/batch=-4.096\n",
      "Extract of training data : [3326] [722]\n",
      "149/16406, train loss is 10.546, state is 0.01117544062435627, time/batch=-4.142\n",
      "Extract of training data : [26887] [105]\n",
      "150/16406, train loss is 10.546, state is -0.0019134118920192122, time/batch=-4.113\n",
      "Extract of training data : [10188] [35]\n",
      "151/16406, train loss is 10.546, state is -0.012018375098705292, time/batch=-4.112\n",
      "Extract of training data : [4309] [10]\n",
      "152/16406, train loss is 10.545, state is 0.003793892217800021, time/batch=-4.143\n",
      "Extract of training data : [71] [2311]\n",
      "153/16406, train loss is 10.546, state is -0.0066881622187793255, time/batch=-4.158\n",
      "Extract of training data : [0] [0]\n",
      "154/16406, train loss is 10.546, state is 0.00737787876278162, time/batch=-4.102\n",
      "Extract of training data : [8] [277]\n",
      "155/16406, train loss is 10.545, state is -0.007525317370891571, time/batch=-4.160\n",
      "Extract of training data : [3] [3]\n",
      "156/16406, train loss is 10.546, state is -0.004163037054240704, time/batch=-4.081\n",
      "Extract of training data : [10] [667]\n",
      "157/16406, train loss is 10.546, state is -0.0004307098570279777, time/batch=-4.200\n",
      "Extract of training data : [2267] [35]\n",
      "158/16406, train loss is 10.546, state is -0.019359929487109184, time/batch=-4.232\n",
      "Extract of training data : [27448] [13378]\n",
      "159/16406, train loss is 10.545, state is -0.01607534848153591, time/batch=-4.239\n",
      "Extract of training data : [10] [328]\n",
      "160/16406, train loss is 10.545, state is 0.005173909943550825, time/batch=-4.135\n",
      "Extract of training data : [2968] [10]\n",
      "161/16406, train loss is 10.546, state is 0.004827294964343309, time/batch=-4.181\n",
      "Extract of training data : [326] [27664]\n",
      "162/16406, train loss is 10.545, state is 0.016310956329107285, time/batch=-4.102\n",
      "Extract of training data : [16] [0]\n",
      "163/16406, train loss is 10.545, state is -0.0018848635954782367, time/batch=-4.143\n",
      "Extract of training data : [10] [2438]\n",
      "164/16406, train loss is 10.545, state is -0.007952779531478882, time/batch=-4.144\n",
      "Extract of training data : [3] [3]\n",
      "165/16406, train loss is 10.545, state is -0.015621363185346127, time/batch=-4.126\n",
      "Extract of training data : [582] [4227]\n",
      "166/16406, train loss is 10.546, state is -0.001594059867784381, time/batch=-4.164\n",
      "Extract of training data : [0] [3]\n",
      "167/16406, train loss is 10.546, state is -0.019953208044171333, time/batch=-4.124\n",
      "Extract of training data : [1557] [422]\n",
      "168/16406, train loss is 10.546, state is 0.010520759038627148, time/batch=-4.098\n",
      "Extract of training data : [20102] [11553]\n",
      "169/16406, train loss is 10.546, state is 0.004098463803529739, time/batch=-4.135\n",
      "Extract of training data : [105] [688]\n",
      "170/16406, train loss is 10.546, state is 0.013560626655817032, time/batch=-4.121\n",
      "Extract of training data : [16577] [11276]\n",
      "171/16406, train loss is 10.546, state is -0.01700727641582489, time/batch=-4.142\n",
      "Extract of training data : [2708] [16]\n",
      "172/16406, train loss is 10.546, state is -0.0007077532354742289, time/batch=-4.150\n",
      "Extract of training data : [283] [12524]\n",
      "173/16406, train loss is 10.546, state is -0.009727485477924347, time/batch=-4.128\n",
      "Extract of training data : [28432] [1161]\n",
      "174/16406, train loss is 10.546, state is -0.021524447947740555, time/batch=-4.149\n",
      "Extract of training data : [318] [35]\n",
      "175/16406, train loss is 10.545, state is 0.011764434166252613, time/batch=-4.116\n",
      "Extract of training data : [13897] [35]\n",
      "176/16406, train loss is 10.546, state is 0.010472007095813751, time/batch=-4.094\n",
      "Extract of training data : [0] [0]\n",
      "177/16406, train loss is 10.545, state is 0.015918273478746414, time/batch=-4.149\n",
      "Extract of training data : [1515] [10]\n",
      "178/16406, train loss is 10.546, state is -0.0010760943405330181, time/batch=-4.115\n",
      "Extract of training data : [533] [259]\n",
      "179/16406, train loss is 10.546, state is -0.016441667452454567, time/batch=-4.146\n",
      "Extract of training data : [3] [9745]\n",
      "180/16406, train loss is 10.545, state is 0.016129856929183006, time/batch=-4.158\n",
      "Extract of training data : [6286] [292]\n",
      "181/16406, train loss is 10.546, state is 0.009640540927648544, time/batch=-4.095\n",
      "Extract of training data : [877] [1601]\n",
      "182/16406, train loss is 10.545, state is 0.004196035675704479, time/batch=-4.155\n",
      "Extract of training data : [3] [3980]\n",
      "183/16406, train loss is 10.546, state is 0.009312927722930908, time/batch=-4.199\n",
      "Extract of training data : [10] [422]\n",
      "184/16406, train loss is 10.546, state is 0.01456119492650032, time/batch=-4.141\n",
      "Extract of training data : [9144] [4211]\n",
      "185/16406, train loss is 10.546, state is -0.0021880879066884518, time/batch=-4.276\n",
      "Extract of training data : [12699] [424]\n",
      "186/16406, train loss is 10.546, state is 0.0032170559279620647, time/batch=-4.138\n",
      "Extract of training data : [458] [4016]\n",
      "187/16406, train loss is 10.546, state is -0.0012131480034440756, time/batch=-4.163\n",
      "Extract of training data : [12482] [10]\n",
      "188/16406, train loss is 10.545, state is 0.01762787625193596, time/batch=-4.114\n",
      "Extract of training data : [3] [3]\n",
      "189/16406, train loss is 10.546, state is 0.011293253861367702, time/batch=-4.155\n",
      "Extract of training data : [548] [29227]\n",
      "190/16406, train loss is 10.545, state is 0.010835612192749977, time/batch=-4.215\n",
      "Extract of training data : [4352] [10]\n",
      "191/16406, train loss is 10.545, state is 0.017381452023983, time/batch=-4.156\n",
      "Extract of training data : [12986] [2127]\n",
      "192/16406, train loss is 10.546, state is -0.011425563134253025, time/batch=-4.117\n",
      "Extract of training data : [3055] [15878]\n",
      "193/16406, train loss is 10.546, state is 0.012200365774333477, time/batch=-4.173\n",
      "Extract of training data : [1188] [2398]\n",
      "194/16406, train loss is 10.546, state is 0.002276109531521797, time/batch=-4.122\n",
      "Extract of training data : [4179] [10]\n",
      "195/16406, train loss is 10.546, state is -0.002560961991548538, time/batch=-4.150\n",
      "Extract of training data : [1385] [5846]\n",
      "196/16406, train loss is 10.546, state is 0.014936914667487144, time/batch=-4.130\n",
      "Extract of training data : [0] [3]\n",
      "197/16406, train loss is 10.546, state is -0.0002931815979536623, time/batch=-4.118\n",
      "Extract of training data : [1299] [1419]\n",
      "198/16406, train loss is 10.546, state is -0.009311527013778687, time/batch=-4.198\n",
      "Extract of training data : [3758] [796]\n",
      "199/16406, train loss is 10.546, state is -0.0026801112107932568, time/batch=-4.254\n",
      "Extract of training data : [29609] [10]\n",
      "200/16406, train loss is 10.545, state is -0.009210995398461819, time/batch=-4.242\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [2574] [10]\n",
      "201/16406, train loss is 10.546, state is -0.006955070421099663, time/batch=-4.216\n",
      "Extract of training data : [3] [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/16406, train loss is 10.546, state is 0.005724200513213873, time/batch=-4.115\n",
      "Extract of training data : [1846] [1422]\n",
      "203/16406, train loss is 10.545, state is 0.009319290518760681, time/batch=-4.122\n",
      "Extract of training data : [2271] [4130]\n",
      "204/16406, train loss is 10.546, state is 0.007927779108285904, time/batch=-4.110\n",
      "Extract of training data : [10] [544]\n",
      "205/16406, train loss is 10.546, state is 0.0008257427834905684, time/batch=-4.143\n",
      "Extract of training data : [21448] [29955]\n",
      "206/16406, train loss is 10.546, state is 0.0016287657199427485, time/batch=-4.139\n",
      "Extract of training data : [10] [3611]\n",
      "207/16406, train loss is 10.546, state is -0.005919860675930977, time/batch=-4.154\n",
      "Extract of training data : [3] [582]\n",
      "208/16406, train loss is 10.545, state is -0.013897445052862167, time/batch=-4.191\n",
      "Extract of training data : [30161] [20610]\n",
      "209/16406, train loss is 10.545, state is -0.004213299602270126, time/batch=-4.143\n",
      "Extract of training data : [2257] [10]\n",
      "210/16406, train loss is 10.546, state is 0.006913222372531891, time/batch=-4.122\n",
      "Extract of training data : [15065] [4352]\n",
      "211/16406, train loss is 10.546, state is 0.01822877861559391, time/batch=-4.162\n",
      "Extract of training data : [35] [16445]\n",
      "212/16406, train loss is 10.546, state is -0.006559919565916061, time/batch=-4.132\n",
      "Extract of training data : [422] [532]\n",
      "213/16406, train loss is 10.546, state is -0.009540028870105743, time/batch=-4.117\n",
      "Extract of training data : [843] [10]\n",
      "214/16406, train loss is 10.546, state is 0.0030127963982522488, time/batch=-4.203\n",
      "Extract of training data : [10] [30502]\n",
      "215/16406, train loss is 10.546, state is -0.0012603832874447107, time/batch=-4.156\n",
      "Extract of training data : [10] [4141]\n",
      "216/16406, train loss is 10.545, state is 0.0028067126404494047, time/batch=-4.139\n",
      "Extract of training data : [413] [12916]\n",
      "217/16406, train loss is 10.546, state is 0.01117593515664339, time/batch=-4.106\n",
      "Extract of training data : [30689] [399]\n",
      "218/16406, train loss is 10.545, state is 0.0015973872505128384, time/batch=-4.217\n",
      "Extract of training data : [0] [3]\n",
      "219/16406, train loss is 10.546, state is -0.009324410930275917, time/batch=-4.175\n",
      "Extract of training data : [29] [413]\n",
      "220/16406, train loss is 10.546, state is -0.0005628576036542654, time/batch=-4.128\n",
      "Extract of training data : [10] [1185]\n",
      "221/16406, train loss is 10.545, state is 0.0032490298617631197, time/batch=-4.159\n",
      "Extract of training data : [582] [472]\n",
      "222/16406, train loss is 10.546, state is 0.005231259390711784, time/batch=-4.099\n",
      "Extract of training data : [0] [0]\n",
      "223/16406, train loss is 10.546, state is -0.010216440074145794, time/batch=-4.106\n",
      "Extract of training data : [553] [3340]\n",
      "224/16406, train loss is 10.545, state is -0.005402303766459227, time/batch=-4.147\n",
      "Extract of training data : [5196] [1220]\n",
      "225/16406, train loss is 10.546, state is -0.005317017901688814, time/batch=-4.134\n",
      "Extract of training data : [46] [1295]\n",
      "226/16406, train loss is 10.546, state is -0.015643958002328873, time/batch=-4.118\n",
      "Extract of training data : [3] [3]\n",
      "227/16406, train loss is 10.546, state is -0.00766307907178998, time/batch=-4.125\n",
      "Extract of training data : [50] [1963]\n",
      "228/16406, train loss is 10.546, state is -0.010566171258687973, time/batch=-4.164\n",
      "Extract of training data : [174] [12]\n",
      "229/16406, train loss is 10.546, state is 0.013245606794953346, time/batch=-4.151\n",
      "Extract of training data : [3408] [111]\n",
      "230/16406, train loss is 10.545, state is -0.02085809037089348, time/batch=-4.159\n",
      "Extract of training data : [0] [0]\n",
      "231/16406, train loss is 10.545, state is 0.00457909656688571, time/batch=-4.216\n",
      "Extract of training data : [10] [293]\n",
      "232/16406, train loss is 10.545, state is 0.008487098850309849, time/batch=-4.213\n",
      "Extract of training data : [2720] [1628]\n",
      "233/16406, train loss is 10.546, state is -0.010879943147301674, time/batch=-4.173\n",
      "Extract of training data : [15444] [1575]\n",
      "234/16406, train loss is 10.546, state is -0.0038534870836883783, time/batch=-4.144\n",
      "Extract of training data : [422] [9376]\n",
      "235/16406, train loss is 10.546, state is -0.005086612422019243, time/batch=-4.165\n",
      "Extract of training data : [28979] [413]\n",
      "236/16406, train loss is 10.546, state is -0.007115359418094158, time/batch=-4.181\n",
      "Extract of training data : [105] [938]\n",
      "237/16406, train loss is 10.546, state is -0.011820483952760696, time/batch=-4.109\n",
      "Extract of training data : [18981] [31828]\n",
      "238/16406, train loss is 10.546, state is -0.010185746476054192, time/batch=-4.104\n",
      "Extract of training data : [14014] [13306]\n",
      "239/16406, train loss is 10.546, state is -0.007612329442054033, time/batch=-4.127\n",
      "Extract of training data : [16355] [31920]\n",
      "240/16406, train loss is 10.546, state is -0.013075937516987324, time/batch=-4.118\n",
      "Extract of training data : [957] [811]\n",
      "241/16406, train loss is 10.545, state is 0.0026602253783494234, time/batch=-4.139\n",
      "Extract of training data : [3515] [3516]\n",
      "242/16406, train loss is 10.546, state is 0.006806541234254837, time/batch=-4.163\n",
      "Extract of training data : [413] [21]\n",
      "243/16406, train loss is 10.546, state is -0.00393250584602356, time/batch=-4.238\n",
      "Extract of training data : [1591] [28]\n",
      "244/16406, train loss is 10.546, state is -0.01757194660604, time/batch=-4.156\n",
      "Extract of training data : [32107] [5180]\n",
      "245/16406, train loss is 10.546, state is 0.00283954874612391, time/batch=-4.095\n",
      "Extract of training data : [12] [9745]\n",
      "246/16406, train loss is 10.546, state is 0.003927003126591444, time/batch=-4.165\n",
      "Extract of training data : [144] [16]\n",
      "247/16406, train loss is 10.545, state is -0.004197993315756321, time/batch=-4.201\n",
      "Extract of training data : [3] [3]\n",
      "248/16406, train loss is 10.546, state is 0.018569784238934517, time/batch=-4.092\n",
      "Extract of training data : [0] [0]\n",
      "249/16406, train loss is 10.546, state is -0.010683265514671803, time/batch=-4.141\n",
      "Extract of training data : [877] [280]\n",
      "250/16406, train loss is 10.545, state is -0.0012969571398571134, time/batch=-4.110\n",
      "Extract of training data : [15481] [29328]\n",
      "251/16406, train loss is 10.545, state is -0.0028908320236951113, time/batch=-4.142\n",
      "Extract of training data : [3] [3]\n",
      "252/16406, train loss is 10.545, state is 0.0030078624840825796, time/batch=-4.122\n",
      "Extract of training data : [3] [3366]\n",
      "253/16406, train loss is 10.545, state is -0.005888014566153288, time/batch=-4.115\n",
      "Extract of training data : [27445] [920]\n",
      "254/16406, train loss is 10.546, state is -0.025706926360726357, time/batch=-4.120\n",
      "Extract of training data : [873] [2875]\n",
      "255/16406, train loss is 10.545, state is -0.020222963765263557, time/batch=-4.135\n",
      "Extract of training data : [1597] [442]\n",
      "256/16406, train loss is 10.546, state is 0.006545661482959986, time/batch=-4.110\n",
      "Extract of training data : [582] [1293]\n",
      "257/16406, train loss is 10.546, state is -0.0067983572371304035, time/batch=-4.510\n",
      "Extract of training data : [877] [280]\n",
      "258/16406, train loss is 10.545, state is -0.021270107477903366, time/batch=-4.234\n",
      "Extract of training data : [5590] [850]\n",
      "259/16406, train loss is 10.546, state is 0.00971989519894123, time/batch=-4.433\n",
      "Extract of training data : [1014] [71]\n",
      "260/16406, train loss is 10.546, state is -0.0015684987884014845, time/batch=-4.668\n",
      "Extract of training data : [10] [143]\n",
      "261/16406, train loss is 10.545, state is -0.000382515718229115, time/batch=-4.728\n",
      "Extract of training data : [4088] [1321]\n",
      "262/16406, train loss is 10.545, state is -0.010199276730418205, time/batch=-4.425\n",
      "Extract of training data : [8] [1599]\n",
      "263/16406, train loss is 10.546, state is 0.009990926831960678, time/batch=-4.173\n",
      "Extract of training data : [1599] [873]\n",
      "264/16406, train loss is 10.546, state is -0.015401647426187992, time/batch=-4.127\n",
      "Extract of training data : [10378] [912]\n",
      "265/16406, train loss is 10.546, state is 0.000497751752845943, time/batch=-4.122\n",
      "Extract of training data : [105] [371]\n",
      "266/16406, train loss is 10.546, state is -0.002592438366264105, time/batch=-4.110\n",
      "Extract of training data : [371] [10]\n",
      "267/16406, train loss is 10.546, state is 0.008897969499230385, time/batch=-4.163\n",
      "Extract of training data : [35] [1553]\n",
      "268/16406, train loss is 10.546, state is -0.007623222656548023, time/batch=-4.094\n",
      "Extract of training data : [3] [23546]\n",
      "269/16406, train loss is 10.546, state is 0.007190164644271135, time/batch=-4.181\n",
      "Extract of training data : [1745] [2853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/16406, train loss is 10.546, state is 0.014002691954374313, time/batch=-4.079\n",
      "Extract of training data : [3] [3]\n",
      "271/16406, train loss is 10.546, state is -0.00027996228891424835, time/batch=-4.373\n",
      "Extract of training data : [3137] [10]\n",
      "272/16406, train loss is 10.546, state is 0.014455494470894337, time/batch=-4.200\n",
      "Extract of training data : [256] [1078]\n",
      "273/16406, train loss is 10.546, state is -0.02083374187350273, time/batch=-4.137\n",
      "Extract of training data : [5551] [571]\n",
      "274/16406, train loss is 10.546, state is -0.006059036590158939, time/batch=-4.116\n",
      "Extract of training data : [164] [117]\n",
      "275/16406, train loss is 10.546, state is -0.0030256586614996195, time/batch=-4.202\n",
      "Extract of training data : [1002] [21402]\n",
      "276/16406, train loss is 10.546, state is -0.010606453754007816, time/batch=-4.160\n",
      "Extract of training data : [1265] [1289]\n",
      "277/16406, train loss is 10.546, state is 0.015215776860713959, time/batch=-4.102\n",
      "Extract of training data : [10] [413]\n",
      "278/16406, train loss is 10.546, state is -0.008640749379992485, time/batch=-4.112\n",
      "Extract of training data : [33275] [10]\n",
      "279/16406, train loss is 10.546, state is -0.004399675410240889, time/batch=-4.114\n",
      "Extract of training data : [1197] [10]\n",
      "280/16406, train loss is 10.546, state is 0.005334016866981983, time/batch=-4.116\n",
      "Extract of training data : [1188] [13896]\n",
      "281/16406, train loss is 10.545, state is -0.009180027060210705, time/batch=-4.095\n",
      "Extract of training data : [344] [16557]\n",
      "282/16406, train loss is 10.545, state is 0.0019073649309575558, time/batch=-4.120\n",
      "Extract of training data : [1198] [105]\n",
      "283/16406, train loss is 10.546, state is 0.005638912785798311, time/batch=-4.104\n",
      "Extract of training data : [561] [1108]\n",
      "284/16406, train loss is 10.546, state is -0.0027822665870189667, time/batch=-4.098\n",
      "Extract of training data : [50] [3792]\n",
      "285/16406, train loss is 10.545, state is 0.003921572584658861, time/batch=-4.111\n",
      "Extract of training data : [32] [77]\n",
      "286/16406, train loss is 10.545, state is 0.0038438141345977783, time/batch=-4.101\n",
      "Extract of training data : [24371] [35]\n",
      "287/16406, train loss is 10.546, state is 0.01416975911706686, time/batch=-4.125\n",
      "Extract of training data : [33733] [10]\n",
      "288/16406, train loss is 10.546, state is -0.0015504722250625491, time/batch=-4.102\n",
      "Extract of training data : [3] [3]\n",
      "289/16406, train loss is 10.546, state is -0.010473544709384441, time/batch=-4.104\n",
      "Extract of training data : [4299] [14537]\n",
      "290/16406, train loss is 10.546, state is 0.0015422697179019451, time/batch=-4.120\n",
      "Extract of training data : [10] [146]\n",
      "291/16406, train loss is 10.545, state is -0.008629048243165016, time/batch=-4.166\n",
      "Extract of training data : [2985] [3315]\n",
      "292/16406, train loss is 10.545, state is -0.0008067575981840491, time/batch=-4.124\n",
      "Extract of training data : [3] [164]\n",
      "293/16406, train loss is 10.545, state is -0.002943585626780987, time/batch=-4.126\n",
      "Extract of training data : [105] [16]\n",
      "294/16406, train loss is 10.546, state is -0.004557873122394085, time/batch=-4.131\n",
      "Extract of training data : [3] [27283]\n",
      "295/16406, train loss is 10.546, state is 0.024849388748407364, time/batch=-4.105\n",
      "Extract of training data : [15444] [26029]\n",
      "296/16406, train loss is 10.545, state is -0.0026613608933985233, time/batch=-4.099\n",
      "Extract of training data : [10] [34177]\n",
      "297/16406, train loss is 10.546, state is -0.00922116544097662, time/batch=-4.104\n",
      "Extract of training data : [2121] [51]\n",
      "298/16406, train loss is 10.546, state is 0.010079729370772839, time/batch=-4.081\n",
      "Extract of training data : [71] [5846]\n",
      "299/16406, train loss is 10.546, state is 0.004754167515784502, time/batch=-4.127\n",
      "Extract of training data : [13476] [35]\n",
      "300/16406, train loss is 10.545, state is 0.01015760563313961, time/batch=-4.208\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [951] [105]\n",
      "301/16406, train loss is 10.546, state is -0.0184633769094944, time/batch=-4.152\n",
      "Extract of training data : [3] [3]\n",
      "302/16406, train loss is 10.546, state is 0.013757647015154362, time/batch=-4.126\n",
      "Extract of training data : [66] [10]\n",
      "303/16406, train loss is 10.546, state is -0.011439413763582706, time/batch=-4.167\n",
      "Extract of training data : [111] [1416]\n",
      "304/16406, train loss is 10.546, state is -0.015913138166069984, time/batch=-4.249\n",
      "Extract of training data : [1874] [256]\n",
      "305/16406, train loss is 10.546, state is -0.0015394941437989473, time/batch=-4.161\n",
      "Extract of training data : [943] [2559]\n",
      "306/16406, train loss is 10.546, state is -0.011100604198873043, time/batch=-4.150\n",
      "Extract of training data : [10] [1108]\n",
      "307/16406, train loss is 10.545, state is -0.01716703549027443, time/batch=-4.201\n",
      "Extract of training data : [3732] [289]\n",
      "308/16406, train loss is 10.546, state is -0.012871486134827137, time/batch=-4.120\n",
      "Extract of training data : [5351] [4130]\n",
      "309/16406, train loss is 10.545, state is -0.005014303606003523, time/batch=-4.175\n",
      "Extract of training data : [277] [873]\n",
      "310/16406, train loss is 10.546, state is -0.022363021969795227, time/batch=-4.109\n",
      "Extract of training data : [5780] [31849]\n",
      "311/16406, train loss is 10.547, state is 0.008167915977537632, time/batch=-4.104\n",
      "Extract of training data : [0] [0]\n",
      "312/16406, train loss is 10.546, state is 0.005431664641946554, time/batch=-4.091\n",
      "Extract of training data : [6253] [10]\n",
      "313/16406, train loss is 10.546, state is -0.0040220231749117374, time/batch=-4.213\n",
      "Extract of training data : [904] [34937]\n",
      "314/16406, train loss is 10.547, state is 0.02975098043680191, time/batch=-4.157\n",
      "Extract of training data : [7281] [117]\n",
      "315/16406, train loss is 10.546, state is 0.003570378292351961, time/batch=-4.123\n",
      "Extract of training data : [16] [280]\n",
      "316/16406, train loss is 10.545, state is -0.00589317362755537, time/batch=-4.114\n",
      "Extract of training data : [35109] [2861]\n",
      "317/16406, train loss is 10.545, state is 0.007175080943852663, time/batch=-4.159\n",
      "Extract of training data : [35] [24498]\n",
      "318/16406, train loss is 10.545, state is 0.0019252789206802845, time/batch=-4.116\n",
      "Extract of training data : [2736] [920]\n",
      "319/16406, train loss is 10.545, state is -0.014512055553495884, time/batch=-4.134\n",
      "Extract of training data : [2284] [675]\n",
      "320/16406, train loss is 10.546, state is -0.005495884921401739, time/batch=-4.136\n",
      "Extract of training data : [22143] [16]\n",
      "321/16406, train loss is 10.546, state is -0.004900468047708273, time/batch=-4.155\n",
      "Extract of training data : [532] [71]\n",
      "322/16406, train loss is 10.546, state is -0.01156393252313137, time/batch=-4.155\n",
      "Extract of training data : [1] [1]\n",
      "323/16406, train loss is 10.545, state is -0.013242245651781559, time/batch=-4.126\n",
      "Extract of training data : [2135] [10245]\n",
      "324/16406, train loss is 10.546, state is -0.023016436025500298, time/batch=-4.107\n",
      "Extract of training data : [699] [436]\n",
      "325/16406, train loss is 10.545, state is 0.008641145192086697, time/batch=-4.132\n",
      "Extract of training data : [1137] [35]\n",
      "326/16406, train loss is 10.545, state is 0.012898963876068592, time/batch=-4.190\n",
      "Extract of training data : [35660] [912]\n",
      "327/16406, train loss is 10.546, state is -0.0013367810752242804, time/batch=-4.098\n",
      "Extract of training data : [15010] [3268]\n",
      "328/16406, train loss is 10.546, state is 0.005176798440515995, time/batch=-4.451\n",
      "Extract of training data : [6962] [164]\n",
      "329/16406, train loss is 10.546, state is -0.0018254215829074383, time/batch=-4.585\n",
      "Extract of training data : [3] [3]\n",
      "330/16406, train loss is 10.545, state is 0.014761723577976227, time/batch=-4.125\n",
      "Extract of training data : [666] [10]\n",
      "331/16406, train loss is 10.545, state is -0.01845943182706833, time/batch=-4.127\n",
      "Extract of training data : [10] [1785]\n",
      "332/16406, train loss is 10.546, state is -0.01330582145601511, time/batch=-4.170\n",
      "Extract of training data : [177] [105]\n",
      "333/16406, train loss is 10.545, state is -0.0024599856697022915, time/batch=-4.155\n",
      "Extract of training data : [581] [105]\n",
      "334/16406, train loss is 10.545, state is -0.015078271739184856, time/batch=-4.187\n",
      "Extract of training data : [10] [6891]\n",
      "335/16406, train loss is 10.545, state is -0.011005662381649017, time/batch=-4.116\n",
      "Extract of training data : [36002] [10]\n",
      "336/16406, train loss is 10.545, state is -0.010503210127353668, time/batch=-4.139\n",
      "Extract of training data : [10] [1626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/16406, train loss is 10.546, state is -0.010159413330256939, time/batch=-4.120\n",
      "Extract of training data : [811] [10839]\n",
      "338/16406, train loss is 10.546, state is -0.012443658895790577, time/batch=-4.109\n",
      "Extract of training data : [16018] [10]\n",
      "339/16406, train loss is 10.545, state is -0.001183388289064169, time/batch=-4.126\n",
      "Extract of training data : [6027] [35]\n",
      "340/16406, train loss is 10.545, state is 0.014371911995112896, time/batch=-4.117\n",
      "Extract of training data : [1872] [45]\n",
      "341/16406, train loss is 10.546, state is -0.005471858195960522, time/batch=-4.135\n",
      "Extract of training data : [3758] [423]\n",
      "342/16406, train loss is 10.545, state is -0.0138357849791646, time/batch=-4.104\n",
      "Extract of training data : [3] [3]\n",
      "343/16406, train loss is 10.546, state is -0.005413620732724667, time/batch=-4.116\n",
      "Extract of training data : [35] [2802]\n",
      "344/16406, train loss is 10.545, state is -0.0035282764583826065, time/batch=-4.120\n",
      "Extract of training data : [811] [10]\n",
      "345/16406, train loss is 10.545, state is -0.00022296389215625823, time/batch=-4.129\n",
      "Extract of training data : [3] [3]\n",
      "346/16406, train loss is 10.546, state is 0.004397292155772448, time/batch=-4.140\n",
      "Extract of training data : [0] [0]\n",
      "347/16406, train loss is 10.545, state is -0.023751823231577873, time/batch=-4.138\n",
      "Extract of training data : [8130] [10]\n",
      "348/16406, train loss is 10.545, state is 0.005756548140197992, time/batch=-4.123\n",
      "Extract of training data : [5556] [10]\n",
      "349/16406, train loss is 10.545, state is 0.012270977720618248, time/batch=-4.142\n",
      "Extract of training data : [10378] [35]\n",
      "350/16406, train loss is 10.545, state is -0.0012049599317833781, time/batch=-4.229\n",
      "Extract of training data : [14454] [595]\n",
      "351/16406, train loss is 10.545, state is 0.00202298816293478, time/batch=-4.226\n",
      "Extract of training data : [6962] [35]\n",
      "352/16406, train loss is 10.546, state is 0.01848519779741764, time/batch=-4.152\n",
      "Extract of training data : [2492] [105]\n",
      "353/16406, train loss is 10.545, state is 7.907242252258584e-05, time/batch=-4.135\n",
      "Extract of training data : [35] [2039]\n",
      "354/16406, train loss is 10.546, state is -0.009504263289272785, time/batch=-4.154\n",
      "Extract of training data : [1348] [6566]\n",
      "355/16406, train loss is 10.545, state is 0.005942056886851788, time/batch=-4.139\n",
      "Extract of training data : [5499] [10]\n",
      "356/16406, train loss is 10.545, state is -0.0019497134489938617, time/batch=-4.104\n",
      "Extract of training data : [1078] [280]\n",
      "357/16406, train loss is 10.546, state is 0.010319959372282028, time/batch=-4.111\n",
      "Extract of training data : [901] [559]\n",
      "358/16406, train loss is 10.546, state is 0.010255761444568634, time/batch=-4.143\n",
      "Extract of training data : [0] [1]\n",
      "359/16406, train loss is 10.547, state is 0.00017631259106565267, time/batch=-4.155\n",
      "Extract of training data : [3] [3]\n",
      "360/16406, train loss is 10.547, state is -0.0024916338734328747, time/batch=-4.154\n",
      "Extract of training data : [280] [3763]\n",
      "361/16406, train loss is 10.546, state is 0.0045667411759495735, time/batch=-4.220\n",
      "Extract of training data : [105] [10]\n",
      "362/16406, train loss is 10.546, state is 0.009655112400650978, time/batch=-4.148\n",
      "Extract of training data : [4213] [29]\n",
      "363/16406, train loss is 10.546, state is -0.006229587830603123, time/batch=-4.173\n",
      "Extract of training data : [10] [777]\n",
      "364/16406, train loss is 10.545, state is -0.01784955896437168, time/batch=-4.131\n",
      "Extract of training data : [556] [10]\n",
      "365/16406, train loss is 10.545, state is 0.007444330956786871, time/batch=-4.134\n",
      "Extract of training data : [0] [0]\n",
      "366/16406, train loss is 10.546, state is -0.005221391562372446, time/batch=-4.142\n",
      "Extract of training data : [105] [1742]\n",
      "367/16406, train loss is 10.545, state is 0.008281507529318333, time/batch=-4.081\n",
      "Extract of training data : [3149] [5259]\n",
      "368/16406, train loss is 10.546, state is -0.004712603986263275, time/batch=-4.127\n",
      "Extract of training data : [3] [3408]\n",
      "369/16406, train loss is 10.546, state is 0.007659093476831913, time/batch=-4.123\n",
      "Extract of training data : [3674] [16]\n",
      "370/16406, train loss is 10.546, state is -0.004739841911941767, time/batch=-4.143\n",
      "Extract of training data : [4581] [105]\n",
      "371/16406, train loss is 10.545, state is -0.011647190898656845, time/batch=-4.115\n",
      "Extract of training data : [344] [4086]\n",
      "372/16406, train loss is 10.545, state is 0.012213155627250671, time/batch=-4.147\n",
      "Extract of training data : [9275] [1601]\n",
      "373/16406, train loss is 10.546, state is 0.018289882689714432, time/batch=-4.160\n",
      "Extract of training data : [16] [280]\n",
      "374/16406, train loss is 10.545, state is -0.00011610302317421883, time/batch=-4.107\n",
      "Extract of training data : [4422] [7432]\n",
      "375/16406, train loss is 10.546, state is 0.006786859594285488, time/batch=-4.133\n",
      "Extract of training data : [0] [3]\n",
      "376/16406, train loss is 10.546, state is -0.015427044592797756, time/batch=-4.135\n",
      "Extract of training data : [6585] [2825]\n",
      "377/16406, train loss is 10.546, state is -0.010686850175261497, time/batch=-4.138\n",
      "Extract of training data : [105] [10066]\n",
      "378/16406, train loss is 10.545, state is 0.006002063397318125, time/batch=-4.110\n",
      "Extract of training data : [16] [912]\n",
      "379/16406, train loss is 10.546, state is -0.005960332229733467, time/batch=-4.144\n",
      "Extract of training data : [647] [1826]\n",
      "380/16406, train loss is 10.545, state is -0.0061074779368937016, time/batch=-4.253\n",
      "Extract of training data : [0] [1]\n",
      "381/16406, train loss is 10.545, state is 0.02005310356616974, time/batch=-4.249\n",
      "Extract of training data : [4842] [10]\n",
      "382/16406, train loss is 10.546, state is -0.0057656848803162575, time/batch=-4.263\n",
      "Extract of training data : [105] [980]\n",
      "383/16406, train loss is 10.546, state is -0.021705348044633865, time/batch=-4.556\n",
      "Extract of training data : [10739] [12]\n",
      "384/16406, train loss is 10.546, state is 0.015273623168468475, time/batch=-4.641\n",
      "Extract of training data : [0] [0]\n",
      "385/16406, train loss is 10.545, state is 0.008279846049845219, time/batch=-4.168\n",
      "Extract of training data : [458] [174]\n",
      "386/16406, train loss is 10.545, state is 0.004146073013544083, time/batch=-4.385\n",
      "Extract of training data : [4450] [105]\n",
      "387/16406, train loss is 10.546, state is -0.004925969988107681, time/batch=-4.692\n",
      "Extract of training data : [117] [16]\n",
      "388/16406, train loss is 10.546, state is -0.010875588282942772, time/batch=-4.132\n",
      "Extract of training data : [0] [3]\n",
      "389/16406, train loss is 10.546, state is -0.003876669332385063, time/batch=-4.112\n",
      "Extract of training data : [105] [10]\n",
      "390/16406, train loss is 10.546, state is -0.014710734598338604, time/batch=-4.190\n",
      "Extract of training data : [2377] [10]\n",
      "391/16406, train loss is 10.546, state is -0.004424432758241892, time/batch=-4.197\n",
      "Extract of training data : [8] [277]\n",
      "392/16406, train loss is 10.546, state is -0.008097855374217033, time/batch=-4.097\n",
      "Extract of training data : [10] [3732]\n",
      "393/16406, train loss is 10.545, state is -0.004720955155789852, time/batch=-4.100\n",
      "Extract of training data : [4167] [245]\n",
      "394/16406, train loss is 10.545, state is -0.002551381243392825, time/batch=-4.127\n",
      "Extract of training data : [943] [10]\n",
      "395/16406, train loss is 10.546, state is -0.0023319607134908438, time/batch=-4.209\n",
      "Extract of training data : [35] [10]\n",
      "396/16406, train loss is 10.546, state is -0.011800598353147507, time/batch=-4.124\n",
      "Extract of training data : [820] [12377]\n",
      "397/16406, train loss is 10.546, state is 0.0072078825905919075, time/batch=-4.118\n",
      "Extract of training data : [12511] [10]\n",
      "398/16406, train loss is 10.546, state is 0.011498693376779556, time/batch=-4.160\n",
      "Extract of training data : [12] [6027]\n",
      "399/16406, train loss is 10.546, state is 0.003954026382416487, time/batch=-4.388\n",
      "Extract of training data : [259] [10]\n",
      "400/16406, train loss is 10.546, state is -0.021868130192160606, time/batch=-4.697\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [12970] [1119]\n",
      "401/16406, train loss is 10.545, state is -0.022119224071502686, time/batch=-4.347\n",
      "Extract of training data : [524] [844]\n",
      "402/16406, train loss is 10.546, state is 0.014258584007620811, time/batch=-4.354\n",
      "Extract of training data : [2147] [12]\n",
      "403/16406, train loss is 10.546, state is 0.0026257229037582874, time/batch=-4.559\n",
      "Extract of training data : [1171] [11230]\n",
      "404/16406, train loss is 10.546, state is -0.025815660133957863, time/batch=-4.875\n",
      "Extract of training data : [13473] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405/16406, train loss is 10.546, state is -0.004789472557604313, time/batch=-4.259\n",
      "Extract of training data : [13794] [2045]\n",
      "406/16406, train loss is 10.545, state is 0.005394291132688522, time/batch=-4.166\n",
      "Extract of training data : [29] [12581]\n",
      "407/16406, train loss is 10.545, state is -0.004666214808821678, time/batch=-4.197\n",
      "Extract of training data : [13483] [10]\n",
      "408/16406, train loss is 10.545, state is 0.015615278854966164, time/batch=-4.134\n",
      "Extract of training data : [359] [2039]\n",
      "409/16406, train loss is 10.545, state is -0.03019680455327034, time/batch=-4.114\n",
      "Extract of training data : [2050] [13961]\n",
      "410/16406, train loss is 10.545, state is -0.0010377226863056421, time/batch=-4.097\n",
      "Extract of training data : [10] [2886]\n",
      "411/16406, train loss is 10.545, state is -0.005374572705477476, time/batch=-4.184\n",
      "Extract of training data : [277] [3379]\n",
      "412/16406, train loss is 10.546, state is 0.00022906294907443225, time/batch=-4.111\n",
      "Extract of training data : [10] [14567]\n",
      "413/16406, train loss is 10.545, state is -0.009940250776708126, time/batch=-4.239\n",
      "Extract of training data : [13293] [3285]\n",
      "414/16406, train loss is 10.545, state is -0.017111342400312424, time/batch=-4.142\n",
      "Extract of training data : [877] [280]\n",
      "415/16406, train loss is 10.545, state is -0.01553407870233059, time/batch=-4.147\n",
      "Extract of training data : [413] [71]\n",
      "416/16406, train loss is 10.545, state is -0.0021627526730298996, time/batch=-4.121\n",
      "Extract of training data : [10] [1637]\n",
      "417/16406, train loss is 10.545, state is -0.012802801094949245, time/batch=-4.144\n",
      "Extract of training data : [151] [10]\n",
      "418/16406, train loss is 10.545, state is -0.01723419316112995, time/batch=-4.180\n",
      "Extract of training data : [906] [13737]\n",
      "419/16406, train loss is 10.546, state is -0.0033263368532061577, time/batch=-4.147\n",
      "Extract of training data : [10] [15284]\n",
      "420/16406, train loss is 10.545, state is 0.007555937394499779, time/batch=-4.146\n",
      "Extract of training data : [15218] [514]\n",
      "421/16406, train loss is 10.545, state is -0.0059199766255915165, time/batch=-5.162\n",
      "Extract of training data : [465] [146]\n",
      "422/16406, train loss is 10.545, state is -0.008267443627119064, time/batch=-5.326\n",
      "Extract of training data : [3] [910]\n",
      "423/16406, train loss is 10.546, state is -0.0029610188212245703, time/batch=-5.278\n",
      "Extract of training data : [0] [3]\n",
      "424/16406, train loss is 10.546, state is -0.007661733310669661, time/batch=-4.538\n",
      "Extract of training data : [55] [15900]\n",
      "425/16406, train loss is 10.546, state is -0.0023732439149171114, time/batch=-4.405\n",
      "Extract of training data : [16019] [10]\n",
      "426/16406, train loss is 10.545, state is 0.006784879602491856, time/batch=-4.288\n",
      "Extract of training data : [495] [50]\n",
      "427/16406, train loss is 10.546, state is 0.007669499143958092, time/batch=-4.319\n",
      "Extract of training data : [3] [582]\n",
      "428/16406, train loss is 10.546, state is -0.010248948819935322, time/batch=-4.385\n",
      "Extract of training data : [283] [2275]\n",
      "429/16406, train loss is 10.545, state is -0.0014605573378503323, time/batch=-4.315\n",
      "Extract of training data : [924] [3196]\n",
      "430/16406, train loss is 10.546, state is 0.009198940359055996, time/batch=-4.874\n",
      "Extract of training data : [10] [6213]\n",
      "431/16406, train loss is 10.546, state is 0.01293516717851162, time/batch=-4.469\n",
      "Extract of training data : [10] [1038]\n",
      "432/16406, train loss is 10.546, state is 0.007036148104816675, time/batch=-4.642\n",
      "Extract of training data : [3611] [71]\n",
      "433/16406, train loss is 10.546, state is -0.00029944017296656966, time/batch=-4.389\n",
      "Extract of training data : [16] [846]\n",
      "434/16406, train loss is 10.545, state is -0.008735204115509987, time/batch=-4.661\n",
      "Extract of training data : [3142] [5653]\n",
      "435/16406, train loss is 10.546, state is -0.0019321935251355171, time/batch=-4.713\n",
      "Extract of training data : [35] [5065]\n",
      "436/16406, train loss is 10.546, state is -0.012478743679821491, time/batch=-4.431\n",
      "Extract of training data : [5710] [2135]\n",
      "437/16406, train loss is 10.545, state is -0.005380965303629637, time/batch=-4.209\n",
      "Extract of training data : [9458] [280]\n",
      "438/16406, train loss is 10.545, state is 0.002951785223558545, time/batch=-4.289\n",
      "Extract of training data : [13587] [10231]\n",
      "439/16406, train loss is 10.546, state is 0.006250837817788124, time/batch=-4.164\n",
      "Extract of training data : [0] [0]\n",
      "440/16406, train loss is 10.545, state is 0.016783256083726883, time/batch=-4.254\n",
      "Extract of training data : [877] [0]\n",
      "441/16406, train loss is 10.546, state is 0.0004352547985035926, time/batch=-4.157\n",
      "Extract of training data : [3] [3]\n",
      "442/16406, train loss is 10.545, state is -0.010322642512619495, time/batch=-4.109\n",
      "Extract of training data : [2437] [559]\n",
      "443/16406, train loss is 10.546, state is 0.021621419116854668, time/batch=-4.299\n",
      "Extract of training data : [3] [3]\n",
      "444/16406, train loss is 10.546, state is 0.016797631978988647, time/batch=-4.112\n",
      "Extract of training data : [16] [0]\n",
      "445/16406, train loss is 10.545, state is -0.0052885799668729305, time/batch=-4.345\n",
      "Extract of training data : [17913] [164]\n",
      "446/16406, train loss is 10.546, state is -0.006477902643382549, time/batch=-4.369\n",
      "Extract of training data : [371] [10]\n",
      "447/16406, train loss is 10.545, state is -0.0021820191759616137, time/batch=-4.233\n",
      "Extract of training data : [344] [901]\n",
      "448/16406, train loss is 10.545, state is 0.0031353498343378305, time/batch=-4.350\n",
      "Extract of training data : [10] [23]\n",
      "449/16406, train loss is 10.545, state is -0.0026490408927202225, time/batch=-4.346\n",
      "Extract of training data : [8] [277]\n",
      "450/16406, train loss is 10.545, state is 0.01804332062602043, time/batch=-4.411\n",
      "Extract of training data : [3] [3]\n",
      "451/16406, train loss is 10.546, state is 0.012190230190753937, time/batch=-4.320\n",
      "Extract of training data : [442] [6530]\n",
      "452/16406, train loss is 10.545, state is 0.01512851007282734, time/batch=-4.378\n",
      "Extract of training data : [3] [3]\n",
      "453/16406, train loss is 10.545, state is -0.006553475745022297, time/batch=-4.494\n",
      "Extract of training data : [10] [121]\n",
      "454/16406, train loss is 10.546, state is 0.0061034406535327435, time/batch=-4.453\n",
      "Extract of training data : [2854] [10]\n",
      "455/16406, train loss is 10.545, state is -5.580902143265121e-05, time/batch=-4.440\n",
      "Extract of training data : [0] [3]\n",
      "456/16406, train loss is 10.546, state is 0.007092057261615992, time/batch=-4.386\n",
      "Extract of training data : [108] [17042]\n",
      "457/16406, train loss is 10.546, state is 0.012855039909482002, time/batch=-4.408\n",
      "Extract of training data : [16049] [811]\n",
      "458/16406, train loss is 10.545, state is -0.016670124605298042, time/batch=-4.258\n",
      "Extract of training data : [21674] [2742]\n",
      "459/16406, train loss is 10.545, state is -0.008386939764022827, time/batch=-4.183\n",
      "Extract of training data : [2137] [10]\n",
      "460/16406, train loss is 10.545, state is 0.022410985082387924, time/batch=-4.306\n",
      "Extract of training data : [10] [1133]\n",
      "461/16406, train loss is 10.546, state is 0.000734193017706275, time/batch=-4.392\n",
      "Extract of training data : [10] [4950]\n",
      "462/16406, train loss is 10.546, state is 0.010040005668997765, time/batch=-4.466\n",
      "Extract of training data : [910] [1006]\n",
      "463/16406, train loss is 10.546, state is 0.011128460057079792, time/batch=-4.157\n",
      "Extract of training data : [920] [28]\n",
      "464/16406, train loss is 10.546, state is -0.0030113288667052984, time/batch=-4.227\n",
      "Extract of training data : [0] [0]\n",
      "465/16406, train loss is 10.545, state is 0.0019348332425579429, time/batch=-4.573\n",
      "Extract of training data : [10] [2639]\n",
      "466/16406, train loss is 10.546, state is -0.00032805048977024853, time/batch=-4.234\n",
      "Extract of training data : [1575] [50]\n",
      "467/16406, train loss is 10.546, state is -0.011942173354327679, time/batch=-4.313\n",
      "Extract of training data : [3] [873]\n",
      "468/16406, train loss is 10.546, state is 0.0013847565278410912, time/batch=-4.306\n",
      "Extract of training data : [16] [894]\n",
      "469/16406, train loss is 10.545, state is 0.0010058608604595065, time/batch=-4.130\n",
      "Extract of training data : [2398] [3515]\n",
      "470/16406, train loss is 10.546, state is -0.006398740224540234, time/batch=-4.505\n",
      "Extract of training data : [623] [8391]\n",
      "471/16406, train loss is 10.546, state is 0.0025621766690164804, time/batch=-4.247\n",
      "Extract of training data : [1131] [13365]\n",
      "472/16406, train loss is 10.545, state is 0.00017216427659150213, time/batch=-4.118\n",
      "Extract of training data : [174] [3383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473/16406, train loss is 10.545, state is 0.003580772550776601, time/batch=-4.136\n",
      "Extract of training data : [548] [2132]\n",
      "474/16406, train loss is 10.546, state is -0.014694707468152046, time/batch=-4.360\n",
      "Extract of training data : [6891] [16]\n",
      "475/16406, train loss is 10.545, state is -0.010125108063220978, time/batch=-4.248\n",
      "Extract of training data : [3749] [471]\n",
      "476/16406, train loss is 10.545, state is -0.00381552055478096, time/batch=-4.343\n",
      "Extract of training data : [35] [3211]\n",
      "477/16406, train loss is 10.546, state is 0.006127453409135342, time/batch=-4.361\n",
      "Extract of training data : [10] [413]\n",
      "478/16406, train loss is 10.546, state is -0.012405200861394405, time/batch=-4.154\n",
      "Extract of training data : [16] [0]\n",
      "479/16406, train loss is 10.546, state is -0.01591157168149948, time/batch=-4.107\n",
      "Extract of training data : [3732] [10]\n",
      "480/16406, train loss is 10.545, state is 0.003962880931794643, time/batch=-4.227\n",
      "Extract of training data : [1507] [10]\n",
      "481/16406, train loss is 10.546, state is -0.010031739249825478, time/batch=-4.314\n",
      "Extract of training data : [7183] [2051]\n",
      "482/16406, train loss is 10.546, state is 0.0006287692813202739, time/batch=-4.418\n",
      "Extract of training data : [174] [105]\n",
      "483/16406, train loss is 10.546, state is -0.014361893758177757, time/batch=-4.390\n",
      "Extract of training data : [10] [1741]\n",
      "484/16406, train loss is 10.546, state is 0.0006636774051003158, time/batch=-4.412\n",
      "Extract of training data : [20707] [10]\n",
      "485/16406, train loss is 10.546, state is 0.0024201509077101946, time/batch=-4.494\n",
      "Extract of training data : [164] [2159]\n",
      "486/16406, train loss is 10.545, state is 0.008516193367540836, time/batch=-4.392\n",
      "Extract of training data : [524] [624]\n",
      "487/16406, train loss is 10.546, state is -0.007929257117211819, time/batch=-4.309\n",
      "Extract of training data : [0] [3]\n",
      "488/16406, train loss is 10.545, state is -0.001982783665880561, time/batch=-4.366\n",
      "Extract of training data : [10] [557]\n",
      "489/16406, train loss is 10.546, state is -0.010041149333119392, time/batch=-4.270\n",
      "Extract of training data : [35] [2039]\n",
      "490/16406, train loss is 10.546, state is 0.00481748953461647, time/batch=-4.248\n",
      "Extract of training data : [7] [8]\n",
      "491/16406, train loss is 10.546, state is 0.001594429835677147, time/batch=-4.234\n",
      "Extract of training data : [10] [1825]\n",
      "492/16406, train loss is 10.546, state is -0.000919711368624121, time/batch=-4.245\n",
      "Extract of training data : [3024] [35]\n",
      "493/16406, train loss is 10.546, state is -0.003527172841131687, time/batch=-4.181\n",
      "Extract of training data : [583] [71]\n",
      "494/16406, train loss is 10.545, state is -0.001999092288315296, time/batch=-4.117\n",
      "Extract of training data : [1481] [804]\n",
      "495/16406, train loss is 10.546, state is 0.025248514488339424, time/batch=-4.241\n",
      "Extract of training data : [3] [29]\n",
      "496/16406, train loss is 10.546, state is 0.015088318847119808, time/batch=-4.331\n",
      "Extract of training data : [13960] [10]\n",
      "497/16406, train loss is 10.546, state is 0.012541168369352818, time/batch=-4.418\n",
      "Extract of training data : [19037] [5004]\n",
      "498/16406, train loss is 10.546, state is 0.009567022323608398, time/batch=-4.337\n",
      "Extract of training data : [545] [86]\n",
      "499/16406, train loss is 10.546, state is -0.01805434748530388, time/batch=-4.348\n",
      "Extract of training data : [10] [5157]\n",
      "500/16406, train loss is 10.545, state is -0.011524133384227753, time/batch=-4.276\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [458] [2304]\n",
      "501/16406, train loss is 10.545, state is -0.01187680009752512, time/batch=-4.650\n",
      "Extract of training data : [20] [3230]\n",
      "502/16406, train loss is 10.545, state is -0.0028956588357686996, time/batch=-4.398\n",
      "Extract of training data : [3] [3]\n",
      "503/16406, train loss is 10.546, state is 0.0012996059376746416, time/batch=-4.493\n",
      "Extract of training data : [6429] [35]\n",
      "504/16406, train loss is 10.546, state is -0.0053183538839221, time/batch=-4.494\n",
      "Extract of training data : [912] [1569]\n",
      "505/16406, train loss is 10.546, state is -0.016993805766105652, time/batch=-4.369\n",
      "Extract of training data : [33] [23035]\n",
      "506/16406, train loss is 10.546, state is 0.0030589685775339603, time/batch=-4.085\n",
      "Extract of training data : [1188] [29]\n",
      "507/16406, train loss is 10.546, state is -0.008455293253064156, time/batch=-4.271\n",
      "Extract of training data : [3208] [1185]\n",
      "508/16406, train loss is 10.546, state is 0.0023021860979497433, time/batch=-4.154\n",
      "Extract of training data : [2050] [2679]\n",
      "509/16406, train loss is 10.546, state is 0.013446938246488571, time/batch=-4.105\n",
      "Extract of training data : [0] [0]\n",
      "510/16406, train loss is 10.546, state is 0.00554271973669529, time/batch=-4.152\n",
      "Extract of training data : [6838] [2225]\n",
      "511/16406, train loss is 10.546, state is -0.009820827282965183, time/batch=-4.168\n",
      "Extract of training data : [3] [1085]\n",
      "512/16406, train loss is 10.546, state is -0.005599189084023237, time/batch=-4.142\n",
      "Extract of training data : [3] [3]\n",
      "513/16406, train loss is 10.545, state is -0.006237817462533712, time/batch=-4.120\n",
      "Extract of training data : [77] [105]\n",
      "514/16406, train loss is 10.546, state is 0.00939340889453888, time/batch=-4.159\n",
      "Extract of training data : [16] [846]\n",
      "515/16406, train loss is 10.546, state is 0.0027023879811167717, time/batch=-4.104\n",
      "Extract of training data : [6077] [10]\n",
      "516/16406, train loss is 10.546, state is 0.010784102603793144, time/batch=-4.173\n",
      "Extract of training data : [9927] [2492]\n",
      "517/16406, train loss is 10.545, state is -0.004596737679094076, time/batch=-4.128\n",
      "Extract of training data : [10563] [1699]\n",
      "518/16406, train loss is 10.546, state is -0.0068716974928975105, time/batch=-4.093\n",
      "Extract of training data : [2853] [6286]\n",
      "519/16406, train loss is 10.546, state is -0.008408264257013798, time/batch=-4.134\n",
      "Extract of training data : [21477] [23543]\n",
      "520/16406, train loss is 10.546, state is -0.0030953919049352407, time/batch=-4.113\n",
      "Extract of training data : [737] [10]\n",
      "521/16406, train loss is 10.546, state is -0.008528818376362324, time/batch=-4.088\n",
      "Extract of training data : [16] [12344]\n",
      "522/16406, train loss is 10.546, state is 0.0021011349745094776, time/batch=-4.114\n",
      "Extract of training data : [328] [1273]\n",
      "523/16406, train loss is 10.546, state is 0.004190689884126186, time/batch=-4.091\n",
      "Extract of training data : [2308] [6146]\n",
      "524/16406, train loss is 10.546, state is 0.002575047081336379, time/batch=-4.122\n",
      "Extract of training data : [196] [10]\n",
      "525/16406, train loss is 10.546, state is 0.015781832858920097, time/batch=-4.162\n",
      "Extract of training data : [61] [1780]\n",
      "526/16406, train loss is 10.546, state is 0.008311795070767403, time/batch=-4.156\n",
      "Extract of training data : [0] [3]\n",
      "527/16406, train loss is 10.546, state is -0.009542044252157211, time/batch=-4.112\n",
      "Extract of training data : [5356] [10]\n",
      "528/16406, train loss is 10.546, state is -0.01846333034336567, time/batch=-4.169\n",
      "Extract of training data : [37560] [10]\n",
      "529/16406, train loss is 10.546, state is 0.010719235055148602, time/batch=-4.228\n",
      "Extract of training data : [35] [24863]\n",
      "530/16406, train loss is 10.546, state is -0.0034398287534713745, time/batch=-4.237\n",
      "Extract of training data : [3] [23535]\n",
      "531/16406, train loss is 10.546, state is 0.0017098269890993834, time/batch=-4.150\n",
      "Extract of training data : [10] [1165]\n",
      "532/16406, train loss is 10.546, state is 0.006481895688921213, time/batch=-4.088\n",
      "Extract of training data : [13159] [5930]\n",
      "533/16406, train loss is 10.546, state is 0.0018918124260380864, time/batch=-4.150\n",
      "Extract of training data : [3197] [23950]\n",
      "534/16406, train loss is 10.546, state is 0.008911952376365662, time/batch=-4.122\n",
      "Extract of training data : [2404] [3270]\n",
      "535/16406, train loss is 10.546, state is 0.00042260659392923117, time/batch=-4.197\n",
      "Extract of training data : [850] [1481]\n",
      "536/16406, train loss is 10.546, state is -0.004215030465275049, time/batch=-4.142\n",
      "Extract of training data : [18303] [1]\n",
      "537/16406, train loss is 10.546, state is 0.0021554394625127316, time/batch=-4.125\n",
      "Extract of training data : [280] [422]\n",
      "538/16406, train loss is 10.546, state is -0.0022000721655786037, time/batch=-4.148\n",
      "Extract of training data : [3] [3]\n",
      "539/16406, train loss is 10.546, state is -0.012487808242440224, time/batch=-4.112\n",
      "Extract of training data : [10] [3125]\n",
      "540/16406, train loss is 10.546, state is 0.003971627447754145, time/batch=-4.137\n",
      "Extract of training data : [10177] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/16406, train loss is 10.546, state is -0.016256973147392273, time/batch=-4.112\n",
      "Extract of training data : [29] [5880]\n",
      "542/16406, train loss is 10.546, state is -0.010176138952374458, time/batch=-4.199\n",
      "Extract of training data : [35] [1293]\n",
      "543/16406, train loss is 10.546, state is -0.0024084928445518017, time/batch=-4.270\n",
      "Extract of training data : [2883] [51]\n",
      "544/16406, train loss is 10.546, state is -0.0006876033148728311, time/batch=-4.166\n",
      "Extract of training data : [3] [3]\n",
      "545/16406, train loss is 10.546, state is 0.00396078871563077, time/batch=-4.136\n",
      "Extract of training data : [4281] [1483]\n",
      "546/16406, train loss is 10.545, state is -0.0018423872534185648, time/batch=-4.160\n",
      "Extract of training data : [1293] [26201]\n",
      "547/16406, train loss is 10.546, state is 0.0016292735235765576, time/batch=-4.107\n",
      "Extract of training data : [2597] [10]\n",
      "548/16406, train loss is 10.546, state is -0.013925133273005486, time/batch=-4.205\n",
      "Extract of training data : [21] [17647]\n",
      "549/16406, train loss is 10.546, state is -0.009808552451431751, time/batch=-4.154\n",
      "Extract of training data : [13628] [12]\n",
      "550/16406, train loss is 10.546, state is 0.01280942466109991, time/batch=-4.118\n",
      "Extract of training data : [5313] [105]\n",
      "551/16406, train loss is 10.546, state is -0.01368027739226818, time/batch=-4.213\n",
      "Extract of training data : [3] [3]\n",
      "552/16406, train loss is 10.546, state is 0.0022226539440453053, time/batch=-4.115\n",
      "Extract of training data : [0] [3]\n",
      "553/16406, train loss is 10.546, state is 0.005502075422555208, time/batch=-4.142\n",
      "Extract of training data : [737] [35]\n",
      "554/16406, train loss is 10.546, state is 0.0037414671387523413, time/batch=-4.114\n",
      "Extract of training data : [21] [1171]\n",
      "555/16406, train loss is 10.546, state is 0.009014569222927094, time/batch=-4.278\n",
      "Extract of training data : [10] [344]\n",
      "556/16406, train loss is 10.546, state is 0.0015534533886238933, time/batch=-4.591\n",
      "Extract of training data : [3414] [16]\n",
      "557/16406, train loss is 10.546, state is 0.005061393603682518, time/batch=-4.252\n",
      "Extract of training data : [2341] [7289]\n",
      "558/16406, train loss is 10.545, state is 0.00564809562638402, time/batch=-4.294\n",
      "Extract of training data : [0] [0]\n",
      "559/16406, train loss is 10.546, state is 0.0031388066709041595, time/batch=-4.194\n",
      "Extract of training data : [6485] [2970]\n",
      "560/16406, train loss is 10.545, state is 0.0030108275823295116, time/batch=-4.237\n",
      "Extract of training data : [8] [277]\n",
      "561/16406, train loss is 10.546, state is -0.006528761703521013, time/batch=-4.108\n",
      "Extract of training data : [10] [159]\n",
      "562/16406, train loss is 10.545, state is -0.011108706705272198, time/batch=-4.091\n",
      "Extract of training data : [458] [15872]\n",
      "563/16406, train loss is 10.545, state is 0.0138628501445055, time/batch=-4.107\n",
      "Extract of training data : [422] [143]\n",
      "564/16406, train loss is 10.545, state is -0.02462073601782322, time/batch=-4.100\n",
      "Extract of training data : [7539] [27618]\n",
      "565/16406, train loss is 10.546, state is -0.02253490872681141, time/batch=-4.139\n",
      "Extract of training data : [10] [901]\n",
      "566/16406, train loss is 10.545, state is -0.0015079618897289038, time/batch=-4.100\n",
      "Extract of training data : [1087] [237]\n",
      "567/16406, train loss is 10.545, state is -0.001112168887630105, time/batch=-4.110\n",
      "Extract of training data : [6528] [1220]\n",
      "568/16406, train loss is 10.545, state is -0.019249795004725456, time/batch=-4.098\n",
      "Extract of training data : [1180] [10]\n",
      "569/16406, train loss is 10.546, state is 0.0038329854141920805, time/batch=-4.117\n",
      "Extract of training data : [10] [50]\n",
      "570/16406, train loss is 10.546, state is -0.006615308579057455, time/batch=-4.120\n",
      "Extract of training data : [19388] [51]\n",
      "571/16406, train loss is 10.546, state is 0.0087824622169137, time/batch=-4.161\n",
      "Extract of training data : [1946] [2612]\n",
      "572/16406, train loss is 10.546, state is 0.002690482186153531, time/batch=-4.146\n",
      "Extract of training data : [2300] [10]\n",
      "573/16406, train loss is 10.546, state is -0.0005490605253726244, time/batch=-4.229\n",
      "Extract of training data : [105] [715]\n",
      "574/16406, train loss is 10.546, state is 0.006783760152757168, time/batch=-4.245\n",
      "Extract of training data : [10] [28405]\n",
      "575/16406, train loss is 10.546, state is 0.00923440046608448, time/batch=-4.174\n",
      "Extract of training data : [29] [28482]\n",
      "576/16406, train loss is 10.545, state is -0.011513189412653446, time/batch=-4.143\n",
      "Extract of training data : [71] [5777]\n",
      "577/16406, train loss is 10.546, state is -0.00015173100109677762, time/batch=-4.108\n",
      "Extract of training data : [1185] [29]\n",
      "578/16406, train loss is 10.545, state is -0.005637248512357473, time/batch=-4.179\n",
      "Extract of training data : [105] [850]\n",
      "579/16406, train loss is 10.546, state is 0.002486602170392871, time/batch=-4.107\n",
      "Extract of training data : [9745] [4441]\n",
      "580/16406, train loss is 10.545, state is -0.01023935154080391, time/batch=-4.102\n",
      "Extract of training data : [3154] [2844]\n",
      "581/16406, train loss is 10.546, state is 0.014548239298164845, time/batch=-4.113\n",
      "Extract of training data : [16] [1785]\n",
      "582/16406, train loss is 10.545, state is -0.009919741190969944, time/batch=-4.195\n",
      "Extract of training data : [688] [1846]\n",
      "583/16406, train loss is 10.546, state is -0.011926905252039433, time/batch=-4.306\n",
      "Extract of training data : [1599] [6409]\n",
      "584/16406, train loss is 10.546, state is 0.010678739286959171, time/batch=-4.098\n",
      "Extract of training data : [10886] [10]\n",
      "585/16406, train loss is 10.546, state is -0.009289628826081753, time/batch=-4.312\n",
      "Extract of training data : [1507] [10]\n",
      "586/16406, train loss is 10.546, state is 0.008330798707902431, time/batch=-4.516\n",
      "Extract of training data : [2182] [3404]\n",
      "587/16406, train loss is 10.546, state is -0.006118223071098328, time/batch=-4.457\n",
      "Extract of training data : [1821] [51]\n",
      "588/16406, train loss is 10.546, state is -0.014374040998518467, time/batch=-4.182\n",
      "Extract of training data : [10] [2910]\n",
      "589/16406, train loss is 10.546, state is -0.0009416656102985144, time/batch=-4.122\n",
      "Extract of training data : [28963] [3743]\n",
      "590/16406, train loss is 10.545, state is -0.012144183740019798, time/batch=-4.155\n",
      "Extract of training data : [29174] [35]\n",
      "591/16406, train loss is 10.546, state is 0.0031979915220290422, time/batch=-4.151\n",
      "Extract of training data : [3203] [10]\n",
      "592/16406, train loss is 10.545, state is 0.0031799646094441414, time/batch=-4.646\n",
      "Extract of training data : [16878] [35]\n",
      "593/16406, train loss is 10.545, state is 0.0058794766664505005, time/batch=-4.160\n",
      "Extract of training data : [1081] [5124]\n",
      "594/16406, train loss is 10.546, state is -0.01836451143026352, time/batch=-4.102\n",
      "Extract of training data : [3980] [2679]\n",
      "595/16406, train loss is 10.545, state is 0.0080353282392025, time/batch=-4.112\n",
      "Extract of training data : [3] [5168]\n",
      "596/16406, train loss is 10.546, state is 0.0003987153177149594, time/batch=-4.153\n",
      "Extract of training data : [10] [344]\n",
      "597/16406, train loss is 10.546, state is 0.00893367175012827, time/batch=-2044.238\n",
      "Extract of training data : [571] [6997]\n",
      "598/16406, train loss is 10.546, state is 0.0122043676674366, time/batch=-4.491\n",
      "Extract of training data : [10] [571]\n",
      "599/16406, train loss is 10.546, state is 0.012728283181786537, time/batch=-14.608\n",
      "Extract of training data : [910] [963]\n",
      "600/16406, train loss is 10.546, state is -0.0021537868306040764, time/batch=-4.703\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1051] [8]\n",
      "601/16406, train loss is 10.546, state is 0.004745887592434883, time/batch=-4.525\n",
      "Extract of training data : [2913] [16549]\n",
      "602/16406, train loss is 10.545, state is 0.007783267181366682, time/batch=-1580.168\n",
      "Extract of training data : [29715] [32]\n",
      "603/16406, train loss is 10.545, state is 0.004639059770852327, time/batch=-4.303\n",
      "Extract of training data : [10] [688]\n",
      "604/16406, train loss is 10.546, state is -0.0031460104510188103, time/batch=-4.071\n",
      "Extract of training data : [3] [3]\n",
      "605/16406, train loss is 10.546, state is -0.0029283887706696987, time/batch=-14.280\n",
      "Extract of training data : [10] [633]\n",
      "606/16406, train loss is 10.546, state is -0.01173478364944458, time/batch=-4.248\n",
      "Extract of training data : [3] [291]\n",
      "607/16406, train loss is 10.545, state is -0.01649087853729725, time/batch=-4.129\n",
      "Extract of training data : [3055] [71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608/16406, train loss is 10.546, state is 0.010913657024502754, time/batch=-4.099\n",
      "Extract of training data : [10] [9562]\n",
      "609/16406, train loss is 10.546, state is -0.008633296936750412, time/batch=-617.881\n",
      "Extract of training data : [9027] [10]\n",
      "610/16406, train loss is 10.545, state is -0.001837227726355195, time/batch=-6.178\n",
      "Extract of training data : [5507] [4610]\n",
      "611/16406, train loss is 10.545, state is 0.019485604017972946, time/batch=-6.933\n",
      "Extract of training data : [105] [1078]\n",
      "612/16406, train loss is 10.546, state is -0.002664069179445505, time/batch=-6.338\n",
      "Extract of training data : [0] [0]\n",
      "613/16406, train loss is 10.546, state is -0.00091306131798774, time/batch=-7.588\n",
      "Extract of training data : [1366] [1553]\n",
      "614/16406, train loss is 10.545, state is -0.016388721764087677, time/batch=-7.955\n",
      "Extract of training data : [8] [277]\n",
      "615/16406, train loss is 10.545, state is -0.014265654608607292, time/batch=-7.012\n",
      "Extract of training data : [11486] [10]\n",
      "616/16406, train loss is 10.545, state is -0.014208431355655193, time/batch=-5.488\n",
      "Extract of training data : [3] [20583]\n",
      "617/16406, train loss is 10.545, state is 0.008895602077245712, time/batch=-5.151\n",
      "Extract of training data : [378] [720]\n",
      "618/16406, train loss is 10.545, state is -0.01388834323734045, time/batch=-6.457\n",
      "Extract of training data : [46] [22852]\n",
      "619/16406, train loss is 10.545, state is 0.004868092946708202, time/batch=-4.418\n",
      "Extract of training data : [3493] [35]\n",
      "620/16406, train loss is 10.545, state is -0.006126058287918568, time/batch=-4.381\n",
      "Extract of training data : [3] [20583]\n",
      "621/16406, train loss is 10.545, state is 0.01743476465344429, time/batch=-5.008\n",
      "Extract of training data : [10987] [105]\n",
      "622/16406, train loss is 10.545, state is -0.0202338844537735, time/batch=-5.240\n",
      "Extract of training data : [7001] [29526]\n",
      "623/16406, train loss is 10.545, state is -0.0003228276618756354, time/batch=-5.170\n",
      "Extract of training data : [7166] [12]\n",
      "624/16406, train loss is 10.545, state is -0.004601106513291597, time/batch=-5.105\n",
      "Extract of training data : [12524] [174]\n",
      "625/16406, train loss is 10.546, state is 0.008679439313709736, time/batch=-4.601\n",
      "Extract of training data : [3524] [1256]\n",
      "626/16406, train loss is 10.546, state is -0.0008091233321465552, time/batch=-4.837\n",
      "Extract of training data : [55] [174]\n",
      "627/16406, train loss is 10.546, state is -0.0033280756324529648, time/batch=-4.772\n",
      "Extract of training data : [1636] [10]\n",
      "628/16406, train loss is 10.545, state is -0.0012543214252218604, time/batch=-4.825\n",
      "Extract of training data : [31476] [10]\n",
      "629/16406, train loss is 10.545, state is -0.012147797271609306, time/batch=-4.694\n",
      "Extract of training data : [3] [3]\n",
      "630/16406, train loss is 10.545, state is -0.01106482744216919, time/batch=-4.668\n",
      "Extract of training data : [12] [150]\n",
      "631/16406, train loss is 10.546, state is -0.011083731427788734, time/batch=-5.069\n",
      "Extract of training data : [60] [6578]\n",
      "632/16406, train loss is 10.546, state is -0.003065172815695405, time/batch=-5.430\n",
      "Extract of training data : [3] [3]\n",
      "633/16406, train loss is 10.546, state is -0.014126492664217949, time/batch=-5.404\n",
      "Extract of training data : [8837] [10]\n",
      "634/16406, train loss is 10.546, state is 0.009686185047030449, time/batch=-5.268\n",
      "Extract of training data : [8467] [2704]\n",
      "635/16406, train loss is 10.546, state is -0.035365693271160126, time/batch=-5.324\n",
      "Extract of training data : [31897] [2159]\n",
      "636/16406, train loss is 10.546, state is -0.020160213112831116, time/batch=-5.194\n",
      "Extract of training data : [3] [31950]\n",
      "637/16406, train loss is 10.545, state is -0.00816623866558075, time/batch=-5.262\n",
      "Extract of training data : [1006] [1769]\n",
      "638/16406, train loss is 10.545, state is 4.985529085388407e-05, time/batch=-5.092\n",
      "Extract of training data : [301] [10]\n",
      "639/16406, train loss is 10.546, state is -0.007312382105737925, time/batch=-5.063\n",
      "Extract of training data : [50] [71]\n",
      "640/16406, train loss is 10.546, state is 0.0022983206436038017, time/batch=-5.029\n",
      "Extract of training data : [10] [588]\n",
      "641/16406, train loss is 10.545, state is 0.02370678074657917, time/batch=-5.053\n",
      "Extract of training data : [0] [0]\n",
      "642/16406, train loss is 10.546, state is -0.011429151520133018, time/batch=-5.052\n",
      "Extract of training data : [413] [4118]\n",
      "643/16406, train loss is 10.545, state is -0.011292128823697567, time/batch=-5.144\n",
      "Extract of training data : [1273] [51]\n",
      "644/16406, train loss is 10.546, state is -0.0006034210091456771, time/batch=-4.965\n",
      "Extract of training data : [8] [277]\n",
      "645/16406, train loss is 10.546, state is -0.006502967793494463, time/batch=-5.053\n",
      "Extract of training data : [2946] [544]\n",
      "646/16406, train loss is 10.546, state is -0.009426411241292953, time/batch=-5.002\n",
      "Extract of training data : [10] [1190]\n",
      "647/16406, train loss is 10.546, state is -0.0047447835095226765, time/batch=-5.056\n",
      "Extract of training data : [24694] [19548]\n",
      "648/16406, train loss is 10.545, state is -0.004500968847423792, time/batch=-5.066\n",
      "Extract of training data : [8725] [105]\n",
      "649/16406, train loss is 10.545, state is 0.007668078411370516, time/batch=-5.060\n",
      "Extract of training data : [2075] [105]\n",
      "650/16406, train loss is 10.545, state is 0.00787117425352335, time/batch=-4.963\n",
      "Extract of training data : [1575] [5137]\n",
      "651/16406, train loss is 10.545, state is 0.002752172527834773, time/batch=-4.954\n",
      "Extract of training data : [10] [9645]\n",
      "652/16406, train loss is 10.546, state is -0.006335888989269733, time/batch=-5.148\n",
      "Extract of training data : [6531] [51]\n",
      "653/16406, train loss is 10.546, state is -0.012910652905702591, time/batch=-4.918\n",
      "Extract of training data : [3] [3]\n",
      "654/16406, train loss is 10.546, state is 0.01829640194773674, time/batch=-5.099\n",
      "Extract of training data : [5284] [21127]\n",
      "655/16406, train loss is 10.546, state is 0.005359960719943047, time/batch=-4.945\n",
      "Extract of training data : [873] [2105]\n",
      "656/16406, train loss is 10.546, state is 0.00538655323907733, time/batch=-4.919\n",
      "Extract of training data : [35] [277]\n",
      "657/16406, train loss is 10.546, state is -0.0023165990132838488, time/batch=-5.049\n",
      "Extract of training data : [3610] [0]\n",
      "658/16406, train loss is 10.545, state is 0.010919641703367233, time/batch=-4.964\n",
      "Extract of training data : [1507] [631]\n",
      "659/16406, train loss is 10.545, state is 0.00011647355131572112, time/batch=-4.953\n",
      "Extract of training data : [1207] [105]\n",
      "660/16406, train loss is 10.545, state is 0.0038861341308802366, time/batch=-4.958\n",
      "Extract of training data : [280] [0]\n",
      "661/16406, train loss is 10.545, state is -0.021327301859855652, time/batch=-4.853\n",
      "Extract of training data : [32906] [3758]\n",
      "662/16406, train loss is 10.545, state is 0.0034648918081074953, time/batch=-4.999\n",
      "Extract of training data : [35] [2633]\n",
      "663/16406, train loss is 10.546, state is 0.003163686254993081, time/batch=-4.935\n",
      "Extract of training data : [3] [8821]\n",
      "664/16406, train loss is 10.546, state is -0.015421727672219276, time/batch=-4.936\n",
      "Extract of training data : [3] [3]\n",
      "665/16406, train loss is 10.545, state is -0.00518085528165102, time/batch=-4.912\n",
      "Extract of training data : [0] [3]\n",
      "666/16406, train loss is 10.546, state is 0.005338555201888084, time/batch=-4.957\n",
      "Extract of training data : [12284] [29]\n",
      "667/16406, train loss is 10.546, state is -0.0116635262966156, time/batch=-4.969\n",
      "Extract of training data : [13192] [0]\n",
      "668/16406, train loss is 10.546, state is 0.0011426208075135946, time/batch=-4.933\n",
      "Extract of training data : [1572] [35]\n",
      "669/16406, train loss is 10.546, state is -0.00038682378362864256, time/batch=-5.052\n",
      "Extract of training data : [9822] [10]\n",
      "670/16406, train loss is 10.546, state is -0.0015894329408183694, time/batch=-4.952\n",
      "Extract of training data : [0] [0]\n",
      "671/16406, train loss is 10.546, state is -0.0015260863583534956, time/batch=-4.937\n",
      "Extract of training data : [35] [16632]\n",
      "672/16406, train loss is 10.546, state is 0.006344159599393606, time/batch=-4.962\n",
      "Extract of training data : [6929] [10]\n",
      "673/16406, train loss is 10.546, state is -0.0388193354010582, time/batch=-5.021\n",
      "Extract of training data : [2985] [2892]\n",
      "674/16406, train loss is 10.546, state is -0.00983317568898201, time/batch=-4.941\n",
      "Extract of training data : [561] [882]\n",
      "675/16406, train loss is 10.545, state is -0.0163645651191473, time/batch=-4.962\n",
      "Extract of training data : [5654] [35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/16406, train loss is 10.545, state is -0.01861458644270897, time/batch=-5.038\n",
      "Extract of training data : [10] [783]\n",
      "677/16406, train loss is 10.545, state is 0.006463649217039347, time/batch=-4.898\n",
      "Extract of training data : [1017] [1988]\n",
      "678/16406, train loss is 10.545, state is 0.0001381499314447865, time/batch=-5.045\n",
      "Extract of training data : [3367] [1079]\n",
      "679/16406, train loss is 10.545, state is 0.016570990905165672, time/batch=-4.932\n",
      "Extract of training data : [18518] [378]\n",
      "680/16406, train loss is 10.545, state is -0.00593913160264492, time/batch=-4.969\n",
      "Extract of training data : [35] [3127]\n",
      "681/16406, train loss is 10.545, state is 0.008222317323088646, time/batch=-4.908\n",
      "Extract of training data : [10] [1477]\n",
      "682/16406, train loss is 10.545, state is -0.017539221793413162, time/batch=-4.968\n",
      "Extract of training data : [5067] [35]\n",
      "683/16406, train loss is 10.546, state is 0.008045691065490246, time/batch=-5.025\n",
      "Extract of training data : [3] [3]\n",
      "684/16406, train loss is 10.546, state is -0.011134590022265911, time/batch=-4.902\n",
      "Extract of training data : [3] [3]\n",
      "685/16406, train loss is 10.545, state is -0.0013261535204946995, time/batch=-4.897\n",
      "Extract of training data : [105] [10]\n",
      "686/16406, train loss is 10.545, state is 0.005717557854950428, time/batch=-4.919\n",
      "Extract of training data : [12504] [29]\n",
      "687/16406, train loss is 10.545, state is -0.024307511746883392, time/batch=-4.902\n",
      "Extract of training data : [20583] [2791]\n",
      "688/16406, train loss is 10.545, state is -0.0010319435968995094, time/batch=-4.872\n",
      "Extract of training data : [13349] [413]\n",
      "689/16406, train loss is 10.546, state is 0.007977865636348724, time/batch=-4.976\n",
      "Extract of training data : [29] [6899]\n",
      "690/16406, train loss is 10.545, state is 0.012062881141901016, time/batch=-4.909\n",
      "Extract of training data : [1180] [10]\n",
      "691/16406, train loss is 10.545, state is -0.0062864082865417, time/batch=-4.874\n",
      "Extract of training data : [11] [2923]\n",
      "692/16406, train loss is 10.545, state is -0.0002488106256350875, time/batch=-4.877\n",
      "Extract of training data : [675] [3904]\n",
      "693/16406, train loss is 10.545, state is -0.009431895799934864, time/batch=-4.930\n",
      "Extract of training data : [10] [2050]\n",
      "694/16406, train loss is 10.546, state is -0.010508817620575428, time/batch=-5.082\n",
      "Extract of training data : [2063] [2311]\n",
      "695/16406, train loss is 10.546, state is 0.011697519570589066, time/batch=-4.891\n",
      "Extract of training data : [3] [7243]\n",
      "696/16406, train loss is 10.545, state is 0.002295283367857337, time/batch=-4.911\n",
      "Extract of training data : [16717] [327]\n",
      "697/16406, train loss is 10.546, state is -0.009998932480812073, time/batch=-4.952\n",
      "Extract of training data : [34576] [1182]\n",
      "698/16406, train loss is 10.546, state is -0.00867338664829731, time/batch=-4.906\n",
      "Extract of training data : [6286] [2398]\n",
      "699/16406, train loss is 10.545, state is 0.01203810703009367, time/batch=-4.944\n",
      "Extract of training data : [10] [439]\n",
      "700/16406, train loss is 10.545, state is -0.0009164625080302358, time/batch=-4.851\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1529] [10]\n",
      "701/16406, train loss is 10.546, state is 0.009730976074934006, time/batch=-5.090\n",
      "Extract of training data : [916] [920]\n",
      "702/16406, train loss is 10.545, state is -0.012612531892955303, time/batch=-5.003\n",
      "Extract of training data : [15508] [3104]\n",
      "703/16406, train loss is 10.546, state is -0.02032272145152092, time/batch=-4.927\n",
      "Extract of training data : [0] [0]\n",
      "704/16406, train loss is 10.546, state is 0.0020999773405492306, time/batch=-4.914\n",
      "Extract of training data : [592] [1134]\n",
      "705/16406, train loss is 10.545, state is 0.02046218514442444, time/batch=-4.913\n",
      "Extract of training data : [10] [4266]\n",
      "706/16406, train loss is 10.545, state is -0.0041428618133068085, time/batch=-4.908\n",
      "Extract of training data : [4990] [46]\n",
      "707/16406, train loss is 10.546, state is -0.014444615691900253, time/batch=-4.916\n",
      "Extract of training data : [23] [3758]\n",
      "708/16406, train loss is 10.545, state is 0.007996040396392345, time/batch=-4.902\n",
      "Extract of training data : [105] [1661]\n",
      "709/16406, train loss is 10.546, state is 0.014692520722746849, time/batch=-4.934\n",
      "Extract of training data : [12] [1273]\n",
      "710/16406, train loss is 10.546, state is 0.006051812320947647, time/batch=-4.936\n",
      "Extract of training data : [2925] [13914]\n",
      "711/16406, train loss is 10.546, state is -0.003256151918321848, time/batch=-4.861\n",
      "Extract of training data : [413] [71]\n",
      "712/16406, train loss is 10.546, state is -0.007867022417485714, time/batch=-4.923\n",
      "Extract of training data : [877] [280]\n",
      "713/16406, train loss is 10.545, state is 0.011587855406105518, time/batch=-4.866\n",
      "Extract of training data : [8539] [35]\n",
      "714/16406, train loss is 10.546, state is -0.00046485502389259636, time/batch=-4.855\n",
      "Extract of training data : [35565] [35566]\n",
      "715/16406, train loss is 10.545, state is 0.00623356644064188, time/batch=-4.942\n",
      "Extract of training data : [1515] [10]\n",
      "716/16406, train loss is 10.545, state is -0.012439814396202564, time/batch=-4.879\n",
      "Extract of training data : [20818] [127]\n",
      "717/16406, train loss is 10.545, state is 0.002185635268688202, time/batch=-4.912\n",
      "Extract of training data : [1636] [10]\n",
      "718/16406, train loss is 10.545, state is -0.004553989972919226, time/batch=-4.965\n",
      "Extract of training data : [4143] [34218]\n",
      "719/16406, train loss is 10.546, state is -0.013060009106993675, time/batch=-5.002\n",
      "Extract of training data : [190] [555]\n",
      "720/16406, train loss is 10.545, state is 0.005026515107601881, time/batch=-4.949\n",
      "Extract of training data : [4765] [10]\n",
      "721/16406, train loss is 10.546, state is 0.0022110973950475454, time/batch=-4.868\n",
      "Extract of training data : [0] [0]\n",
      "722/16406, train loss is 10.545, state is -0.0024830454494804144, time/batch=-4.922\n",
      "Extract of training data : [1014] [17764]\n",
      "723/16406, train loss is 10.546, state is 0.00021651192218996584, time/batch=-4.942\n",
      "Extract of training data : [6873] [2813]\n",
      "724/16406, train loss is 10.545, state is 0.004628794267773628, time/batch=-4.970\n",
      "Extract of training data : [2076] [633]\n",
      "725/16406, train loss is 10.545, state is -0.0019414351554587483, time/batch=-4.896\n",
      "Extract of training data : [1507] [10]\n",
      "726/16406, train loss is 10.546, state is -0.010455025359988213, time/batch=-4.891\n",
      "Extract of training data : [3] [3]\n",
      "727/16406, train loss is 10.545, state is -0.003397571388632059, time/batch=-4.906\n",
      "Extract of training data : [4945] [499]\n",
      "728/16406, train loss is 10.545, state is 0.008712349459528923, time/batch=-4.899\n",
      "Extract of training data : [1675] [4162]\n",
      "729/16406, train loss is 10.546, state is -0.024707717821002007, time/batch=-4.878\n",
      "Extract of training data : [1386] [0]\n",
      "730/16406, train loss is 10.545, state is -0.007512431591749191, time/batch=-4.901\n",
      "Extract of training data : [2633] [906]\n",
      "731/16406, train loss is 10.546, state is -0.016179794445633888, time/batch=-4.961\n",
      "Extract of training data : [422] [35]\n",
      "732/16406, train loss is 10.546, state is -0.019355246797204018, time/batch=-4.876\n",
      "Extract of training data : [176] [7949]\n",
      "733/16406, train loss is 10.545, state is 0.008895439095795155, time/batch=-4.923\n",
      "Extract of training data : [51] [106]\n",
      "734/16406, train loss is 10.546, state is -0.009298210963606834, time/batch=-4.943\n",
      "Extract of training data : [3] [277]\n",
      "735/16406, train loss is 10.545, state is 0.0036600674502551556, time/batch=-4.922\n",
      "Extract of training data : [10] [3485]\n",
      "736/16406, train loss is 10.545, state is 0.005481223110109568, time/batch=-4.874\n",
      "Extract of training data : [105] [910]\n",
      "737/16406, train loss is 10.545, state is -0.0073976884596049786, time/batch=-4.929\n",
      "Extract of training data : [2119] [10]\n",
      "738/16406, train loss is 10.546, state is 0.0050607468001544476, time/batch=-4.923\n",
      "Extract of training data : [28829] [2007]\n",
      "739/16406, train loss is 10.546, state is 0.0009735851781442761, time/batch=-4.896\n",
      "Extract of training data : [0] [3]\n",
      "740/16406, train loss is 10.545, state is 0.009570901282131672, time/batch=-4.878\n",
      "Extract of training data : [0] [3]\n",
      "741/16406, train loss is 10.545, state is 0.002897409023717046, time/batch=-4.910\n",
      "Extract of training data : [3] [3]\n",
      "742/16406, train loss is 10.546, state is -0.006604486145079136, time/batch=-4.931\n",
      "Extract of training data : [3] [3]\n",
      "743/16406, train loss is 10.546, state is -0.015059249475598335, time/batch=-4.944\n",
      "Extract of training data : [9167] [12915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744/16406, train loss is 10.545, state is -0.005648376885801554, time/batch=-4.954\n",
      "Extract of training data : [0] [1]\n",
      "745/16406, train loss is 10.545, state is -0.0044733574613928795, time/batch=-4.895\n",
      "Extract of training data : [883] [10]\n",
      "746/16406, train loss is 10.545, state is -0.021404201164841652, time/batch=-4.943\n",
      "Extract of training data : [277] [1137]\n",
      "747/16406, train loss is 10.545, state is -0.004695568699389696, time/batch=-4.902\n",
      "Extract of training data : [3] [3]\n",
      "748/16406, train loss is 10.545, state is -0.0010061119683086872, time/batch=-4.934\n",
      "Extract of training data : [1935] [422]\n",
      "749/16406, train loss is 10.546, state is -0.023029591888189316, time/batch=-4.915\n",
      "Extract of training data : [2605] [359]\n",
      "750/16406, train loss is 10.545, state is -0.00988466665148735, time/batch=-4.910\n",
      "Extract of training data : [3516] [14]\n",
      "751/16406, train loss is 10.545, state is -0.022142594680190086, time/batch=-4.906\n",
      "Extract of training data : [3516] [3701]\n",
      "752/16406, train loss is 10.546, state is 0.016209742054343224, time/batch=-4.893\n",
      "Extract of training data : [359] [804]\n",
      "753/16406, train loss is 10.545, state is 0.009600860066711903, time/batch=-4.865\n",
      "Extract of training data : [806] [105]\n",
      "754/16406, train loss is 10.545, state is -0.006050491705536842, time/batch=-4.883\n",
      "Extract of training data : [4868] [105]\n",
      "755/16406, train loss is 10.545, state is 0.009009649977087975, time/batch=-4.947\n",
      "Extract of training data : [10] [2854]\n",
      "756/16406, train loss is 10.545, state is -0.018926337361335754, time/batch=-4.898\n",
      "Extract of training data : [3] [1021]\n",
      "757/16406, train loss is 10.545, state is -0.019610639661550522, time/batch=-4.847\n",
      "Extract of training data : [10] [5860]\n",
      "758/16406, train loss is 10.545, state is 0.016460902988910675, time/batch=-4.831\n",
      "Extract of training data : [3] [292]\n",
      "759/16406, train loss is 10.545, state is 0.0010569465812295675, time/batch=-4.920\n",
      "Extract of training data : [6327] [811]\n",
      "760/16406, train loss is 10.545, state is 0.0064763836562633514, time/batch=-4.881\n",
      "Extract of training data : [291] [643]\n",
      "761/16406, train loss is 10.545, state is 0.0017881820676848292, time/batch=-4.833\n",
      "Extract of training data : [413] [876]\n",
      "762/16406, train loss is 10.545, state is 0.011829150840640068, time/batch=-4.946\n",
      "Extract of training data : [1056] [7122]\n",
      "763/16406, train loss is 10.545, state is -0.008585824631154537, time/batch=-4.923\n",
      "Extract of training data : [25] [1437]\n",
      "764/16406, train loss is 10.546, state is -0.021565953269600868, time/batch=-4.921\n",
      "Extract of training data : [2141] [28]\n",
      "765/16406, train loss is 10.545, state is -0.011277369223535061, time/batch=-4.925\n",
      "Extract of training data : [559] [71]\n",
      "766/16406, train loss is 10.545, state is -0.011220208369195461, time/batch=-4.861\n",
      "Extract of training data : [3] [3]\n",
      "767/16406, train loss is 10.545, state is -0.00892542488873005, time/batch=-4.872\n",
      "Extract of training data : [110] [10]\n",
      "768/16406, train loss is 10.545, state is -0.002315860241651535, time/batch=-4.947\n",
      "Extract of training data : [8197] [16]\n",
      "769/16406, train loss is 10.545, state is 0.0010711046634241939, time/batch=-4.898\n",
      "Extract of training data : [6749] [8411]\n",
      "770/16406, train loss is 10.545, state is -0.017882555723190308, time/batch=-4.898\n",
      "Extract of training data : [8606] [1220]\n",
      "771/16406, train loss is 10.545, state is 0.00994658563286066, time/batch=-4.891\n",
      "Extract of training data : [3] [699]\n",
      "772/16406, train loss is 10.546, state is -0.005166932474821806, time/batch=-4.887\n",
      "Extract of training data : [277] [4505]\n",
      "773/16406, train loss is 10.545, state is -0.0030309646390378475, time/batch=-4.977\n",
      "Extract of training data : [3] [422]\n",
      "774/16406, train loss is 10.545, state is -0.012387212365865707, time/batch=-4.962\n",
      "Extract of training data : [3552] [3553]\n",
      "775/16406, train loss is 10.546, state is -0.0010731220245361328, time/batch=-4.923\n",
      "Extract of training data : [9380] [51]\n",
      "776/16406, train loss is 10.545, state is 0.0007960355142131448, time/batch=-4.871\n",
      "Extract of training data : [35] [2404]\n",
      "777/16406, train loss is 10.546, state is -0.004014960490167141, time/batch=-4.924\n",
      "Extract of training data : [3327] [2586]\n",
      "778/16406, train loss is 10.545, state is 0.008858218789100647, time/batch=-4.896\n",
      "Extract of training data : [10] [3366]\n",
      "779/16406, train loss is 10.546, state is -0.021549105644226074, time/batch=-4.848\n",
      "Extract of training data : [3] [3]\n",
      "780/16406, train loss is 10.545, state is 0.01567547582089901, time/batch=-4.945\n",
      "Extract of training data : [0] [0]\n",
      "781/16406, train loss is 10.546, state is -0.0009766921866685152, time/batch=-4.872\n",
      "Extract of training data : [3] [3]\n",
      "782/16406, train loss is 10.546, state is -0.006733647082000971, time/batch=-4.832\n",
      "Extract of training data : [10] [3155]\n",
      "783/16406, train loss is 10.546, state is 0.0016098353080451488, time/batch=-4.826\n",
      "Extract of training data : [530] [10]\n",
      "784/16406, train loss is 10.546, state is 0.005309689790010452, time/batch=-4.847\n",
      "Extract of training data : [801] [10142]\n",
      "785/16406, train loss is 10.546, state is -0.006901395041495562, time/batch=-4.868\n",
      "Extract of training data : [277] [6179]\n",
      "786/16406, train loss is 10.546, state is -0.004915905185043812, time/batch=-4.913\n",
      "Extract of training data : [6077] [10]\n",
      "787/16406, train loss is 10.546, state is -0.008956336416304111, time/batch=-4.899\n",
      "Extract of training data : [10924] [10230]\n",
      "788/16406, train loss is 10.546, state is -0.021467523649334908, time/batch=-4.879\n",
      "Extract of training data : [0] [0]\n",
      "789/16406, train loss is 10.546, state is -0.006804526783525944, time/batch=-4.915\n",
      "Extract of training data : [3566] [413]\n",
      "790/16406, train loss is 10.546, state is -0.014451684430241585, time/batch=-4.942\n",
      "Extract of training data : [3] [1707]\n",
      "791/16406, train loss is 10.546, state is 0.005691901780664921, time/batch=-4.846\n",
      "Extract of training data : [1997] [16]\n",
      "792/16406, train loss is 10.546, state is -0.004097484517842531, time/batch=-4.856\n",
      "Extract of training data : [3516] [2941]\n",
      "793/16406, train loss is 10.546, state is -0.011678616516292095, time/batch=-4.862\n",
      "Extract of training data : [105] [1594]\n",
      "794/16406, train loss is 10.546, state is 0.005605699028819799, time/batch=-4.829\n",
      "Extract of training data : [11697] [263]\n",
      "795/16406, train loss is 10.546, state is -0.0016843852354213595, time/batch=-4.839\n",
      "Extract of training data : [548] [105]\n",
      "796/16406, train loss is 10.545, state is 0.008693695068359375, time/batch=-4.875\n",
      "Extract of training data : [32] [3613]\n",
      "797/16406, train loss is 10.546, state is 0.0037178564816713333, time/batch=-4.934\n",
      "Extract of training data : [3] [3]\n",
      "798/16406, train loss is 10.546, state is 0.010968766175210476, time/batch=-4.962\n",
      "Extract of training data : [277] [12281]\n",
      "799/16406, train loss is 10.545, state is 0.006129364017397165, time/batch=-4.883\n",
      "Extract of training data : [1220] [10]\n",
      "800/16406, train loss is 10.546, state is -0.003972585778683424, time/batch=-4.893\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1480] [10]\n",
      "801/16406, train loss is 10.546, state is -0.0007992672617547214, time/batch=-5.223\n",
      "Extract of training data : [6025] [10]\n",
      "802/16406, train loss is 10.545, state is 0.009321247227489948, time/batch=-5.012\n",
      "Extract of training data : [10] [1971]\n",
      "803/16406, train loss is 10.545, state is 0.0013809326337650418, time/batch=-4.908\n",
      "Extract of training data : [1021] [1161]\n",
      "804/16406, train loss is 10.545, state is 0.003861738834530115, time/batch=-4.844\n",
      "Extract of training data : [13194] [1007]\n",
      "805/16406, train loss is 10.546, state is 0.002408076310530305, time/batch=-4.860\n",
      "Extract of training data : [528] [877]\n",
      "806/16406, train loss is 10.546, state is 0.006806390359997749, time/batch=-4.977\n",
      "Extract of training data : [3] [912]\n",
      "807/16406, train loss is 10.546, state is 0.005389506462961435, time/batch=-4.919\n",
      "Extract of training data : [13562] [13563]\n",
      "808/16406, train loss is 10.546, state is -0.006459418218582869, time/batch=-4.911\n",
      "Extract of training data : [1079] [105]\n",
      "809/16406, train loss is 10.545, state is -0.006472736597061157, time/batch=-4.917\n",
      "Extract of training data : [3] [846]\n",
      "810/16406, train loss is 10.545, state is -0.0024338122457265854, time/batch=-4.827\n",
      "Extract of training data : [5740] [9010]\n",
      "811/16406, train loss is 10.545, state is -0.0029125679284334183, time/batch=-4.802\n",
      "Extract of training data : [4681] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812/16406, train loss is 10.545, state is -0.0038489094004034996, time/batch=-4.779\n",
      "Extract of training data : [8] [277]\n",
      "813/16406, train loss is 10.546, state is -0.0017000646330416203, time/batch=-4.816\n",
      "Extract of training data : [277] [2442]\n",
      "814/16406, train loss is 10.545, state is -0.01845293864607811, time/batch=-4.806\n",
      "Extract of training data : [280] [0]\n",
      "815/16406, train loss is 10.545, state is 0.010571868158876896, time/batch=-4.956\n",
      "Extract of training data : [11460] [10]\n",
      "816/16406, train loss is 10.545, state is -0.01991966739296913, time/batch=-4.966\n",
      "Extract of training data : [924] [3938]\n",
      "817/16406, train loss is 10.545, state is -0.018929634243249893, time/batch=-4.794\n",
      "Extract of training data : [3758] [688]\n",
      "818/16406, train loss is 10.545, state is -0.007398972753435373, time/batch=-4.852\n",
      "Extract of training data : [14893] [1185]\n",
      "819/16406, train loss is 10.545, state is 0.0023498644586652517, time/batch=-4.960\n",
      "Extract of training data : [492] [12]\n",
      "820/16406, train loss is 10.545, state is -0.0037854614201933146, time/batch=-4.854\n",
      "Extract of training data : [505] [1177]\n",
      "821/16406, train loss is 10.545, state is -0.007012973073869944, time/batch=-4.857\n",
      "Extract of training data : [4853] [16]\n",
      "822/16406, train loss is 10.545, state is -0.009391740895807743, time/batch=-4.845\n",
      "Extract of training data : [46] [6974]\n",
      "823/16406, train loss is 10.545, state is -0.004563589580357075, time/batch=-4.825\n",
      "Extract of training data : [3328] [6399]\n",
      "824/16406, train loss is 10.545, state is 0.0022490646224468946, time/batch=-4.855\n",
      "Extract of training data : [3] [910]\n",
      "825/16406, train loss is 10.546, state is 0.012748200446367264, time/batch=-4.933\n",
      "Extract of training data : [699] [16]\n",
      "826/16406, train loss is 10.546, state is 0.00026419467758387327, time/batch=-4.839\n",
      "Extract of training data : [3758] [832]\n",
      "827/16406, train loss is 10.546, state is -0.013547354377806187, time/batch=-4.965\n",
      "Extract of training data : [10] [1489]\n",
      "828/16406, train loss is 10.545, state is -0.015497450716793537, time/batch=-4.942\n",
      "Extract of training data : [105] [371]\n",
      "829/16406, train loss is 10.545, state is -0.004773005843162537, time/batch=-4.981\n",
      "Extract of training data : [1167] [873]\n",
      "830/16406, train loss is 10.546, state is 0.004716816358268261, time/batch=-4.880\n",
      "Extract of training data : [910] [1803]\n",
      "831/16406, train loss is 10.545, state is -0.005001395475119352, time/batch=-4.956\n",
      "Extract of training data : [1021] [811]\n",
      "832/16406, train loss is 10.546, state is -0.003044955665245652, time/batch=-4.955\n",
      "Extract of training data : [0] [0]\n",
      "833/16406, train loss is 10.546, state is -0.01023157499730587, time/batch=-5.040\n",
      "Extract of training data : [280] [0]\n",
      "834/16406, train loss is 10.546, state is 0.010974030941724777, time/batch=-4.959\n",
      "Extract of training data : [16725] [14224]\n",
      "835/16406, train loss is 10.546, state is -0.010874971747398376, time/batch=-4.988\n",
      "Extract of training data : [284] [285]\n",
      "836/16406, train loss is 10.546, state is 0.008965777233242989, time/batch=-4.917\n",
      "Extract of training data : [0] [0]\n",
      "837/16406, train loss is 10.546, state is 2.3469094230677e-05, time/batch=-4.876\n",
      "Extract of training data : [11071] [35]\n",
      "838/16406, train loss is 10.546, state is -0.010406835936009884, time/batch=-4.932\n",
      "Extract of training data : [10] [17100]\n",
      "839/16406, train loss is 10.545, state is 0.016072988510131836, time/batch=-4.975\n",
      "Extract of training data : [10] [6402]\n",
      "840/16406, train loss is 10.545, state is -0.00045990737271495163, time/batch=-4.944\n",
      "Extract of training data : [14342] [17345]\n",
      "841/16406, train loss is 10.546, state is -0.006543128751218319, time/batch=-4.968\n",
      "Extract of training data : [17464] [559]\n",
      "842/16406, train loss is 10.545, state is -0.001895334804430604, time/batch=-4.994\n",
      "Extract of training data : [3516] [35]\n",
      "843/16406, train loss is 10.545, state is -0.023857660591602325, time/batch=-5.083\n",
      "Extract of training data : [910] [378]\n",
      "844/16406, train loss is 10.545, state is -0.008300624787807465, time/batch=-5.000\n",
      "Extract of training data : [3285] [1077]\n",
      "845/16406, train loss is 10.546, state is -0.016262182965874672, time/batch=-4.872\n",
      "Extract of training data : [559] [3105]\n",
      "846/16406, train loss is 10.546, state is -0.0033406305592507124, time/batch=-5.017\n",
      "Extract of training data : [10] [143]\n",
      "847/16406, train loss is 10.545, state is 0.004835234489291906, time/batch=-4.945\n",
      "Extract of training data : [3] [3]\n",
      "848/16406, train loss is 10.546, state is 0.006190972402691841, time/batch=-5.002\n",
      "Extract of training data : [1188] [12110]\n",
      "849/16406, train loss is 10.546, state is 0.005486587528139353, time/batch=-5.002\n",
      "Extract of training data : [16451] [164]\n",
      "850/16406, train loss is 10.545, state is -0.0035417473409324884, time/batch=-4.909\n",
      "Extract of training data : [3] [3]\n",
      "851/16406, train loss is 10.545, state is -0.003438139334321022, time/batch=-5.056\n",
      "Extract of training data : [0] [3]\n",
      "852/16406, train loss is 10.546, state is 0.004719607997685671, time/batch=-4.947\n",
      "Extract of training data : [3055] [10]\n",
      "853/16406, train loss is 10.546, state is -0.004902885761111975, time/batch=-4.952\n",
      "Extract of training data : [3] [3]\n",
      "854/16406, train loss is 10.546, state is -0.02049667201936245, time/batch=-4.909\n",
      "Extract of training data : [13381] [10]\n",
      "855/16406, train loss is 10.546, state is -0.002196365501731634, time/batch=-5.051\n",
      "Extract of training data : [3] [3]\n",
      "856/16406, train loss is 10.546, state is 0.0001981871173484251, time/batch=-5.051\n",
      "Extract of training data : [436] [283]\n",
      "857/16406, train loss is 10.546, state is -0.0030327634885907173, time/batch=-4.904\n",
      "Extract of training data : [1137] [28]\n",
      "858/16406, train loss is 10.546, state is 0.0032442857045680285, time/batch=-4.994\n",
      "Extract of training data : [413] [2442]\n",
      "859/16406, train loss is 10.546, state is -0.008947995491325855, time/batch=-5.038\n",
      "Extract of training data : [11953] [17849]\n",
      "860/16406, train loss is 10.545, state is 0.0006916298298165202, time/batch=-4.985\n",
      "Extract of training data : [3] [3]\n",
      "861/16406, train loss is 10.546, state is -0.014774939976632595, time/batch=-4.864\n",
      "Extract of training data : [3] [3]\n",
      "862/16406, train loss is 10.546, state is -0.004779044538736343, time/batch=-4.854\n",
      "Extract of training data : [10] [3860]\n",
      "863/16406, train loss is 10.545, state is 0.006809432525187731, time/batch=-4.866\n",
      "Extract of training data : [146] [8]\n",
      "864/16406, train loss is 10.546, state is -0.01302236970514059, time/batch=-4.911\n",
      "Extract of training data : [4873] [2924]\n",
      "865/16406, train loss is 10.546, state is -0.0020442320965230465, time/batch=-4.941\n",
      "Extract of training data : [10] [2398]\n",
      "866/16406, train loss is 10.545, state is 0.00034398259595036507, time/batch=-4.899\n",
      "Extract of training data : [245] [10]\n",
      "867/16406, train loss is 10.545, state is 0.009527900256216526, time/batch=-4.912\n",
      "Extract of training data : [561] [4309]\n",
      "868/16406, train loss is 10.546, state is -0.00350311491638422, time/batch=-4.984\n",
      "Extract of training data : [14] [17716]\n",
      "869/16406, train loss is 10.545, state is 0.00011707328667398542, time/batch=-4.926\n",
      "Extract of training data : [413] [17114]\n",
      "870/16406, train loss is 10.545, state is 0.011752516962587833, time/batch=-4.925\n",
      "Extract of training data : [972] [883]\n",
      "871/16406, train loss is 10.546, state is -0.005672984290868044, time/batch=-4.940\n",
      "Extract of training data : [1180] [35]\n",
      "872/16406, train loss is 10.545, state is 0.006937530357390642, time/batch=-4.905\n",
      "Extract of training data : [0] [0]\n",
      "873/16406, train loss is 10.545, state is 0.0059567950665950775, time/batch=-4.944\n",
      "Extract of training data : [3] [3]\n",
      "874/16406, train loss is 10.546, state is -0.008096210658550262, time/batch=-4.964\n",
      "Extract of training data : [6982] [688]\n",
      "875/16406, train loss is 10.546, state is -0.003960460424423218, time/batch=-4.914\n",
      "Extract of training data : [1185] [13445]\n",
      "876/16406, train loss is 10.546, state is 0.003403632901608944, time/batch=-4.951\n",
      "Extract of training data : [10] [753]\n",
      "877/16406, train loss is 10.545, state is 0.0013019901234656572, time/batch=-5.015\n",
      "Extract of training data : [533] [2221]\n",
      "878/16406, train loss is 10.546, state is 0.017430976033210754, time/batch=-4.966\n",
      "Extract of training data : [3] [3]\n",
      "879/16406, train loss is 10.546, state is 0.0054548573680222034, time/batch=-5.011\n",
      "Extract of training data : [1139] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/16406, train loss is 10.546, state is -0.023102344945073128, time/batch=-4.890\n",
      "Extract of training data : [2611] [801]\n",
      "881/16406, train loss is 10.546, state is -0.013295862823724747, time/batch=-4.886\n",
      "Extract of training data : [0] [3]\n",
      "882/16406, train loss is 10.546, state is 0.006449043285101652, time/batch=-4.896\n",
      "Extract of training data : [3830] [478]\n",
      "883/16406, train loss is 10.546, state is 0.007272956892848015, time/batch=-4.929\n",
      "Extract of training data : [1426] [16]\n",
      "884/16406, train loss is 10.546, state is -0.005464424379169941, time/batch=-4.876\n",
      "Extract of training data : [422] [35]\n",
      "885/16406, train loss is 10.546, state is 0.009521003812551498, time/batch=-4.998\n",
      "Extract of training data : [873] [29]\n",
      "886/16406, train loss is 10.546, state is -0.003855601418763399, time/batch=-4.947\n",
      "Extract of training data : [19037] [21284]\n",
      "887/16406, train loss is 10.545, state is 0.006762735079973936, time/batch=-4.931\n",
      "Extract of training data : [5214] [5809]\n",
      "888/16406, train loss is 10.546, state is -0.00023811226128600538, time/batch=-4.970\n",
      "Extract of training data : [11789] [2007]\n",
      "889/16406, train loss is 10.546, state is -0.02209370955824852, time/batch=-4.992\n",
      "Extract of training data : [1445] [9663]\n",
      "890/16406, train loss is 10.546, state is -0.001777855446562171, time/batch=-4.992\n",
      "Extract of training data : [35] [826]\n",
      "891/16406, train loss is 10.545, state is -0.00289031770080328, time/batch=-4.895\n",
      "Extract of training data : [10] [176]\n",
      "892/16406, train loss is 10.545, state is -0.0048805284313857555, time/batch=-4.896\n",
      "Extract of training data : [422] [1289]\n",
      "893/16406, train loss is 10.546, state is -0.004901772830635309, time/batch=-4.836\n",
      "Extract of training data : [0] [0]\n",
      "894/16406, train loss is 10.546, state is -0.010913760401308537, time/batch=-4.927\n",
      "Extract of training data : [413] [4311]\n",
      "895/16406, train loss is 10.545, state is 0.004289870150387287, time/batch=-4.890\n",
      "Extract of training data : [3] [3]\n",
      "896/16406, train loss is 10.546, state is -0.005277599208056927, time/batch=-4.951\n",
      "Extract of training data : [11483] [2508]\n",
      "897/16406, train loss is 10.546, state is 0.003697215346619487, time/batch=-5.077\n",
      "Extract of training data : [12] [972]\n",
      "898/16406, train loss is 10.546, state is 0.001725316746160388, time/batch=-5.150\n",
      "Extract of training data : [4378] [16249]\n",
      "899/16406, train loss is 10.546, state is -0.002846398623660207, time/batch=-5.160\n",
      "Extract of training data : [3] [3]\n",
      "900/16406, train loss is 10.546, state is 0.0020110481418669224, time/batch=-4.949\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [12] [22382]\n",
      "901/16406, train loss is 10.546, state is -0.003492310643196106, time/batch=-5.538\n",
      "Extract of training data : [291] [495]\n",
      "902/16406, train loss is 10.546, state is 0.006883881986141205, time/batch=-5.063\n",
      "Extract of training data : [16] [0]\n",
      "903/16406, train loss is 10.546, state is 0.0070565687492489815, time/batch=-5.072\n",
      "Extract of training data : [22596] [12843]\n",
      "904/16406, train loss is 10.545, state is -0.0016319812275469303, time/batch=-4.903\n",
      "Extract of training data : [3] [3]\n",
      "905/16406, train loss is 10.545, state is -0.0062211682088673115, time/batch=-4.874\n",
      "Extract of training data : [3] [3]\n",
      "906/16406, train loss is 10.546, state is 0.01161174662411213, time/batch=-4.955\n",
      "Extract of training data : [20707] [720]\n",
      "907/16406, train loss is 10.546, state is 0.004867789801210165, time/batch=-4.956\n",
      "Extract of training data : [20510] [16]\n",
      "908/16406, train loss is 10.546, state is 0.02103324607014656, time/batch=-4.994\n",
      "Extract of training data : [559] [464]\n",
      "909/16406, train loss is 10.546, state is 0.000741019903216511, time/batch=-4.971\n",
      "Extract of training data : [5214] [1078]\n",
      "910/16406, train loss is 10.546, state is 0.0006514526903629303, time/batch=-4.921\n",
      "Extract of training data : [1458] [9701]\n",
      "911/16406, train loss is 10.546, state is -0.01851423643529415, time/batch=-4.876\n",
      "Extract of training data : [1234] [1842]\n",
      "912/16406, train loss is 10.546, state is 0.004851995036005974, time/batch=-4.945\n",
      "Extract of training data : [10] [4307]\n",
      "913/16406, train loss is 10.546, state is -0.018318599089980125, time/batch=-4.992\n",
      "Extract of training data : [105] [2045]\n",
      "914/16406, train loss is 10.546, state is -0.015225324779748917, time/batch=-4.912\n",
      "Extract of training data : [3202] [10]\n",
      "915/16406, train loss is 10.546, state is -0.015313719399273396, time/batch=-4.931\n",
      "Extract of training data : [23373] [16]\n",
      "916/16406, train loss is 10.546, state is -0.01783085986971855, time/batch=-5.009\n",
      "Extract of training data : [3] [3]\n",
      "917/16406, train loss is 10.546, state is -0.0004040659696329385, time/batch=-4.870\n",
      "Extract of training data : [2557] [3]\n",
      "918/16406, train loss is 10.545, state is 0.0020310983527451754, time/batch=-4.995\n",
      "Extract of training data : [5593] [2392]\n",
      "919/16406, train loss is 10.546, state is 0.005490757059305906, time/batch=-4.877\n",
      "Extract of training data : [1437] [16726]\n",
      "920/16406, train loss is 10.546, state is -0.017529066652059555, time/batch=-4.879\n",
      "Extract of training data : [1308] [5313]\n",
      "921/16406, train loss is 10.546, state is 0.011567101813852787, time/batch=-4.994\n",
      "Extract of training data : [280] [1228]\n",
      "922/16406, train loss is 10.546, state is -0.029143568128347397, time/batch=-4.959\n",
      "Extract of training data : [3] [277]\n",
      "923/16406, train loss is 10.546, state is -0.0033706538379192352, time/batch=-4.943\n",
      "Extract of training data : [13852] [2841]\n",
      "924/16406, train loss is 10.546, state is 0.0005928957252763212, time/batch=-4.984\n",
      "Extract of training data : [378] [327]\n",
      "925/16406, train loss is 10.546, state is 0.011276989243924618, time/batch=-5.002\n",
      "Extract of training data : [23552] [146]\n",
      "926/16406, train loss is 10.546, state is -0.006294067949056625, time/batch=-4.897\n",
      "Extract of training data : [10] [14699]\n",
      "927/16406, train loss is 10.546, state is -0.019905462861061096, time/batch=-4.876\n",
      "Extract of training data : [7937] [2082]\n",
      "928/16406, train loss is 10.546, state is 0.0066664512269198895, time/batch=-4.873\n",
      "Extract of training data : [2442] [21812]\n",
      "929/16406, train loss is 10.546, state is 0.00016386184142902493, time/batch=-4.908\n",
      "Extract of training data : [1575] [1419]\n",
      "930/16406, train loss is 10.546, state is -0.004870673641562462, time/batch=-4.842\n",
      "Extract of training data : [10] [6154]\n",
      "931/16406, train loss is 10.546, state is 0.009773899801075459, time/batch=-4.835\n",
      "Extract of training data : [3] [3]\n",
      "932/16406, train loss is 10.546, state is -0.003118748776614666, time/batch=-4.901\n",
      "Extract of training data : [2039] [10]\n",
      "933/16406, train loss is 10.546, state is -0.023193085566163063, time/batch=-4.934\n",
      "Extract of training data : [105] [16]\n",
      "934/16406, train loss is 10.546, state is 0.001457269536331296, time/batch=-4.918\n",
      "Extract of training data : [413] [473]\n",
      "935/16406, train loss is 10.546, state is -0.015276221558451653, time/batch=-5.101\n",
      "Extract of training data : [24668] [10]\n",
      "936/16406, train loss is 10.546, state is -0.01439331192523241, time/batch=-4.927\n",
      "Extract of training data : [2045] [877]\n",
      "937/16406, train loss is 10.546, state is 0.00816345401108265, time/batch=-4.985\n",
      "Extract of training data : [877] [877]\n",
      "938/16406, train loss is 10.546, state is 0.006832045968621969, time/batch=-5.027\n",
      "Extract of training data : [71] [33]\n",
      "939/16406, train loss is 10.546, state is -0.018114859238266945, time/batch=-5.101\n",
      "Extract of training data : [3] [3]\n",
      "940/16406, train loss is 10.546, state is 0.0034499638713896275, time/batch=-4.974\n",
      "Extract of training data : [256] [3247]\n",
      "941/16406, train loss is 10.546, state is 0.006636994890868664, time/batch=-4.873\n",
      "Extract of training data : [10] [3818]\n",
      "942/16406, train loss is 10.545, state is 0.0044290125370025635, time/batch=-4.893\n",
      "Extract of training data : [146] [8]\n",
      "943/16406, train loss is 10.546, state is 0.002944718347862363, time/batch=-4.901\n",
      "Extract of training data : [18743] [465]\n",
      "944/16406, train loss is 10.546, state is -0.007810760289430618, time/batch=-4.957\n",
      "Extract of training data : [25375] [10]\n",
      "945/16406, train loss is 10.545, state is -0.00012141910701757297, time/batch=-4.904\n",
      "Extract of training data : [1501] [10]\n",
      "946/16406, train loss is 10.546, state is -0.015395530499517918, time/batch=-4.844\n",
      "Extract of training data : [1577] [1176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "947/16406, train loss is 10.546, state is 0.008844028227031231, time/batch=-4.914\n",
      "Extract of training data : [172] [10]\n",
      "948/16406, train loss is 10.546, state is 0.004217600915580988, time/batch=-4.955\n",
      "Extract of training data : [3728] [33]\n",
      "949/16406, train loss is 10.546, state is 0.0009552881238050759, time/batch=-4.950\n",
      "Extract of training data : [21] [10]\n",
      "950/16406, train loss is 10.546, state is 0.0484369695186615, time/batch=-4.850\n",
      "Extract of training data : [344] [3219]\n",
      "951/16406, train loss is 10.546, state is 0.014773616567254066, time/batch=-5.026\n",
      "Extract of training data : [1829] [1310]\n",
      "952/16406, train loss is 10.546, state is -0.020348209887742996, time/batch=-4.879\n",
      "Extract of training data : [3] [3]\n",
      "953/16406, train loss is 10.546, state is -0.0052412524819374084, time/batch=-4.834\n",
      "Extract of training data : [7051] [536]\n",
      "954/16406, train loss is 10.546, state is -0.0029565736185759306, time/batch=-5.014\n",
      "Extract of training data : [544] [372]\n",
      "955/16406, train loss is 10.546, state is 0.00561227323487401, time/batch=-4.964\n",
      "Extract of training data : [4329] [35]\n",
      "956/16406, train loss is 10.545, state is -0.005487286485731602, time/batch=-4.925\n",
      "Extract of training data : [16] [280]\n",
      "957/16406, train loss is 10.545, state is 0.005231561604887247, time/batch=-4.929\n",
      "Extract of training data : [12504] [7071]\n",
      "958/16406, train loss is 10.546, state is -0.008014721795916557, time/batch=-4.992\n",
      "Extract of training data : [2305] [912]\n",
      "959/16406, train loss is 10.546, state is -0.019076772034168243, time/batch=-4.969\n",
      "Extract of training data : [1161] [1191]\n",
      "960/16406, train loss is 10.546, state is -0.014394979923963547, time/batch=-4.949\n",
      "Extract of training data : [12504] [7284]\n",
      "961/16406, train loss is 10.546, state is -0.007472638506442308, time/batch=-4.944\n",
      "Extract of training data : [8454] [16]\n",
      "962/16406, train loss is 10.546, state is 0.005311307497322559, time/batch=-4.901\n",
      "Extract of training data : [35] [3055]\n",
      "963/16406, train loss is 10.546, state is 0.0038134553469717503, time/batch=-4.906\n",
      "Extract of training data : [10] [26159]\n",
      "964/16406, train loss is 10.546, state is 0.000166494442964904, time/batch=-4.916\n",
      "Extract of training data : [699] [16]\n",
      "965/16406, train loss is 10.546, state is 0.0149306645616889, time/batch=-4.875\n",
      "Extract of training data : [24499] [12504]\n",
      "966/16406, train loss is 10.545, state is 0.001731770345941186, time/batch=-4.911\n",
      "Extract of training data : [275] [20945]\n",
      "967/16406, train loss is 10.546, state is -4.134304617764428e-05, time/batch=-4.991\n",
      "Extract of training data : [10] [12]\n",
      "968/16406, train loss is 10.546, state is -0.0023517291992902756, time/batch=-4.968\n",
      "Extract of training data : [3326] [722]\n",
      "969/16406, train loss is 10.546, state is 0.01117544062435627, time/batch=-4.940\n",
      "Extract of training data : [26887] [105]\n",
      "970/16406, train loss is 10.546, state is -0.0019134118920192122, time/batch=-4.942\n",
      "Extract of training data : [10188] [35]\n",
      "971/16406, train loss is 10.546, state is -0.012018375098705292, time/batch=-4.953\n",
      "Extract of training data : [4309] [10]\n",
      "972/16406, train loss is 10.545, state is 0.003793892217800021, time/batch=-4.906\n",
      "Extract of training data : [71] [2311]\n",
      "973/16406, train loss is 10.546, state is -0.0066881622187793255, time/batch=-4.947\n",
      "Extract of training data : [0] [0]\n",
      "974/16406, train loss is 10.546, state is 0.00737787876278162, time/batch=-4.941\n",
      "Extract of training data : [8] [277]\n",
      "975/16406, train loss is 10.545, state is -0.007525317370891571, time/batch=-5.008\n",
      "Extract of training data : [3] [3]\n",
      "976/16406, train loss is 10.546, state is -0.004163037054240704, time/batch=-5.317\n",
      "Extract of training data : [10] [667]\n",
      "977/16406, train loss is 10.546, state is -0.0004307098570279777, time/batch=-4.946\n",
      "Extract of training data : [2267] [35]\n",
      "978/16406, train loss is 10.546, state is -0.019359929487109184, time/batch=-4.972\n",
      "Extract of training data : [27448] [13378]\n",
      "979/16406, train loss is 10.545, state is -0.01607534848153591, time/batch=-4.967\n",
      "Extract of training data : [10] [328]\n",
      "980/16406, train loss is 10.545, state is 0.005173909943550825, time/batch=-5.063\n",
      "Extract of training data : [2968] [10]\n",
      "981/16406, train loss is 10.546, state is 0.004827294964343309, time/batch=-5.129\n",
      "Extract of training data : [326] [27664]\n",
      "982/16406, train loss is 10.545, state is 0.016310956329107285, time/batch=-4.884\n",
      "Extract of training data : [16] [0]\n",
      "983/16406, train loss is 10.545, state is -0.0018848635954782367, time/batch=-4.919\n",
      "Extract of training data : [10] [2438]\n",
      "984/16406, train loss is 10.545, state is -0.007952779531478882, time/batch=-4.987\n",
      "Extract of training data : [3] [3]\n",
      "985/16406, train loss is 10.545, state is -0.015621363185346127, time/batch=-4.949\n",
      "Extract of training data : [582] [4227]\n",
      "986/16406, train loss is 10.546, state is -0.001594059867784381, time/batch=-4.924\n",
      "Extract of training data : [0] [3]\n",
      "987/16406, train loss is 10.546, state is -0.019953208044171333, time/batch=-4.874\n",
      "Extract of training data : [1557] [422]\n",
      "988/16406, train loss is 10.546, state is 0.010520759038627148, time/batch=-4.912\n",
      "Extract of training data : [20102] [11553]\n",
      "989/16406, train loss is 10.546, state is 0.004098463803529739, time/batch=-4.962\n",
      "Extract of training data : [105] [688]\n",
      "990/16406, train loss is 10.546, state is 0.013560626655817032, time/batch=-4.929\n",
      "Extract of training data : [16577] [11276]\n",
      "991/16406, train loss is 10.546, state is -0.01700727641582489, time/batch=-4.929\n",
      "Extract of training data : [2708] [16]\n",
      "992/16406, train loss is 10.546, state is -0.0007077532354742289, time/batch=-4.930\n",
      "Extract of training data : [283] [12524]\n",
      "993/16406, train loss is 10.546, state is -0.009727485477924347, time/batch=-4.950\n",
      "Extract of training data : [28432] [1161]\n",
      "994/16406, train loss is 10.546, state is -0.021524447947740555, time/batch=-4.899\n",
      "Extract of training data : [318] [35]\n",
      "995/16406, train loss is 10.545, state is 0.011764434166252613, time/batch=-4.895\n",
      "Extract of training data : [13897] [35]\n",
      "996/16406, train loss is 10.546, state is 0.010472007095813751, time/batch=-4.927\n",
      "Extract of training data : [0] [0]\n",
      "997/16406, train loss is 10.545, state is 0.015918273478746414, time/batch=-4.919\n",
      "Extract of training data : [1515] [10]\n",
      "998/16406, train loss is 10.546, state is -0.0010760943405330181, time/batch=-4.895\n",
      "Extract of training data : [533] [259]\n",
      "999/16406, train loss is 10.546, state is -0.016441667452454567, time/batch=-4.986\n",
      "Extract of training data : [3] [9745]\n",
      "1000/16406, train loss is 10.545, state is 0.016129856929183006, time/batch=-4.970\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [6286] [292]\n",
      "1001/16406, train loss is 10.546, state is 0.009640540927648544, time/batch=-5.529\n",
      "Extract of training data : [877] [1601]\n",
      "1002/16406, train loss is 10.545, state is 0.004196035675704479, time/batch=-4.953\n",
      "Extract of training data : [3] [3980]\n",
      "1003/16406, train loss is 10.546, state is 0.009312927722930908, time/batch=-4.973\n",
      "Extract of training data : [10] [422]\n",
      "1004/16406, train loss is 10.546, state is 0.01456119492650032, time/batch=-4.942\n",
      "Extract of training data : [9144] [4211]\n",
      "1005/16406, train loss is 10.546, state is -0.0021880879066884518, time/batch=-4.938\n",
      "Extract of training data : [12699] [424]\n",
      "1006/16406, train loss is 10.546, state is 0.0032170559279620647, time/batch=-5.107\n",
      "Extract of training data : [458] [4016]\n",
      "1007/16406, train loss is 10.546, state is -0.0012131480034440756, time/batch=-5.012\n",
      "Extract of training data : [12482] [10]\n",
      "1008/16406, train loss is 10.545, state is 0.01762787625193596, time/batch=-4.949\n",
      "Extract of training data : [3] [3]\n",
      "1009/16406, train loss is 10.546, state is 0.011293253861367702, time/batch=-4.990\n",
      "Extract of training data : [548] [29227]\n",
      "1010/16406, train loss is 10.545, state is 0.010835612192749977, time/batch=-4.916\n",
      "Extract of training data : [4352] [10]\n",
      "1011/16406, train loss is 10.545, state is 0.017381452023983, time/batch=-5.051\n",
      "Extract of training data : [12986] [2127]\n",
      "1012/16406, train loss is 10.546, state is -0.011425563134253025, time/batch=-5.037\n",
      "Extract of training data : [3055] [15878]\n",
      "1013/16406, train loss is 10.546, state is 0.012200365774333477, time/batch=-5.046\n",
      "Extract of training data : [1188] [2398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014/16406, train loss is 10.546, state is 0.002276109531521797, time/batch=-4.952\n",
      "Extract of training data : [4179] [10]\n",
      "1015/16406, train loss is 10.546, state is -0.002560961991548538, time/batch=-5.134\n",
      "Extract of training data : [1385] [5846]\n",
      "1016/16406, train loss is 10.546, state is 0.014936914667487144, time/batch=-4.998\n",
      "Extract of training data : [0] [3]\n",
      "1017/16406, train loss is 10.546, state is -0.0002931815979536623, time/batch=-4.934\n",
      "Extract of training data : [1299] [1419]\n",
      "1018/16406, train loss is 10.546, state is -0.009311527013778687, time/batch=-5.023\n",
      "Extract of training data : [3758] [796]\n",
      "1019/16406, train loss is 10.546, state is -0.0026801112107932568, time/batch=-4.939\n",
      "Extract of training data : [29609] [10]\n",
      "1020/16406, train loss is 10.545, state is -0.009210995398461819, time/batch=-5.012\n",
      "Extract of training data : [2574] [10]\n",
      "1021/16406, train loss is 10.546, state is -0.006955070421099663, time/batch=-5.037\n",
      "Extract of training data : [3] [3]\n",
      "1022/16406, train loss is 10.546, state is 0.005724200513213873, time/batch=-5.002\n",
      "Extract of training data : [1846] [1422]\n",
      "1023/16406, train loss is 10.545, state is 0.009319290518760681, time/batch=-4.954\n",
      "Extract of training data : [2271] [4130]\n",
      "1024/16406, train loss is 10.546, state is 0.007927779108285904, time/batch=-4.954\n",
      "Extract of training data : [10] [544]\n",
      "1025/16406, train loss is 10.546, state is 0.0008257427834905684, time/batch=-4.907\n",
      "Extract of training data : [21448] [29955]\n",
      "1026/16406, train loss is 10.546, state is 0.0016287657199427485, time/batch=-4.982\n",
      "Extract of training data : [10] [3611]\n",
      "1027/16406, train loss is 10.546, state is -0.005919860675930977, time/batch=-4.998\n",
      "Extract of training data : [3] [582]\n",
      "1028/16406, train loss is 10.545, state is -0.013897445052862167, time/batch=-4.953\n",
      "Extract of training data : [30161] [20610]\n",
      "1029/16406, train loss is 10.545, state is -0.004213299602270126, time/batch=-4.984\n",
      "Extract of training data : [2257] [10]\n",
      "1030/16406, train loss is 10.546, state is 0.006913222372531891, time/batch=-5.144\n",
      "Extract of training data : [15065] [4352]\n",
      "1031/16406, train loss is 10.546, state is 0.01822877861559391, time/batch=-4.978\n",
      "Extract of training data : [35] [16445]\n",
      "1032/16406, train loss is 10.546, state is -0.006559919565916061, time/batch=-5.093\n",
      "Extract of training data : [422] [532]\n",
      "1033/16406, train loss is 10.546, state is -0.009540028870105743, time/batch=-4.944\n",
      "Extract of training data : [843] [10]\n",
      "1034/16406, train loss is 10.546, state is 0.0030127963982522488, time/batch=-4.992\n",
      "Extract of training data : [10] [30502]\n",
      "1035/16406, train loss is 10.546, state is -0.0012603832874447107, time/batch=-4.982\n",
      "Extract of training data : [10] [4141]\n",
      "1036/16406, train loss is 10.545, state is 0.0028067126404494047, time/batch=-5.096\n",
      "Extract of training data : [413] [12916]\n",
      "1037/16406, train loss is 10.546, state is 0.01117593515664339, time/batch=-4.988\n",
      "Extract of training data : [30689] [399]\n",
      "1038/16406, train loss is 10.545, state is 0.0015973872505128384, time/batch=-5.012\n",
      "Extract of training data : [0] [3]\n",
      "1039/16406, train loss is 10.546, state is -0.009324410930275917, time/batch=-4.970\n",
      "Extract of training data : [29] [413]\n",
      "1040/16406, train loss is 10.546, state is -0.0005628576036542654, time/batch=-5.066\n",
      "Extract of training data : [10] [1185]\n",
      "1041/16406, train loss is 10.545, state is 0.0032490298617631197, time/batch=-5.110\n",
      "Extract of training data : [582] [472]\n",
      "1042/16406, train loss is 10.546, state is 0.005231259390711784, time/batch=-5.281\n",
      "Extract of training data : [0] [0]\n",
      "1043/16406, train loss is 10.546, state is -0.010216440074145794, time/batch=-5.032\n",
      "Extract of training data : [553] [3340]\n",
      "1044/16406, train loss is 10.545, state is -0.005402303766459227, time/batch=-4.918\n",
      "Extract of training data : [5196] [1220]\n",
      "1045/16406, train loss is 10.546, state is -0.005317017901688814, time/batch=-5.078\n",
      "Extract of training data : [46] [1295]\n",
      "1046/16406, train loss is 10.546, state is -0.015643958002328873, time/batch=-5.079\n",
      "Extract of training data : [3] [3]\n",
      "1047/16406, train loss is 10.546, state is -0.00766307907178998, time/batch=-4.913\n",
      "Extract of training data : [50] [1963]\n",
      "1048/16406, train loss is 10.546, state is -0.010566171258687973, time/batch=-5.021\n",
      "Extract of training data : [174] [12]\n",
      "1049/16406, train loss is 10.546, state is 0.013245606794953346, time/batch=-5.111\n",
      "Extract of training data : [3408] [111]\n",
      "1050/16406, train loss is 10.545, state is -0.02085809037089348, time/batch=-5.021\n",
      "Extract of training data : [0] [0]\n",
      "1051/16406, train loss is 10.545, state is 0.00457909656688571, time/batch=-5.050\n",
      "Extract of training data : [10] [293]\n",
      "1052/16406, train loss is 10.545, state is 0.008487098850309849, time/batch=-4.880\n",
      "Extract of training data : [2720] [1628]\n",
      "1053/16406, train loss is 10.546, state is -0.010879943147301674, time/batch=-5.039\n",
      "Extract of training data : [15444] [1575]\n",
      "1054/16406, train loss is 10.546, state is -0.0038534870836883783, time/batch=-5.132\n",
      "Extract of training data : [422] [9376]\n",
      "1055/16406, train loss is 10.546, state is -0.005086612422019243, time/batch=-5.092\n",
      "Extract of training data : [28979] [413]\n",
      "1056/16406, train loss is 10.546, state is -0.007115359418094158, time/batch=-4.982\n",
      "Extract of training data : [105] [938]\n",
      "1057/16406, train loss is 10.546, state is -0.011820483952760696, time/batch=-5.029\n",
      "Extract of training data : [18981] [31828]\n",
      "1058/16406, train loss is 10.546, state is -0.010185746476054192, time/batch=-4.935\n",
      "Extract of training data : [14014] [13306]\n",
      "1059/16406, train loss is 10.546, state is -0.007612329442054033, time/batch=-5.009\n",
      "Extract of training data : [16355] [31920]\n",
      "1060/16406, train loss is 10.546, state is -0.013075937516987324, time/batch=-5.009\n",
      "Extract of training data : [957] [811]\n",
      "1061/16406, train loss is 10.545, state is 0.0026602253783494234, time/batch=-5.060\n",
      "Extract of training data : [3515] [3516]\n",
      "1062/16406, train loss is 10.546, state is 0.006806541234254837, time/batch=-5.083\n",
      "Extract of training data : [413] [21]\n",
      "1063/16406, train loss is 10.546, state is -0.00393250584602356, time/batch=-4.957\n",
      "Extract of training data : [1591] [28]\n",
      "1064/16406, train loss is 10.546, state is -0.01757194660604, time/batch=-4.999\n",
      "Extract of training data : [32107] [5180]\n",
      "1065/16406, train loss is 10.546, state is 0.00283954874612391, time/batch=-4.942\n",
      "Extract of training data : [12] [9745]\n",
      "1066/16406, train loss is 10.546, state is 0.003927003126591444, time/batch=-5.073\n",
      "Extract of training data : [144] [16]\n",
      "1067/16406, train loss is 10.545, state is -0.004197993315756321, time/batch=-4.941\n",
      "Extract of training data : [3] [3]\n",
      "1068/16406, train loss is 10.546, state is 0.018569784238934517, time/batch=-5.001\n",
      "Extract of training data : [0] [0]\n",
      "1069/16406, train loss is 10.546, state is -0.010683265514671803, time/batch=-5.071\n",
      "Extract of training data : [877] [280]\n",
      "1070/16406, train loss is 10.545, state is -0.0012969571398571134, time/batch=-4.971\n",
      "Extract of training data : [15481] [29328]\n",
      "1071/16406, train loss is 10.545, state is -0.0028908320236951113, time/batch=-5.066\n",
      "Extract of training data : [3] [3]\n",
      "1072/16406, train loss is 10.545, state is 0.0030078624840825796, time/batch=-5.061\n",
      "Extract of training data : [3] [3366]\n",
      "1073/16406, train loss is 10.545, state is -0.005888014566153288, time/batch=-4.980\n",
      "Extract of training data : [27445] [920]\n",
      "1074/16406, train loss is 10.546, state is -0.025706926360726357, time/batch=-5.019\n",
      "Extract of training data : [873] [2875]\n",
      "1075/16406, train loss is 10.545, state is -0.020222963765263557, time/batch=-5.081\n",
      "Extract of training data : [1597] [442]\n",
      "1076/16406, train loss is 10.546, state is 0.006545661482959986, time/batch=-5.055\n",
      "Extract of training data : [582] [1293]\n",
      "1077/16406, train loss is 10.546, state is -0.0067983572371304035, time/batch=-5.063\n",
      "Extract of training data : [877] [280]\n",
      "1078/16406, train loss is 10.545, state is -0.021270107477903366, time/batch=-5.039\n",
      "Extract of training data : [5590] [850]\n",
      "1079/16406, train loss is 10.546, state is 0.00971989519894123, time/batch=-5.081\n",
      "Extract of training data : [1014] [71]\n",
      "1080/16406, train loss is 10.546, state is -0.0015684987884014845, time/batch=-4.968\n",
      "Extract of training data : [10] [143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081/16406, train loss is 10.545, state is -0.000382515718229115, time/batch=-5.156\n",
      "Extract of training data : [4088] [1321]\n",
      "1082/16406, train loss is 10.545, state is -0.010199276730418205, time/batch=-4.935\n",
      "Extract of training data : [8] [1599]\n",
      "1083/16406, train loss is 10.546, state is 0.009990926831960678, time/batch=-5.067\n",
      "Extract of training data : [1599] [873]\n",
      "1084/16406, train loss is 10.546, state is -0.015401647426187992, time/batch=-4.971\n",
      "Extract of training data : [10378] [912]\n",
      "1085/16406, train loss is 10.546, state is 0.000497751752845943, time/batch=-4.968\n",
      "Extract of training data : [105] [371]\n",
      "1086/16406, train loss is 10.546, state is -0.002592438366264105, time/batch=-4.949\n",
      "Extract of training data : [371] [10]\n",
      "1087/16406, train loss is 10.546, state is 0.008897969499230385, time/batch=-4.943\n",
      "Extract of training data : [35] [1553]\n",
      "1088/16406, train loss is 10.546, state is -0.007623222656548023, time/batch=-5.022\n",
      "Extract of training data : [3] [23546]\n",
      "1089/16406, train loss is 10.546, state is 0.007190164644271135, time/batch=-5.030\n",
      "Extract of training data : [1745] [2853]\n",
      "1090/16406, train loss is 10.546, state is 0.014002691954374313, time/batch=-5.124\n",
      "Extract of training data : [3] [3]\n",
      "1091/16406, train loss is 10.546, state is -0.00027996228891424835, time/batch=-4.987\n",
      "Extract of training data : [3137] [10]\n",
      "1092/16406, train loss is 10.546, state is 0.014455494470894337, time/batch=-4.957\n",
      "Extract of training data : [256] [1078]\n",
      "1093/16406, train loss is 10.546, state is -0.02083374187350273, time/batch=-4.978\n",
      "Extract of training data : [5551] [571]\n",
      "1094/16406, train loss is 10.546, state is -0.006059036590158939, time/batch=-4.991\n",
      "Extract of training data : [164] [117]\n",
      "1095/16406, train loss is 10.546, state is -0.0030256586614996195, time/batch=-4.944\n",
      "Extract of training data : [1002] [21402]\n",
      "1096/16406, train loss is 10.546, state is -0.010606453754007816, time/batch=-5.047\n",
      "Extract of training data : [1265] [1289]\n",
      "1097/16406, train loss is 10.546, state is 0.015215776860713959, time/batch=-4.979\n",
      "Extract of training data : [10] [413]\n",
      "1098/16406, train loss is 10.546, state is -0.008640749379992485, time/batch=-4.816\n",
      "Extract of training data : [33275] [10]\n",
      "1099/16406, train loss is 10.546, state is -0.004399675410240889, time/batch=-4.841\n",
      "Extract of training data : [1197] [10]\n",
      "1100/16406, train loss is 10.546, state is 0.005334016866981983, time/batch=-4.900\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1188] [13896]\n",
      "1101/16406, train loss is 10.545, state is -0.009180027060210705, time/batch=-5.057\n",
      "Extract of training data : [344] [16557]\n",
      "1102/16406, train loss is 10.545, state is 0.0019073649309575558, time/batch=-4.892\n",
      "Extract of training data : [1198] [105]\n",
      "1103/16406, train loss is 10.546, state is 0.005638912785798311, time/batch=-4.869\n",
      "Extract of training data : [561] [1108]\n",
      "1104/16406, train loss is 10.546, state is -0.0027822665870189667, time/batch=-4.868\n",
      "Extract of training data : [50] [3792]\n",
      "1105/16406, train loss is 10.545, state is 0.003921572584658861, time/batch=-4.878\n",
      "Extract of training data : [32] [77]\n",
      "1106/16406, train loss is 10.545, state is 0.0038438141345977783, time/batch=-4.885\n",
      "Extract of training data : [24371] [35]\n",
      "1107/16406, train loss is 10.546, state is 0.01416975911706686, time/batch=-4.966\n",
      "Extract of training data : [33733] [10]\n",
      "1108/16406, train loss is 10.546, state is -0.0015504722250625491, time/batch=-5.855\n",
      "Extract of training data : [3] [3]\n",
      "1109/16406, train loss is 10.546, state is -0.010473544709384441, time/batch=-5.184\n",
      "Extract of training data : [4299] [14537]\n",
      "1110/16406, train loss is 10.546, state is 0.0015422697179019451, time/batch=-4.911\n",
      "Extract of training data : [10] [146]\n",
      "1111/16406, train loss is 10.545, state is -0.008629048243165016, time/batch=-4.997\n",
      "Extract of training data : [2985] [3315]\n",
      "1112/16406, train loss is 10.545, state is -0.0008067575981840491, time/batch=-4.896\n",
      "Extract of training data : [3] [164]\n",
      "1113/16406, train loss is 10.545, state is -0.002943585626780987, time/batch=-4.965\n",
      "Extract of training data : [105] [16]\n",
      "1114/16406, train loss is 10.546, state is -0.004557873122394085, time/batch=-4.923\n",
      "Extract of training data : [3] [27283]\n",
      "1115/16406, train loss is 10.546, state is 0.024849388748407364, time/batch=-4.853\n",
      "Extract of training data : [15444] [26029]\n",
      "1116/16406, train loss is 10.545, state is -0.0026613608933985233, time/batch=-5.022\n",
      "Extract of training data : [10] [34177]\n",
      "1117/16406, train loss is 10.546, state is -0.00922116544097662, time/batch=-5.085\n",
      "Extract of training data : [2121] [51]\n",
      "1118/16406, train loss is 10.546, state is 0.010079729370772839, time/batch=-5.042\n",
      "Extract of training data : [71] [5846]\n",
      "1119/16406, train loss is 10.546, state is 0.004754167515784502, time/batch=-5.329\n",
      "Extract of training data : [13476] [35]\n",
      "1120/16406, train loss is 10.545, state is 0.01015760563313961, time/batch=-4.388\n",
      "Extract of training data : [951] [105]\n",
      "1121/16406, train loss is 10.546, state is -0.0184633769094944, time/batch=-4.477\n",
      "Extract of training data : [3] [3]\n",
      "1122/16406, train loss is 10.546, state is 0.013757647015154362, time/batch=-4.417\n",
      "Extract of training data : [66] [10]\n",
      "1123/16406, train loss is 10.546, state is -0.011439413763582706, time/batch=-4.397\n",
      "Extract of training data : [111] [1416]\n",
      "1124/16406, train loss is 10.546, state is -0.015913138166069984, time/batch=-4.423\n",
      "Extract of training data : [1874] [256]\n",
      "1125/16406, train loss is 10.546, state is -0.0015394941437989473, time/batch=-4.326\n",
      "Extract of training data : [943] [2559]\n",
      "1126/16406, train loss is 10.546, state is -0.011100604198873043, time/batch=-4.389\n",
      "Extract of training data : [10] [1108]\n",
      "1127/16406, train loss is 10.545, state is -0.01716703549027443, time/batch=-4.307\n",
      "Extract of training data : [3732] [289]\n",
      "1128/16406, train loss is 10.546, state is -0.012871486134827137, time/batch=-4.333\n",
      "Extract of training data : [5351] [4130]\n",
      "1129/16406, train loss is 10.545, state is -0.005014303606003523, time/batch=-4.355\n",
      "Extract of training data : [277] [873]\n",
      "1130/16406, train loss is 10.546, state is -0.022363021969795227, time/batch=-4.365\n",
      "Extract of training data : [5780] [31849]\n",
      "1131/16406, train loss is 10.547, state is 0.008167915977537632, time/batch=-4.382\n",
      "Extract of training data : [0] [0]\n",
      "1132/16406, train loss is 10.546, state is 0.005431664641946554, time/batch=-4.373\n",
      "Extract of training data : [6253] [10]\n",
      "1133/16406, train loss is 10.546, state is -0.0040220231749117374, time/batch=-4.326\n",
      "Extract of training data : [904] [34937]\n",
      "1134/16406, train loss is 10.547, state is 0.02975098043680191, time/batch=-4.308\n",
      "Extract of training data : [7281] [117]\n",
      "1135/16406, train loss is 10.546, state is 0.003570378292351961, time/batch=-4.357\n",
      "Extract of training data : [16] [280]\n",
      "1136/16406, train loss is 10.545, state is -0.00589317362755537, time/batch=-4.620\n",
      "Extract of training data : [35109] [2861]\n",
      "1137/16406, train loss is 10.545, state is 0.007175080943852663, time/batch=-5.150\n",
      "Extract of training data : [35] [24498]\n",
      "1138/16406, train loss is 10.545, state is 0.0019252789206802845, time/batch=-5.034\n",
      "Extract of training data : [2736] [920]\n",
      "1139/16406, train loss is 10.545, state is -0.014512055553495884, time/batch=-4.905\n",
      "Extract of training data : [2284] [675]\n",
      "1140/16406, train loss is 10.546, state is -0.005495884921401739, time/batch=-4.981\n",
      "Extract of training data : [22143] [16]\n",
      "1141/16406, train loss is 10.546, state is -0.004900468047708273, time/batch=-4.863\n",
      "Extract of training data : [532] [71]\n",
      "1142/16406, train loss is 10.546, state is -0.01156393252313137, time/batch=-4.945\n",
      "Extract of training data : [1] [1]\n",
      "1143/16406, train loss is 10.545, state is -0.013242245651781559, time/batch=-4.958\n",
      "Extract of training data : [2135] [10245]\n",
      "1144/16406, train loss is 10.546, state is -0.023016436025500298, time/batch=-4.873\n",
      "Extract of training data : [699] [436]\n",
      "1145/16406, train loss is 10.545, state is 0.008641145192086697, time/batch=-4.862\n",
      "Extract of training data : [1137] [35]\n",
      "1146/16406, train loss is 10.545, state is 0.012898963876068592, time/batch=-4.899\n",
      "Extract of training data : [35660] [912]\n",
      "1147/16406, train loss is 10.546, state is -0.0013367810752242804, time/batch=-4.938\n",
      "Extract of training data : [15010] [3268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/16406, train loss is 10.546, state is 0.005176798440515995, time/batch=-4.932\n",
      "Extract of training data : [6962] [164]\n",
      "1149/16406, train loss is 10.546, state is -0.0018254215829074383, time/batch=-4.976\n",
      "Extract of training data : [3] [3]\n",
      "1150/16406, train loss is 10.545, state is 0.014761723577976227, time/batch=-4.889\n",
      "Extract of training data : [666] [10]\n",
      "1151/16406, train loss is 10.545, state is -0.01845943182706833, time/batch=-4.962\n",
      "Extract of training data : [10] [1785]\n",
      "1152/16406, train loss is 10.546, state is -0.01330582145601511, time/batch=-5.013\n",
      "Extract of training data : [177] [105]\n",
      "1153/16406, train loss is 10.545, state is -0.0024599856697022915, time/batch=-4.923\n",
      "Extract of training data : [581] [105]\n",
      "1154/16406, train loss is 10.545, state is -0.015078271739184856, time/batch=-4.892\n",
      "Extract of training data : [10] [6891]\n",
      "1155/16406, train loss is 10.545, state is -0.011005662381649017, time/batch=-4.930\n",
      "Extract of training data : [36002] [10]\n",
      "1156/16406, train loss is 10.545, state is -0.010503210127353668, time/batch=-5.009\n",
      "Extract of training data : [10] [1626]\n",
      "1157/16406, train loss is 10.546, state is -0.010159413330256939, time/batch=-4.903\n",
      "Extract of training data : [811] [10839]\n",
      "1158/16406, train loss is 10.546, state is -0.012443658895790577, time/batch=-4.942\n",
      "Extract of training data : [16018] [10]\n",
      "1159/16406, train loss is 10.545, state is -0.001183388289064169, time/batch=-4.933\n",
      "Extract of training data : [6027] [35]\n",
      "1160/16406, train loss is 10.545, state is 0.014371911995112896, time/batch=-4.992\n",
      "Extract of training data : [1872] [45]\n",
      "1161/16406, train loss is 10.546, state is -0.005471858195960522, time/batch=-4.976\n",
      "Extract of training data : [3758] [423]\n",
      "1162/16406, train loss is 10.545, state is -0.0138357849791646, time/batch=-4.981\n",
      "Extract of training data : [3] [3]\n",
      "1163/16406, train loss is 10.546, state is -0.005413620732724667, time/batch=-4.987\n",
      "Extract of training data : [35] [2802]\n",
      "1164/16406, train loss is 10.545, state is -0.0035282764583826065, time/batch=-5.095\n",
      "Extract of training data : [811] [10]\n",
      "1165/16406, train loss is 10.545, state is -0.00022296389215625823, time/batch=-5.022\n",
      "Extract of training data : [3] [3]\n",
      "1166/16406, train loss is 10.546, state is 0.004397292155772448, time/batch=-4.939\n",
      "Extract of training data : [0] [0]\n",
      "1167/16406, train loss is 10.545, state is -0.023751823231577873, time/batch=-4.953\n",
      "Extract of training data : [8130] [10]\n",
      "1168/16406, train loss is 10.545, state is 0.005756548140197992, time/batch=-4.882\n",
      "Extract of training data : [5556] [10]\n",
      "1169/16406, train loss is 10.545, state is 0.012270977720618248, time/batch=-5.018\n",
      "Extract of training data : [10378] [35]\n",
      "1170/16406, train loss is 10.545, state is -0.0012049599317833781, time/batch=-4.899\n",
      "Extract of training data : [14454] [595]\n",
      "1171/16406, train loss is 10.545, state is 0.00202298816293478, time/batch=-4.984\n",
      "Extract of training data : [6962] [35]\n",
      "1172/16406, train loss is 10.546, state is 0.01848519779741764, time/batch=-5.050\n",
      "Extract of training data : [2492] [105]\n",
      "1173/16406, train loss is 10.545, state is 7.907242252258584e-05, time/batch=-5.061\n",
      "Extract of training data : [35] [2039]\n",
      "1174/16406, train loss is 10.546, state is -0.009504263289272785, time/batch=-5.073\n",
      "Extract of training data : [1348] [6566]\n",
      "1175/16406, train loss is 10.545, state is 0.005942056886851788, time/batch=-5.115\n",
      "Extract of training data : [5499] [10]\n",
      "1176/16406, train loss is 10.545, state is -0.0019497134489938617, time/batch=-4.972\n",
      "Extract of training data : [1078] [280]\n",
      "1177/16406, train loss is 10.546, state is 0.010319959372282028, time/batch=-5.075\n",
      "Extract of training data : [901] [559]\n",
      "1178/16406, train loss is 10.546, state is 0.010255761444568634, time/batch=-4.998\n",
      "Extract of training data : [0] [1]\n",
      "1179/16406, train loss is 10.547, state is 0.00017631259106565267, time/batch=-5.116\n",
      "Extract of training data : [3] [3]\n",
      "1180/16406, train loss is 10.547, state is -0.0024916338734328747, time/batch=-5.045\n",
      "Extract of training data : [280] [3763]\n",
      "1181/16406, train loss is 10.546, state is 0.0045667411759495735, time/batch=-4.991\n",
      "Extract of training data : [105] [10]\n",
      "1182/16406, train loss is 10.546, state is 0.009655112400650978, time/batch=-4.916\n",
      "Extract of training data : [4213] [29]\n",
      "1183/16406, train loss is 10.546, state is -0.006229587830603123, time/batch=-4.890\n",
      "Extract of training data : [10] [777]\n",
      "1184/16406, train loss is 10.545, state is -0.01784955896437168, time/batch=-4.875\n",
      "Extract of training data : [556] [10]\n",
      "1185/16406, train loss is 10.545, state is 0.007444330956786871, time/batch=-4.993\n",
      "Extract of training data : [0] [0]\n",
      "1186/16406, train loss is 10.546, state is -0.005221391562372446, time/batch=-4.844\n",
      "Extract of training data : [105] [1742]\n",
      "1187/16406, train loss is 10.545, state is 0.008281507529318333, time/batch=-4.986\n",
      "Extract of training data : [3149] [5259]\n",
      "1188/16406, train loss is 10.546, state is -0.004712603986263275, time/batch=-4.952\n",
      "Extract of training data : [3] [3408]\n",
      "1189/16406, train loss is 10.546, state is 0.007659093476831913, time/batch=-4.867\n",
      "Extract of training data : [3674] [16]\n",
      "1190/16406, train loss is 10.546, state is -0.004739841911941767, time/batch=-5.077\n",
      "Extract of training data : [4581] [105]\n",
      "1191/16406, train loss is 10.545, state is -0.011647190898656845, time/batch=-4.922\n",
      "Extract of training data : [344] [4086]\n",
      "1192/16406, train loss is 10.545, state is 0.012213155627250671, time/batch=-4.996\n",
      "Extract of training data : [9275] [1601]\n",
      "1193/16406, train loss is 10.546, state is 0.018289882689714432, time/batch=-4.882\n",
      "Extract of training data : [16] [280]\n",
      "1194/16406, train loss is 10.545, state is -0.00011610302317421883, time/batch=-4.928\n",
      "Extract of training data : [4422] [7432]\n",
      "1195/16406, train loss is 10.546, state is 0.006786859594285488, time/batch=-5.009\n",
      "Extract of training data : [0] [3]\n",
      "1196/16406, train loss is 10.546, state is -0.015427044592797756, time/batch=-4.941\n",
      "Extract of training data : [6585] [2825]\n",
      "1197/16406, train loss is 10.546, state is -0.010686850175261497, time/batch=-5.004\n",
      "Extract of training data : [105] [10066]\n",
      "1198/16406, train loss is 10.545, state is 0.006002063397318125, time/batch=-4.966\n",
      "Extract of training data : [16] [912]\n",
      "1199/16406, train loss is 10.546, state is -0.005960332229733467, time/batch=-4.868\n",
      "Extract of training data : [647] [1826]\n",
      "1200/16406, train loss is 10.545, state is -0.0061074779368937016, time/batch=-4.938\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [0] [1]\n",
      "1201/16406, train loss is 10.545, state is 0.02005310356616974, time/batch=-5.138\n",
      "Extract of training data : [4842] [10]\n",
      "1202/16406, train loss is 10.546, state is -0.0057656848803162575, time/batch=-5.047\n",
      "Extract of training data : [105] [980]\n",
      "1203/16406, train loss is 10.546, state is -0.021705348044633865, time/batch=-4.924\n",
      "Extract of training data : [10739] [12]\n",
      "1204/16406, train loss is 10.546, state is 0.015273623168468475, time/batch=-4.930\n",
      "Extract of training data : [0] [0]\n",
      "1205/16406, train loss is 10.545, state is 0.008279846049845219, time/batch=-4.985\n",
      "Extract of training data : [458] [174]\n",
      "1206/16406, train loss is 10.545, state is 0.004146073013544083, time/batch=-4.939\n",
      "Extract of training data : [4450] [105]\n",
      "1207/16406, train loss is 10.546, state is -0.004925969988107681, time/batch=-4.986\n",
      "Extract of training data : [117] [16]\n",
      "1208/16406, train loss is 10.546, state is -0.010875588282942772, time/batch=-4.900\n",
      "Extract of training data : [0] [3]\n",
      "1209/16406, train loss is 10.546, state is -0.003876669332385063, time/batch=-4.911\n",
      "Extract of training data : [105] [10]\n",
      "1210/16406, train loss is 10.546, state is -0.014710734598338604, time/batch=-4.974\n",
      "Extract of training data : [2377] [10]\n",
      "1211/16406, train loss is 10.546, state is -0.004424432758241892, time/batch=-5.021\n",
      "Extract of training data : [8] [277]\n",
      "1212/16406, train loss is 10.546, state is -0.008097855374217033, time/batch=-4.907\n",
      "Extract of training data : [10] [3732]\n",
      "1213/16406, train loss is 10.545, state is -0.004720955155789852, time/batch=-5.033\n",
      "Extract of training data : [4167] [245]\n",
      "1214/16406, train loss is 10.545, state is -0.002551381243392825, time/batch=-4.952\n",
      "Extract of training data : [943] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1215/16406, train loss is 10.546, state is -0.0023319607134908438, time/batch=-4.997\n",
      "Extract of training data : [35] [10]\n",
      "1216/16406, train loss is 10.546, state is -0.011800598353147507, time/batch=-4.984\n",
      "Extract of training data : [820] [12377]\n",
      "1217/16406, train loss is 10.546, state is 0.0072078825905919075, time/batch=-4.849\n",
      "Extract of training data : [12511] [10]\n",
      "1218/16406, train loss is 10.546, state is 0.011498693376779556, time/batch=-4.886\n",
      "Extract of training data : [12] [6027]\n",
      "1219/16406, train loss is 10.546, state is 0.003954026382416487, time/batch=-4.941\n",
      "Extract of training data : [259] [10]\n",
      "1220/16406, train loss is 10.546, state is -0.021868130192160606, time/batch=-4.924\n",
      "Extract of training data : [12970] [1119]\n",
      "1221/16406, train loss is 10.545, state is -0.022119224071502686, time/batch=-4.878\n",
      "Extract of training data : [524] [844]\n",
      "1222/16406, train loss is 10.546, state is 0.014258584007620811, time/batch=-4.932\n",
      "Extract of training data : [2147] [12]\n",
      "1223/16406, train loss is 10.546, state is 0.0026257229037582874, time/batch=-4.893\n",
      "Extract of training data : [1171] [11230]\n",
      "1224/16406, train loss is 10.546, state is -0.025815660133957863, time/batch=-4.866\n",
      "Extract of training data : [13473] [10]\n",
      "1225/16406, train loss is 10.546, state is -0.004789472557604313, time/batch=-4.940\n",
      "Extract of training data : [13794] [2045]\n",
      "1226/16406, train loss is 10.545, state is 0.005394291132688522, time/batch=-4.862\n",
      "Extract of training data : [29] [12581]\n",
      "1227/16406, train loss is 10.545, state is -0.004666214808821678, time/batch=-4.934\n",
      "Extract of training data : [13483] [10]\n",
      "1228/16406, train loss is 10.545, state is 0.015615278854966164, time/batch=-4.906\n",
      "Extract of training data : [359] [2039]\n",
      "1229/16406, train loss is 10.545, state is -0.03019680455327034, time/batch=-4.965\n",
      "Extract of training data : [2050] [13961]\n",
      "1230/16406, train loss is 10.545, state is -0.0010377226863056421, time/batch=-4.873\n",
      "Extract of training data : [10] [2886]\n",
      "1231/16406, train loss is 10.545, state is -0.005374572705477476, time/batch=-4.912\n",
      "Extract of training data : [277] [3379]\n",
      "1232/16406, train loss is 10.546, state is 0.00022906294907443225, time/batch=-4.895\n",
      "Extract of training data : [10] [14567]\n",
      "1233/16406, train loss is 10.545, state is -0.009940250776708126, time/batch=-4.880\n",
      "Extract of training data : [13293] [3285]\n",
      "1234/16406, train loss is 10.545, state is -0.017111342400312424, time/batch=-5.029\n",
      "Extract of training data : [877] [280]\n",
      "1235/16406, train loss is 10.545, state is -0.01553407870233059, time/batch=-4.938\n",
      "Extract of training data : [413] [71]\n",
      "1236/16406, train loss is 10.545, state is -0.0021627526730298996, time/batch=-4.888\n",
      "Extract of training data : [10] [1637]\n",
      "1237/16406, train loss is 10.545, state is -0.012802801094949245, time/batch=-4.881\n",
      "Extract of training data : [151] [10]\n",
      "1238/16406, train loss is 10.545, state is -0.01723419316112995, time/batch=-4.896\n",
      "Extract of training data : [906] [13737]\n",
      "1239/16406, train loss is 10.546, state is -0.0033263368532061577, time/batch=-4.868\n",
      "Extract of training data : [10] [15284]\n",
      "1240/16406, train loss is 10.545, state is 0.007555937394499779, time/batch=-4.952\n",
      "Extract of training data : [15218] [514]\n",
      "1241/16406, train loss is 10.545, state is -0.0059199766255915165, time/batch=-4.886\n",
      "Extract of training data : [465] [146]\n",
      "1242/16406, train loss is 10.545, state is -0.008267443627119064, time/batch=-4.924\n",
      "Extract of training data : [3] [910]\n",
      "1243/16406, train loss is 10.546, state is -0.0029610188212245703, time/batch=-4.900\n",
      "Extract of training data : [0] [3]\n",
      "1244/16406, train loss is 10.546, state is -0.007661733310669661, time/batch=-4.891\n",
      "Extract of training data : [55] [15900]\n",
      "1245/16406, train loss is 10.546, state is -0.0023732439149171114, time/batch=-4.927\n",
      "Extract of training data : [16019] [10]\n",
      "1246/16406, train loss is 10.545, state is 0.006784879602491856, time/batch=-4.891\n",
      "Extract of training data : [495] [50]\n",
      "1247/16406, train loss is 10.546, state is 0.007669499143958092, time/batch=-4.915\n",
      "Extract of training data : [3] [582]\n",
      "1248/16406, train loss is 10.546, state is -0.010248948819935322, time/batch=-4.902\n",
      "Extract of training data : [283] [2275]\n",
      "1249/16406, train loss is 10.545, state is -0.0014605573378503323, time/batch=-4.879\n",
      "Extract of training data : [924] [3196]\n",
      "1250/16406, train loss is 10.546, state is 0.009198940359055996, time/batch=-4.906\n",
      "Extract of training data : [10] [6213]\n",
      "1251/16406, train loss is 10.546, state is 0.01293516717851162, time/batch=-4.909\n",
      "Extract of training data : [10] [1038]\n",
      "1252/16406, train loss is 10.546, state is 0.007036148104816675, time/batch=-4.957\n",
      "Extract of training data : [3611] [71]\n",
      "1253/16406, train loss is 10.546, state is -0.00029944017296656966, time/batch=-5.034\n",
      "Extract of training data : [16] [846]\n",
      "1254/16406, train loss is 10.545, state is -0.008735204115509987, time/batch=-4.952\n",
      "Extract of training data : [3142] [5653]\n",
      "1255/16406, train loss is 10.546, state is -0.0019321935251355171, time/batch=-5.082\n",
      "Extract of training data : [35] [5065]\n",
      "1256/16406, train loss is 10.546, state is -0.012478743679821491, time/batch=-4.892\n",
      "Extract of training data : [5710] [2135]\n",
      "1257/16406, train loss is 10.545, state is -0.005380965303629637, time/batch=-4.887\n",
      "Extract of training data : [9458] [280]\n",
      "1258/16406, train loss is 10.545, state is 0.002951785223558545, time/batch=-5.073\n",
      "Extract of training data : [13587] [10231]\n",
      "1259/16406, train loss is 10.546, state is 0.006250837817788124, time/batch=-4.995\n",
      "Extract of training data : [0] [0]\n",
      "1260/16406, train loss is 10.545, state is 0.016783256083726883, time/batch=-5.048\n",
      "Extract of training data : [877] [0]\n",
      "1261/16406, train loss is 10.546, state is 0.0004352547985035926, time/batch=-4.889\n",
      "Extract of training data : [3] [3]\n",
      "1262/16406, train loss is 10.545, state is -0.010322642512619495, time/batch=-4.872\n",
      "Extract of training data : [2437] [559]\n",
      "1263/16406, train loss is 10.546, state is 0.021621419116854668, time/batch=-5.017\n",
      "Extract of training data : [3] [3]\n",
      "1264/16406, train loss is 10.546, state is 0.016797631978988647, time/batch=-4.922\n",
      "Extract of training data : [16] [0]\n",
      "1265/16406, train loss is 10.545, state is -0.0052885799668729305, time/batch=-4.893\n",
      "Extract of training data : [17913] [164]\n",
      "1266/16406, train loss is 10.546, state is -0.006477902643382549, time/batch=-4.972\n",
      "Extract of training data : [371] [10]\n",
      "1267/16406, train loss is 10.545, state is -0.0021820191759616137, time/batch=-4.989\n",
      "Extract of training data : [344] [901]\n",
      "1268/16406, train loss is 10.545, state is 0.0031353498343378305, time/batch=-5.337\n",
      "Extract of training data : [10] [23]\n",
      "1269/16406, train loss is 10.545, state is -0.0026490408927202225, time/batch=-4.893\n",
      "Extract of training data : [8] [277]\n",
      "1270/16406, train loss is 10.545, state is 0.01804332062602043, time/batch=-4.885\n",
      "Extract of training data : [3] [3]\n",
      "1271/16406, train loss is 10.546, state is 0.012190230190753937, time/batch=-4.910\n",
      "Extract of training data : [442] [6530]\n",
      "1272/16406, train loss is 10.545, state is 0.01512851007282734, time/batch=-4.858\n",
      "Extract of training data : [3] [3]\n",
      "1273/16406, train loss is 10.545, state is -0.006553475745022297, time/batch=-4.899\n",
      "Extract of training data : [10] [121]\n",
      "1274/16406, train loss is 10.546, state is 0.0061034406535327435, time/batch=-4.905\n",
      "Extract of training data : [2854] [10]\n",
      "1275/16406, train loss is 10.545, state is -5.580902143265121e-05, time/batch=-4.897\n",
      "Extract of training data : [0] [3]\n",
      "1276/16406, train loss is 10.546, state is 0.007092057261615992, time/batch=-4.892\n",
      "Extract of training data : [108] [17042]\n",
      "1277/16406, train loss is 10.546, state is 0.012855039909482002, time/batch=-4.964\n",
      "Extract of training data : [16049] [811]\n",
      "1278/16406, train loss is 10.545, state is -0.016670124605298042, time/batch=-4.942\n",
      "Extract of training data : [21674] [2742]\n",
      "1279/16406, train loss is 10.545, state is -0.008386939764022827, time/batch=-4.955\n",
      "Extract of training data : [2137] [10]\n",
      "1280/16406, train loss is 10.545, state is 0.022410985082387924, time/batch=-5.038\n",
      "Extract of training data : [10] [1133]\n",
      "1281/16406, train loss is 10.546, state is 0.000734193017706275, time/batch=-4.952\n",
      "Extract of training data : [10] [4950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282/16406, train loss is 10.546, state is 0.010040005668997765, time/batch=-4.888\n",
      "Extract of training data : [910] [1006]\n",
      "1283/16406, train loss is 10.546, state is 0.011128460057079792, time/batch=-4.950\n",
      "Extract of training data : [920] [28]\n",
      "1284/16406, train loss is 10.546, state is -0.0030113288667052984, time/batch=-4.980\n",
      "Extract of training data : [0] [0]\n",
      "1285/16406, train loss is 10.545, state is 0.0019348332425579429, time/batch=-5.021\n",
      "Extract of training data : [10] [2639]\n",
      "1286/16406, train loss is 10.546, state is -0.00032805048977024853, time/batch=-4.987\n",
      "Extract of training data : [1575] [50]\n",
      "1287/16406, train loss is 10.546, state is -0.011942173354327679, time/batch=-4.979\n",
      "Extract of training data : [3] [873]\n",
      "1288/16406, train loss is 10.546, state is 0.0013847565278410912, time/batch=-4.951\n",
      "Extract of training data : [16] [894]\n",
      "1289/16406, train loss is 10.545, state is 0.0010058608604595065, time/batch=-5.011\n",
      "Extract of training data : [2398] [3515]\n",
      "1290/16406, train loss is 10.546, state is -0.006398740224540234, time/batch=-4.967\n",
      "Extract of training data : [623] [8391]\n",
      "1291/16406, train loss is 10.546, state is 0.0025621766690164804, time/batch=-4.981\n",
      "Extract of training data : [1131] [13365]\n",
      "1292/16406, train loss is 10.545, state is 0.00017216427659150213, time/batch=-4.928\n",
      "Extract of training data : [174] [3383]\n",
      "1293/16406, train loss is 10.545, state is 0.003580772550776601, time/batch=-5.045\n",
      "Extract of training data : [548] [2132]\n",
      "1294/16406, train loss is 10.546, state is -0.014694707468152046, time/batch=-4.953\n",
      "Extract of training data : [6891] [16]\n",
      "1295/16406, train loss is 10.545, state is -0.010125108063220978, time/batch=-5.056\n",
      "Extract of training data : [3749] [471]\n",
      "1296/16406, train loss is 10.545, state is -0.00381552055478096, time/batch=-4.909\n",
      "Extract of training data : [35] [3211]\n",
      "1297/16406, train loss is 10.546, state is 0.006127453409135342, time/batch=-5.040\n",
      "Extract of training data : [10] [413]\n",
      "1298/16406, train loss is 10.546, state is -0.012405200861394405, time/batch=-4.975\n",
      "Extract of training data : [16] [0]\n",
      "1299/16406, train loss is 10.546, state is -0.01591157168149948, time/batch=-4.923\n",
      "Extract of training data : [3732] [10]\n",
      "1300/16406, train loss is 10.545, state is 0.003962880931794643, time/batch=-5.008\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1507] [10]\n",
      "1301/16406, train loss is 10.546, state is -0.010031739249825478, time/batch=-5.396\n",
      "Extract of training data : [7183] [2051]\n",
      "1302/16406, train loss is 10.546, state is 0.0006287692813202739, time/batch=-4.979\n",
      "Extract of training data : [174] [105]\n",
      "1303/16406, train loss is 10.546, state is -0.014361893758177757, time/batch=-4.947\n",
      "Extract of training data : [10] [1741]\n",
      "1304/16406, train loss is 10.546, state is 0.0006636774051003158, time/batch=-4.926\n",
      "Extract of training data : [20707] [10]\n",
      "1305/16406, train loss is 10.546, state is 0.0024201509077101946, time/batch=-5.076\n",
      "Extract of training data : [164] [2159]\n",
      "1306/16406, train loss is 10.545, state is 0.008516193367540836, time/batch=-4.947\n",
      "Extract of training data : [524] [624]\n",
      "1307/16406, train loss is 10.546, state is -0.007929257117211819, time/batch=-5.015\n",
      "Extract of training data : [0] [3]\n",
      "1308/16406, train loss is 10.545, state is -0.001982783665880561, time/batch=-5.113\n",
      "Extract of training data : [10] [557]\n",
      "1309/16406, train loss is 10.546, state is -0.010041149333119392, time/batch=-4.992\n",
      "Extract of training data : [35] [2039]\n",
      "1310/16406, train loss is 10.546, state is 0.00481748953461647, time/batch=-5.108\n",
      "Extract of training data : [7] [8]\n",
      "1311/16406, train loss is 10.546, state is 0.001594429835677147, time/batch=-5.078\n",
      "Extract of training data : [10] [1825]\n",
      "1312/16406, train loss is 10.546, state is -0.000919711368624121, time/batch=-5.043\n",
      "Extract of training data : [3024] [35]\n",
      "1313/16406, train loss is 10.546, state is -0.003527172841131687, time/batch=-5.058\n",
      "Extract of training data : [583] [71]\n",
      "1314/16406, train loss is 10.545, state is -0.001999092288315296, time/batch=-4.952\n",
      "Extract of training data : [1481] [804]\n",
      "1315/16406, train loss is 10.546, state is 0.025248514488339424, time/batch=-5.222\n",
      "Extract of training data : [3] [29]\n",
      "1316/16406, train loss is 10.546, state is 0.015088318847119808, time/batch=-5.060\n",
      "Extract of training data : [13960] [10]\n",
      "1317/16406, train loss is 10.546, state is 0.012541168369352818, time/batch=-5.014\n",
      "Extract of training data : [19037] [5004]\n",
      "1318/16406, train loss is 10.546, state is 0.009567022323608398, time/batch=-4.995\n",
      "Extract of training data : [545] [86]\n",
      "1319/16406, train loss is 10.546, state is -0.01805434748530388, time/batch=-5.037\n",
      "Extract of training data : [10] [5157]\n",
      "1320/16406, train loss is 10.545, state is -0.011524133384227753, time/batch=-5.036\n",
      "Extract of training data : [458] [2304]\n",
      "1321/16406, train loss is 10.545, state is -0.01187680009752512, time/batch=-5.018\n",
      "Extract of training data : [20] [3230]\n",
      "1322/16406, train loss is 10.545, state is -0.0028956588357686996, time/batch=-4.919\n",
      "Extract of training data : [3] [3]\n",
      "1323/16406, train loss is 10.546, state is 0.0012996059376746416, time/batch=-5.112\n",
      "Extract of training data : [6429] [35]\n",
      "1324/16406, train loss is 10.546, state is -0.0053183538839221, time/batch=-4.949\n",
      "Extract of training data : [912] [1569]\n",
      "1325/16406, train loss is 10.546, state is -0.016993805766105652, time/batch=-5.102\n",
      "Extract of training data : [33] [23035]\n",
      "1326/16406, train loss is 10.546, state is 0.0030589685775339603, time/batch=-5.084\n",
      "Extract of training data : [1188] [29]\n",
      "1327/16406, train loss is 10.546, state is -0.008455293253064156, time/batch=-5.121\n",
      "Extract of training data : [3208] [1185]\n",
      "1328/16406, train loss is 10.546, state is 0.0023021860979497433, time/batch=-5.156\n",
      "Extract of training data : [2050] [2679]\n",
      "1329/16406, train loss is 10.546, state is 0.013446938246488571, time/batch=-5.139\n",
      "Extract of training data : [0] [0]\n",
      "1330/16406, train loss is 10.546, state is 0.00554271973669529, time/batch=-4.934\n",
      "Extract of training data : [6838] [2225]\n",
      "1331/16406, train loss is 10.546, state is -0.009820827282965183, time/batch=-4.974\n",
      "Extract of training data : [3] [1085]\n",
      "1332/16406, train loss is 10.546, state is -0.005599189084023237, time/batch=-5.034\n",
      "Extract of training data : [3] [3]\n",
      "1333/16406, train loss is 10.545, state is -0.006237817462533712, time/batch=-4.953\n",
      "Extract of training data : [77] [105]\n",
      "1334/16406, train loss is 10.546, state is 0.00939340889453888, time/batch=-5.025\n",
      "Extract of training data : [16] [846]\n",
      "1335/16406, train loss is 10.546, state is 0.0027023879811167717, time/batch=-4.993\n",
      "Extract of training data : [6077] [10]\n",
      "1336/16406, train loss is 10.546, state is 0.010784102603793144, time/batch=-4.963\n",
      "Extract of training data : [9927] [2492]\n",
      "1337/16406, train loss is 10.545, state is -0.004596737679094076, time/batch=-4.999\n",
      "Extract of training data : [10563] [1699]\n",
      "1338/16406, train loss is 10.546, state is -0.0068716974928975105, time/batch=-4.964\n",
      "Extract of training data : [2853] [6286]\n",
      "1339/16406, train loss is 10.546, state is -0.008408264257013798, time/batch=-4.979\n",
      "Extract of training data : [21477] [23543]\n",
      "1340/16406, train loss is 10.546, state is -0.0030953919049352407, time/batch=-4.919\n",
      "Extract of training data : [737] [10]\n",
      "1341/16406, train loss is 10.546, state is -0.008528818376362324, time/batch=-4.889\n",
      "Extract of training data : [16] [12344]\n",
      "1342/16406, train loss is 10.546, state is 0.0021011349745094776, time/batch=-4.951\n",
      "Extract of training data : [328] [1273]\n",
      "1343/16406, train loss is 10.546, state is 0.004190689884126186, time/batch=-5.089\n",
      "Extract of training data : [2308] [6146]\n",
      "1344/16406, train loss is 10.546, state is 0.002575047081336379, time/batch=-5.100\n",
      "Extract of training data : [196] [10]\n",
      "1345/16406, train loss is 10.546, state is 0.015781832858920097, time/batch=-5.123\n",
      "Extract of training data : [61] [1780]\n",
      "1346/16406, train loss is 10.546, state is 0.008311795070767403, time/batch=-5.048\n",
      "Extract of training data : [0] [3]\n",
      "1347/16406, train loss is 10.546, state is -0.009542044252157211, time/batch=-5.142\n",
      "Extract of training data : [5356] [10]\n",
      "1348/16406, train loss is 10.546, state is -0.01846333034336567, time/batch=-4.937\n",
      "Extract of training data : [37560] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349/16406, train loss is 10.546, state is 0.010719235055148602, time/batch=-5.163\n",
      "Extract of training data : [35] [24863]\n",
      "1350/16406, train loss is 10.546, state is -0.0034398287534713745, time/batch=-5.000\n",
      "Extract of training data : [3] [23535]\n",
      "1351/16406, train loss is 10.546, state is 0.0017098269890993834, time/batch=-5.012\n",
      "Extract of training data : [10] [1165]\n",
      "1352/16406, train loss is 10.546, state is 0.006481895688921213, time/batch=-5.119\n",
      "Extract of training data : [13159] [5930]\n",
      "1353/16406, train loss is 10.546, state is 0.0018918124260380864, time/batch=-5.096\n",
      "Extract of training data : [3197] [23950]\n",
      "1354/16406, train loss is 10.546, state is 0.008911952376365662, time/batch=-5.071\n",
      "Extract of training data : [2404] [3270]\n",
      "1355/16406, train loss is 10.546, state is 0.00042260659392923117, time/batch=-5.029\n",
      "Extract of training data : [850] [1481]\n",
      "1356/16406, train loss is 10.546, state is -0.004215030465275049, time/batch=-5.009\n",
      "Extract of training data : [18303] [1]\n",
      "1357/16406, train loss is 10.546, state is 0.0021554394625127316, time/batch=-5.046\n",
      "Extract of training data : [280] [422]\n",
      "1358/16406, train loss is 10.546, state is -0.0022000721655786037, time/batch=-5.006\n",
      "Extract of training data : [3] [3]\n",
      "1359/16406, train loss is 10.546, state is -0.012487808242440224, time/batch=-4.956\n",
      "Extract of training data : [10] [3125]\n",
      "1360/16406, train loss is 10.546, state is 0.003971627447754145, time/batch=-5.079\n",
      "Extract of training data : [10177] [10]\n",
      "1361/16406, train loss is 10.546, state is -0.016256973147392273, time/batch=-4.996\n",
      "Extract of training data : [29] [5880]\n",
      "1362/16406, train loss is 10.546, state is -0.010176138952374458, time/batch=-5.041\n",
      "Extract of training data : [35] [1293]\n",
      "1363/16406, train loss is 10.546, state is -0.0024084928445518017, time/batch=-4.969\n",
      "Extract of training data : [2883] [51]\n",
      "1364/16406, train loss is 10.546, state is -0.0006876033148728311, time/batch=-4.962\n",
      "Extract of training data : [3] [3]\n",
      "1365/16406, train loss is 10.546, state is 0.00396078871563077, time/batch=-4.914\n",
      "Extract of training data : [4281] [1483]\n",
      "1366/16406, train loss is 10.545, state is -0.0018423872534185648, time/batch=-4.948\n",
      "Extract of training data : [1293] [26201]\n",
      "1367/16406, train loss is 10.546, state is 0.0016292735235765576, time/batch=-4.982\n",
      "Extract of training data : [2597] [10]\n",
      "1368/16406, train loss is 10.546, state is -0.013925133273005486, time/batch=-4.951\n",
      "Extract of training data : [21] [17647]\n",
      "1369/16406, train loss is 10.546, state is -0.009808552451431751, time/batch=-4.930\n",
      "Extract of training data : [13628] [12]\n",
      "1370/16406, train loss is 10.546, state is 0.01280942466109991, time/batch=-4.917\n",
      "Extract of training data : [5313] [105]\n",
      "1371/16406, train loss is 10.546, state is -0.01368027739226818, time/batch=-4.998\n",
      "Extract of training data : [3] [3]\n",
      "1372/16406, train loss is 10.546, state is 0.0022226539440453053, time/batch=-4.933\n",
      "Extract of training data : [0] [3]\n",
      "1373/16406, train loss is 10.546, state is 0.005502075422555208, time/batch=-5.045\n",
      "Extract of training data : [737] [35]\n",
      "1374/16406, train loss is 10.546, state is 0.0037414671387523413, time/batch=-4.972\n",
      "Extract of training data : [21] [1171]\n",
      "1375/16406, train loss is 10.546, state is 0.009014569222927094, time/batch=-5.017\n",
      "Extract of training data : [10] [344]\n",
      "1376/16406, train loss is 10.546, state is 0.0015534533886238933, time/batch=-4.889\n",
      "Extract of training data : [3414] [16]\n",
      "1377/16406, train loss is 10.546, state is 0.005061393603682518, time/batch=-4.988\n",
      "Extract of training data : [2341] [7289]\n",
      "1378/16406, train loss is 10.545, state is 0.00564809562638402, time/batch=-4.918\n",
      "Extract of training data : [0] [0]\n",
      "1379/16406, train loss is 10.546, state is 0.0031388066709041595, time/batch=-4.928\n",
      "Extract of training data : [6485] [2970]\n",
      "1380/16406, train loss is 10.545, state is 0.0030108275823295116, time/batch=-4.901\n",
      "Extract of training data : [8] [277]\n",
      "1381/16406, train loss is 10.546, state is -0.006528761703521013, time/batch=-4.931\n",
      "Extract of training data : [10] [159]\n",
      "1382/16406, train loss is 10.545, state is -0.011108706705272198, time/batch=-4.886\n",
      "Extract of training data : [458] [15872]\n",
      "1383/16406, train loss is 10.545, state is 0.0138628501445055, time/batch=-4.934\n",
      "Extract of training data : [422] [143]\n",
      "1384/16406, train loss is 10.545, state is -0.02462073601782322, time/batch=-4.996\n",
      "Extract of training data : [7539] [27618]\n",
      "1385/16406, train loss is 10.546, state is -0.02253490872681141, time/batch=-5.015\n",
      "Extract of training data : [10] [901]\n",
      "1386/16406, train loss is 10.545, state is -0.0015079618897289038, time/batch=-4.972\n",
      "Extract of training data : [1087] [237]\n",
      "1387/16406, train loss is 10.545, state is -0.001112168887630105, time/batch=-5.146\n",
      "Extract of training data : [6528] [1220]\n",
      "1388/16406, train loss is 10.545, state is -0.019249795004725456, time/batch=-5.017\n",
      "Extract of training data : [1180] [10]\n",
      "1389/16406, train loss is 10.546, state is 0.0038329854141920805, time/batch=-4.940\n",
      "Extract of training data : [10] [50]\n",
      "1390/16406, train loss is 10.546, state is -0.006615308579057455, time/batch=-4.983\n",
      "Extract of training data : [19388] [51]\n",
      "1391/16406, train loss is 10.546, state is 0.0087824622169137, time/batch=-4.968\n",
      "Extract of training data : [1946] [2612]\n",
      "1392/16406, train loss is 10.546, state is 0.002690482186153531, time/batch=-4.946\n",
      "Extract of training data : [2300] [10]\n",
      "1393/16406, train loss is 10.546, state is -0.0005490605253726244, time/batch=-4.894\n",
      "Extract of training data : [105] [715]\n",
      "1394/16406, train loss is 10.546, state is 0.006783760152757168, time/batch=-4.968\n",
      "Extract of training data : [10] [28405]\n",
      "1395/16406, train loss is 10.546, state is 0.00923440046608448, time/batch=-5.029\n",
      "Extract of training data : [29] [28482]\n",
      "1396/16406, train loss is 10.545, state is -0.011513189412653446, time/batch=-4.899\n",
      "Extract of training data : [71] [5777]\n",
      "1397/16406, train loss is 10.546, state is -0.00015173100109677762, time/batch=-4.892\n",
      "Extract of training data : [1185] [29]\n",
      "1398/16406, train loss is 10.545, state is -0.005637248512357473, time/batch=-5.046\n",
      "Extract of training data : [105] [850]\n",
      "1399/16406, train loss is 10.546, state is 0.002486602170392871, time/batch=-5.075\n",
      "Extract of training data : [9745] [4441]\n",
      "1400/16406, train loss is 10.545, state is -0.01023935154080391, time/batch=-4.920\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [3154] [2844]\n",
      "1401/16406, train loss is 10.546, state is 0.014548239298164845, time/batch=-5.546\n",
      "Extract of training data : [16] [1785]\n",
      "1402/16406, train loss is 10.545, state is -0.009919741190969944, time/batch=-5.017\n",
      "Extract of training data : [688] [1846]\n",
      "1403/16406, train loss is 10.546, state is -0.011926905252039433, time/batch=-4.864\n",
      "Extract of training data : [1599] [6409]\n",
      "1404/16406, train loss is 10.546, state is 0.010678739286959171, time/batch=-4.921\n",
      "Extract of training data : [10886] [10]\n",
      "1405/16406, train loss is 10.546, state is -0.009289628826081753, time/batch=-4.975\n",
      "Extract of training data : [1507] [10]\n",
      "1406/16406, train loss is 10.546, state is 0.008330798707902431, time/batch=-4.990\n",
      "Extract of training data : [2182] [3404]\n",
      "1407/16406, train loss is 10.546, state is -0.006118223071098328, time/batch=-4.978\n",
      "Extract of training data : [1821] [51]\n",
      "1408/16406, train loss is 10.546, state is -0.014374040998518467, time/batch=-4.880\n",
      "Extract of training data : [10] [2910]\n",
      "1409/16406, train loss is 10.546, state is -0.0009416656102985144, time/batch=-4.986\n",
      "Extract of training data : [28963] [3743]\n",
      "1410/16406, train loss is 10.545, state is -0.012144183740019798, time/batch=-4.960\n",
      "Extract of training data : [29174] [35]\n",
      "1411/16406, train loss is 10.546, state is 0.0031979915220290422, time/batch=-5.037\n",
      "Extract of training data : [3203] [10]\n",
      "1412/16406, train loss is 10.545, state is 0.0031799646094441414, time/batch=-4.948\n",
      "Extract of training data : [16878] [35]\n",
      "1413/16406, train loss is 10.545, state is 0.0058794766664505005, time/batch=-4.963\n",
      "Extract of training data : [1081] [5124]\n",
      "1414/16406, train loss is 10.546, state is -0.01836451143026352, time/batch=-4.984\n",
      "Extract of training data : [3980] [2679]\n",
      "1415/16406, train loss is 10.545, state is 0.0080353282392025, time/batch=-4.937\n",
      "Extract of training data : [3] [5168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1416/16406, train loss is 10.546, state is 0.0003987153177149594, time/batch=-4.969\n",
      "Extract of training data : [10] [344]\n",
      "1417/16406, train loss is 10.546, state is 0.00893367175012827, time/batch=-4.948\n",
      "Extract of training data : [571] [6997]\n",
      "1418/16406, train loss is 10.546, state is 0.0122043676674366, time/batch=-4.864\n",
      "Extract of training data : [10] [571]\n",
      "1419/16406, train loss is 10.546, state is 0.012728283181786537, time/batch=-4.889\n",
      "Extract of training data : [910] [963]\n",
      "1420/16406, train loss is 10.546, state is -0.0021537868306040764, time/batch=-4.997\n",
      "Extract of training data : [1051] [8]\n",
      "1421/16406, train loss is 10.546, state is 0.004745887592434883, time/batch=-5.067\n",
      "Extract of training data : [2913] [16549]\n",
      "1422/16406, train loss is 10.545, state is 0.007783267181366682, time/batch=-5.058\n",
      "Extract of training data : [29715] [32]\n",
      "1423/16406, train loss is 10.545, state is 0.004639059770852327, time/batch=-5.059\n",
      "Extract of training data : [10] [688]\n",
      "1424/16406, train loss is 10.546, state is -0.0031460104510188103, time/batch=-5.212\n",
      "Extract of training data : [3] [3]\n",
      "1425/16406, train loss is 10.546, state is -0.0029283887706696987, time/batch=-4.989\n",
      "Extract of training data : [10] [633]\n",
      "1426/16406, train loss is 10.546, state is -0.01173478364944458, time/batch=-5.023\n",
      "Extract of training data : [3] [291]\n",
      "1427/16406, train loss is 10.545, state is -0.01649087853729725, time/batch=-4.920\n",
      "Extract of training data : [3055] [71]\n",
      "1428/16406, train loss is 10.546, state is 0.010913657024502754, time/batch=-5.112\n",
      "Extract of training data : [10] [9562]\n",
      "1429/16406, train loss is 10.546, state is -0.008633296936750412, time/batch=-4.857\n",
      "Extract of training data : [9027] [10]\n",
      "1430/16406, train loss is 10.545, state is -0.001837227726355195, time/batch=-4.898\n",
      "Extract of training data : [5507] [4610]\n",
      "1431/16406, train loss is 10.545, state is 0.019485604017972946, time/batch=-4.996\n",
      "Extract of training data : [105] [1078]\n",
      "1432/16406, train loss is 10.546, state is -0.002664069179445505, time/batch=-4.986\n",
      "Extract of training data : [0] [0]\n",
      "1433/16406, train loss is 10.546, state is -0.00091306131798774, time/batch=-4.854\n",
      "Extract of training data : [1366] [1553]\n",
      "1434/16406, train loss is 10.545, state is -0.016388721764087677, time/batch=-4.870\n",
      "Extract of training data : [8] [277]\n",
      "1435/16406, train loss is 10.545, state is -0.014265654608607292, time/batch=-4.830\n",
      "Extract of training data : [11486] [10]\n",
      "1436/16406, train loss is 10.545, state is -0.014208431355655193, time/batch=-4.957\n",
      "Extract of training data : [3] [20583]\n",
      "1437/16406, train loss is 10.545, state is 0.008895602077245712, time/batch=-4.953\n",
      "Extract of training data : [378] [720]\n",
      "1438/16406, train loss is 10.545, state is -0.01388834323734045, time/batch=-4.901\n",
      "Extract of training data : [46] [22852]\n",
      "1439/16406, train loss is 10.545, state is 0.004868092946708202, time/batch=-4.948\n",
      "Extract of training data : [3493] [35]\n",
      "1440/16406, train loss is 10.545, state is -0.006126058287918568, time/batch=-4.887\n",
      "Extract of training data : [3] [20583]\n",
      "1441/16406, train loss is 10.545, state is 0.01743476465344429, time/batch=-5.020\n",
      "Extract of training data : [10987] [105]\n",
      "1442/16406, train loss is 10.545, state is -0.0202338844537735, time/batch=-4.958\n",
      "Extract of training data : [7001] [29526]\n",
      "1443/16406, train loss is 10.545, state is -0.0003228276618756354, time/batch=-4.948\n",
      "Extract of training data : [7166] [12]\n",
      "1444/16406, train loss is 10.545, state is -0.004601106513291597, time/batch=-4.850\n",
      "Extract of training data : [12524] [174]\n",
      "1445/16406, train loss is 10.546, state is 0.008679439313709736, time/batch=-4.922\n",
      "Extract of training data : [3524] [1256]\n",
      "1446/16406, train loss is 10.546, state is -0.0008091233321465552, time/batch=-5.022\n",
      "Extract of training data : [55] [174]\n",
      "1447/16406, train loss is 10.546, state is -0.0033280756324529648, time/batch=-4.941\n",
      "Extract of training data : [1636] [10]\n",
      "1448/16406, train loss is 10.545, state is -0.0012543214252218604, time/batch=-4.912\n",
      "Extract of training data : [31476] [10]\n",
      "1449/16406, train loss is 10.545, state is -0.012147797271609306, time/batch=-4.968\n",
      "Extract of training data : [3] [3]\n",
      "1450/16406, train loss is 10.545, state is -0.01106482744216919, time/batch=-4.889\n",
      "Extract of training data : [12] [150]\n",
      "1451/16406, train loss is 10.546, state is -0.011083731427788734, time/batch=-4.936\n",
      "Extract of training data : [60] [6578]\n",
      "1452/16406, train loss is 10.546, state is -0.003065172815695405, time/batch=-4.897\n",
      "Extract of training data : [3] [3]\n",
      "1453/16406, train loss is 10.546, state is -0.014126492664217949, time/batch=-4.901\n",
      "Extract of training data : [8837] [10]\n",
      "1454/16406, train loss is 10.546, state is 0.009686185047030449, time/batch=-4.919\n",
      "Extract of training data : [8467] [2704]\n",
      "1455/16406, train loss is 10.546, state is -0.035365693271160126, time/batch=-4.982\n",
      "Extract of training data : [31897] [2159]\n",
      "1456/16406, train loss is 10.546, state is -0.020160213112831116, time/batch=-4.896\n",
      "Extract of training data : [3] [31950]\n",
      "1457/16406, train loss is 10.545, state is -0.00816623866558075, time/batch=-4.975\n",
      "Extract of training data : [1006] [1769]\n",
      "1458/16406, train loss is 10.545, state is 4.985529085388407e-05, time/batch=-4.972\n",
      "Extract of training data : [301] [10]\n",
      "1459/16406, train loss is 10.546, state is -0.007312382105737925, time/batch=-4.891\n",
      "Extract of training data : [50] [71]\n",
      "1460/16406, train loss is 10.546, state is 0.0022983206436038017, time/batch=-5.062\n",
      "Extract of training data : [10] [588]\n",
      "1461/16406, train loss is 10.545, state is 0.02370678074657917, time/batch=-4.893\n",
      "Extract of training data : [0] [0]\n",
      "1462/16406, train loss is 10.546, state is -0.011429151520133018, time/batch=-4.894\n",
      "Extract of training data : [413] [4118]\n",
      "1463/16406, train loss is 10.545, state is -0.011292128823697567, time/batch=-4.852\n",
      "Extract of training data : [1273] [51]\n",
      "1464/16406, train loss is 10.546, state is -0.0006034210091456771, time/batch=-4.928\n",
      "Extract of training data : [8] [277]\n",
      "1465/16406, train loss is 10.546, state is -0.006502967793494463, time/batch=-4.981\n",
      "Extract of training data : [2946] [544]\n",
      "1466/16406, train loss is 10.546, state is -0.009426411241292953, time/batch=-4.969\n",
      "Extract of training data : [10] [1190]\n",
      "1467/16406, train loss is 10.546, state is -0.0047447835095226765, time/batch=-4.869\n",
      "Extract of training data : [24694] [19548]\n",
      "1468/16406, train loss is 10.545, state is -0.004500968847423792, time/batch=-4.919\n",
      "Extract of training data : [8725] [105]\n",
      "1469/16406, train loss is 10.545, state is 0.007668078411370516, time/batch=-4.925\n",
      "Extract of training data : [2075] [105]\n",
      "1470/16406, train loss is 10.545, state is 0.00787117425352335, time/batch=-4.982\n",
      "Extract of training data : [1575] [5137]\n",
      "1471/16406, train loss is 10.545, state is 0.002752172527834773, time/batch=-5.056\n",
      "Extract of training data : [10] [9645]\n",
      "1472/16406, train loss is 10.546, state is -0.006335888989269733, time/batch=-5.008\n",
      "Extract of training data : [6531] [51]\n",
      "1473/16406, train loss is 10.546, state is -0.012910652905702591, time/batch=-4.913\n",
      "Extract of training data : [3] [3]\n",
      "1474/16406, train loss is 10.546, state is 0.01829640194773674, time/batch=-4.835\n",
      "Extract of training data : [5284] [21127]\n",
      "1475/16406, train loss is 10.546, state is 0.005359960719943047, time/batch=-4.924\n",
      "Extract of training data : [873] [2105]\n",
      "1476/16406, train loss is 10.546, state is 0.00538655323907733, time/batch=-4.882\n",
      "Extract of training data : [35] [277]\n",
      "1477/16406, train loss is 10.546, state is -0.0023165990132838488, time/batch=-4.951\n",
      "Extract of training data : [3610] [0]\n",
      "1478/16406, train loss is 10.545, state is 0.010919641703367233, time/batch=-4.891\n",
      "Extract of training data : [1507] [631]\n",
      "1479/16406, train loss is 10.545, state is 0.00011647355131572112, time/batch=-4.966\n",
      "Extract of training data : [1207] [105]\n",
      "1480/16406, train loss is 10.545, state is 0.0038861341308802366, time/batch=-4.997\n",
      "Extract of training data : [280] [0]\n",
      "1481/16406, train loss is 10.545, state is -0.021327301859855652, time/batch=-4.993\n",
      "Extract of training data : [32906] [3758]\n",
      "1482/16406, train loss is 10.545, state is 0.0034648918081074953, time/batch=-4.972\n",
      "Extract of training data : [35] [2633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483/16406, train loss is 10.546, state is 0.003163686254993081, time/batch=-4.917\n",
      "Extract of training data : [3] [8821]\n",
      "1484/16406, train loss is 10.546, state is -0.015421727672219276, time/batch=-4.942\n",
      "Extract of training data : [3] [3]\n",
      "1485/16406, train loss is 10.545, state is -0.00518085528165102, time/batch=-4.928\n",
      "Extract of training data : [0] [3]\n",
      "1486/16406, train loss is 10.546, state is 0.005338555201888084, time/batch=-4.922\n",
      "Extract of training data : [12284] [29]\n",
      "1487/16406, train loss is 10.546, state is -0.0116635262966156, time/batch=-4.914\n",
      "Extract of training data : [13192] [0]\n",
      "1488/16406, train loss is 10.546, state is 0.0011426208075135946, time/batch=-5.003\n",
      "Extract of training data : [1572] [35]\n",
      "1489/16406, train loss is 10.546, state is -0.00038682378362864256, time/batch=-4.897\n",
      "Extract of training data : [9822] [10]\n",
      "1490/16406, train loss is 10.546, state is -0.0015894329408183694, time/batch=-4.958\n",
      "Extract of training data : [0] [0]\n",
      "1491/16406, train loss is 10.546, state is -0.0015260863583534956, time/batch=-5.013\n",
      "Extract of training data : [35] [16632]\n",
      "1492/16406, train loss is 10.546, state is 0.006344159599393606, time/batch=-4.938\n",
      "Extract of training data : [6929] [10]\n",
      "1493/16406, train loss is 10.546, state is -0.0388193354010582, time/batch=-5.063\n",
      "Extract of training data : [2985] [2892]\n",
      "1494/16406, train loss is 10.546, state is -0.00983317568898201, time/batch=-4.930\n",
      "Extract of training data : [561] [882]\n",
      "1495/16406, train loss is 10.545, state is -0.0163645651191473, time/batch=-4.993\n",
      "Extract of training data : [5654] [35]\n",
      "1496/16406, train loss is 10.545, state is -0.01861458644270897, time/batch=-4.988\n",
      "Extract of training data : [10] [783]\n",
      "1497/16406, train loss is 10.545, state is 0.006463649217039347, time/batch=-4.953\n",
      "Extract of training data : [1017] [1988]\n",
      "1498/16406, train loss is 10.545, state is 0.0001381499314447865, time/batch=-5.049\n",
      "Extract of training data : [3367] [1079]\n",
      "1499/16406, train loss is 10.545, state is 0.016570990905165672, time/batch=-5.021\n",
      "Extract of training data : [18518] [378]\n",
      "1500/16406, train loss is 10.545, state is -0.00593913160264492, time/batch=-5.080\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [35] [3127]\n",
      "1501/16406, train loss is 10.545, state is 0.008222317323088646, time/batch=-5.134\n",
      "Extract of training data : [10] [1477]\n",
      "1502/16406, train loss is 10.545, state is -0.017539221793413162, time/batch=-5.108\n",
      "Extract of training data : [5067] [35]\n",
      "1503/16406, train loss is 10.546, state is 0.008045691065490246, time/batch=-4.989\n",
      "Extract of training data : [3] [3]\n",
      "1504/16406, train loss is 10.546, state is -0.011134590022265911, time/batch=-4.959\n",
      "Extract of training data : [3] [3]\n",
      "1505/16406, train loss is 10.545, state is -0.0013261535204946995, time/batch=-4.943\n",
      "Extract of training data : [105] [10]\n",
      "1506/16406, train loss is 10.545, state is 0.005717557854950428, time/batch=-4.990\n",
      "Extract of training data : [12504] [29]\n",
      "1507/16406, train loss is 10.545, state is -0.024307511746883392, time/batch=-4.954\n",
      "Extract of training data : [20583] [2791]\n",
      "1508/16406, train loss is 10.545, state is -0.0010319435968995094, time/batch=-4.995\n",
      "Extract of training data : [13349] [413]\n",
      "1509/16406, train loss is 10.546, state is 0.007977865636348724, time/batch=-4.996\n",
      "Extract of training data : [29] [6899]\n",
      "1510/16406, train loss is 10.545, state is 0.012062881141901016, time/batch=-4.932\n",
      "Extract of training data : [1180] [10]\n",
      "1511/16406, train loss is 10.545, state is -0.0062864082865417, time/batch=-4.954\n",
      "Extract of training data : [11] [2923]\n",
      "1512/16406, train loss is 10.545, state is -0.0002488106256350875, time/batch=-5.126\n",
      "Extract of training data : [675] [3904]\n",
      "1513/16406, train loss is 10.545, state is -0.009431895799934864, time/batch=-4.937\n",
      "Extract of training data : [10] [2050]\n",
      "1514/16406, train loss is 10.546, state is -0.010508817620575428, time/batch=-4.940\n",
      "Extract of training data : [2063] [2311]\n",
      "1515/16406, train loss is 10.546, state is 0.011697519570589066, time/batch=-5.015\n",
      "Extract of training data : [3] [7243]\n",
      "1516/16406, train loss is 10.545, state is 0.002295283367857337, time/batch=-5.040\n",
      "Extract of training data : [16717] [327]\n",
      "1517/16406, train loss is 10.546, state is -0.009998932480812073, time/batch=-5.163\n",
      "Extract of training data : [34576] [1182]\n",
      "1518/16406, train loss is 10.546, state is -0.00867338664829731, time/batch=-4.995\n",
      "Extract of training data : [6286] [2398]\n",
      "1519/16406, train loss is 10.545, state is 0.01203810703009367, time/batch=-5.015\n",
      "Extract of training data : [10] [439]\n",
      "1520/16406, train loss is 10.545, state is -0.0009164625080302358, time/batch=-4.946\n",
      "Extract of training data : [1529] [10]\n",
      "1521/16406, train loss is 10.546, state is 0.009730976074934006, time/batch=-5.144\n",
      "Extract of training data : [916] [920]\n",
      "1522/16406, train loss is 10.545, state is -0.012612531892955303, time/batch=-5.048\n",
      "Extract of training data : [15508] [3104]\n",
      "1523/16406, train loss is 10.546, state is -0.02032272145152092, time/batch=-5.047\n",
      "Extract of training data : [0] [0]\n",
      "1524/16406, train loss is 10.546, state is 0.0020999773405492306, time/batch=-4.979\n",
      "Extract of training data : [592] [1134]\n",
      "1525/16406, train loss is 10.545, state is 0.02046218514442444, time/batch=-5.072\n",
      "Extract of training data : [10] [4266]\n",
      "1526/16406, train loss is 10.545, state is -0.0041428618133068085, time/batch=-5.004\n",
      "Extract of training data : [4990] [46]\n",
      "1527/16406, train loss is 10.546, state is -0.014444615691900253, time/batch=-5.099\n",
      "Extract of training data : [23] [3758]\n",
      "1528/16406, train loss is 10.545, state is 0.007996040396392345, time/batch=-5.002\n",
      "Extract of training data : [105] [1661]\n",
      "1529/16406, train loss is 10.546, state is 0.014692520722746849, time/batch=-4.967\n",
      "Extract of training data : [12] [1273]\n",
      "1530/16406, train loss is 10.546, state is 0.006051812320947647, time/batch=-5.079\n",
      "Extract of training data : [2925] [13914]\n",
      "1531/16406, train loss is 10.546, state is -0.003256151918321848, time/batch=-4.941\n",
      "Extract of training data : [413] [71]\n",
      "1532/16406, train loss is 10.546, state is -0.007867022417485714, time/batch=-5.136\n",
      "Extract of training data : [877] [280]\n",
      "1533/16406, train loss is 10.545, state is 0.011587855406105518, time/batch=-5.074\n",
      "Extract of training data : [8539] [35]\n",
      "1534/16406, train loss is 10.546, state is -0.00046485502389259636, time/batch=-5.143\n",
      "Extract of training data : [35565] [35566]\n",
      "1535/16406, train loss is 10.545, state is 0.00623356644064188, time/batch=-4.914\n",
      "Extract of training data : [1515] [10]\n",
      "1536/16406, train loss is 10.545, state is -0.012439814396202564, time/batch=-5.020\n",
      "Extract of training data : [20818] [127]\n",
      "1537/16406, train loss is 10.545, state is 0.002185635268688202, time/batch=-4.939\n",
      "Extract of training data : [1636] [10]\n",
      "1538/16406, train loss is 10.545, state is -0.004553989972919226, time/batch=-4.912\n",
      "Extract of training data : [4143] [34218]\n",
      "1539/16406, train loss is 10.546, state is -0.013060009106993675, time/batch=-4.943\n",
      "Extract of training data : [190] [555]\n",
      "1540/16406, train loss is 10.545, state is 0.005026515107601881, time/batch=-5.118\n",
      "Extract of training data : [4765] [10]\n",
      "1541/16406, train loss is 10.546, state is 0.0022110973950475454, time/batch=-4.936\n",
      "Extract of training data : [0] [0]\n",
      "1542/16406, train loss is 10.545, state is -0.0024830454494804144, time/batch=-4.960\n",
      "Extract of training data : [1014] [17764]\n",
      "1543/16406, train loss is 10.546, state is 0.00021651192218996584, time/batch=-4.983\n",
      "Extract of training data : [6873] [2813]\n",
      "1544/16406, train loss is 10.545, state is 0.004628794267773628, time/batch=-4.942\n",
      "Extract of training data : [2076] [633]\n",
      "1545/16406, train loss is 10.545, state is -0.0019414351554587483, time/batch=-4.907\n",
      "Extract of training data : [1507] [10]\n",
      "1546/16406, train loss is 10.546, state is -0.010455025359988213, time/batch=-4.905\n",
      "Extract of training data : [3] [3]\n",
      "1547/16406, train loss is 10.545, state is -0.003397571388632059, time/batch=-5.001\n",
      "Extract of training data : [4945] [499]\n",
      "1548/16406, train loss is 10.545, state is 0.008712349459528923, time/batch=-4.989\n",
      "Extract of training data : [1675] [4162]\n",
      "1549/16406, train loss is 10.546, state is -0.024707717821002007, time/batch=-4.965\n",
      "Extract of training data : [1386] [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550/16406, train loss is 10.545, state is -0.007512431591749191, time/batch=-4.895\n",
      "Extract of training data : [2633] [906]\n",
      "1551/16406, train loss is 10.546, state is -0.016179794445633888, time/batch=-4.952\n",
      "Extract of training data : [422] [35]\n",
      "1552/16406, train loss is 10.546, state is -0.019355246797204018, time/batch=-4.926\n",
      "Extract of training data : [176] [7949]\n",
      "1553/16406, train loss is 10.545, state is 0.008895439095795155, time/batch=-5.145\n",
      "Extract of training data : [51] [106]\n",
      "1554/16406, train loss is 10.546, state is -0.009298210963606834, time/batch=-4.880\n",
      "Extract of training data : [3] [277]\n",
      "1555/16406, train loss is 10.545, state is 0.0036600674502551556, time/batch=-4.940\n",
      "Extract of training data : [10] [3485]\n",
      "1556/16406, train loss is 10.545, state is 0.005481223110109568, time/batch=-4.846\n",
      "Extract of training data : [105] [910]\n",
      "1557/16406, train loss is 10.545, state is -0.0073976884596049786, time/batch=-4.943\n",
      "Extract of training data : [2119] [10]\n",
      "1558/16406, train loss is 10.546, state is 0.0050607468001544476, time/batch=-4.926\n",
      "Extract of training data : [28829] [2007]\n",
      "1559/16406, train loss is 10.546, state is 0.0009735851781442761, time/batch=-4.988\n",
      "Extract of training data : [0] [3]\n",
      "1560/16406, train loss is 10.545, state is 0.009570901282131672, time/batch=-4.917\n",
      "Extract of training data : [0] [3]\n",
      "1561/16406, train loss is 10.545, state is 0.002897409023717046, time/batch=-4.880\n",
      "Extract of training data : [3] [3]\n",
      "1562/16406, train loss is 10.546, state is -0.006604486145079136, time/batch=-4.858\n",
      "Extract of training data : [3] [3]\n",
      "1563/16406, train loss is 10.546, state is -0.015059249475598335, time/batch=-4.878\n",
      "Extract of training data : [9167] [12915]\n",
      "1564/16406, train loss is 10.545, state is -0.005648376885801554, time/batch=-4.898\n",
      "Extract of training data : [0] [1]\n",
      "1565/16406, train loss is 10.545, state is -0.0044733574613928795, time/batch=-4.929\n",
      "Extract of training data : [883] [10]\n",
      "1566/16406, train loss is 10.545, state is -0.021404201164841652, time/batch=-4.934\n",
      "Extract of training data : [277] [1137]\n",
      "1567/16406, train loss is 10.545, state is -0.004695568699389696, time/batch=-4.919\n",
      "Extract of training data : [3] [3]\n",
      "1568/16406, train loss is 10.545, state is -0.0010061119683086872, time/batch=-4.947\n",
      "Extract of training data : [1935] [422]\n",
      "1569/16406, train loss is 10.546, state is -0.023029591888189316, time/batch=-5.011\n",
      "Extract of training data : [2605] [359]\n",
      "1570/16406, train loss is 10.545, state is -0.00988466665148735, time/batch=-4.824\n",
      "Extract of training data : [3516] [14]\n",
      "1571/16406, train loss is 10.545, state is -0.022142594680190086, time/batch=-4.872\n",
      "Extract of training data : [3516] [3701]\n",
      "1572/16406, train loss is 10.546, state is 0.016209742054343224, time/batch=-4.835\n",
      "Extract of training data : [359] [804]\n",
      "1573/16406, train loss is 10.545, state is 0.009600860066711903, time/batch=-4.808\n",
      "Extract of training data : [806] [105]\n",
      "1574/16406, train loss is 10.545, state is -0.006050491705536842, time/batch=-4.823\n",
      "Extract of training data : [4868] [105]\n",
      "1575/16406, train loss is 10.545, state is 0.009009649977087975, time/batch=-4.800\n",
      "Extract of training data : [10] [2854]\n",
      "1576/16406, train loss is 10.545, state is -0.018926337361335754, time/batch=-4.806\n",
      "Extract of training data : [3] [1021]\n",
      "1577/16406, train loss is 10.545, state is -0.019610639661550522, time/batch=-4.853\n",
      "Extract of training data : [10] [5860]\n",
      "1578/16406, train loss is 10.545, state is 0.016460902988910675, time/batch=-4.797\n",
      "Extract of training data : [3] [292]\n",
      "1579/16406, train loss is 10.545, state is 0.0010569465812295675, time/batch=-4.876\n",
      "Extract of training data : [6327] [811]\n",
      "1580/16406, train loss is 10.545, state is 0.0064763836562633514, time/batch=-4.813\n",
      "Extract of training data : [291] [643]\n",
      "1581/16406, train loss is 10.545, state is 0.0017881820676848292, time/batch=-4.769\n",
      "Extract of training data : [413] [876]\n",
      "1582/16406, train loss is 10.545, state is 0.011829150840640068, time/batch=-4.783\n",
      "Extract of training data : [1056] [7122]\n",
      "1583/16406, train loss is 10.545, state is -0.008585824631154537, time/batch=-4.750\n",
      "Extract of training data : [25] [1437]\n",
      "1584/16406, train loss is 10.546, state is -0.021565953269600868, time/batch=-4.840\n",
      "Extract of training data : [2141] [28]\n",
      "1585/16406, train loss is 10.545, state is -0.011277369223535061, time/batch=-4.817\n",
      "Extract of training data : [559] [71]\n",
      "1586/16406, train loss is 10.545, state is -0.011220208369195461, time/batch=-4.801\n",
      "Extract of training data : [3] [3]\n",
      "1587/16406, train loss is 10.545, state is -0.00892542488873005, time/batch=-4.797\n",
      "Extract of training data : [110] [10]\n",
      "1588/16406, train loss is 10.545, state is -0.002315860241651535, time/batch=-4.842\n",
      "Extract of training data : [8197] [16]\n",
      "1589/16406, train loss is 10.545, state is 0.0010711046634241939, time/batch=-4.892\n",
      "Extract of training data : [6749] [8411]\n",
      "1590/16406, train loss is 10.545, state is -0.017882555723190308, time/batch=-4.817\n",
      "Extract of training data : [8606] [1220]\n",
      "1591/16406, train loss is 10.545, state is 0.00994658563286066, time/batch=-4.801\n",
      "Extract of training data : [3] [699]\n",
      "1592/16406, train loss is 10.546, state is -0.005166932474821806, time/batch=-4.868\n",
      "Extract of training data : [277] [4505]\n",
      "1593/16406, train loss is 10.545, state is -0.0030309646390378475, time/batch=-4.830\n",
      "Extract of training data : [3] [422]\n",
      "1594/16406, train loss is 10.545, state is -0.012387212365865707, time/batch=-4.784\n",
      "Extract of training data : [3552] [3553]\n",
      "1595/16406, train loss is 10.546, state is -0.0010731220245361328, time/batch=-4.815\n",
      "Extract of training data : [9380] [51]\n",
      "1596/16406, train loss is 10.545, state is 0.0007960355142131448, time/batch=-4.844\n",
      "Extract of training data : [35] [2404]\n",
      "1597/16406, train loss is 10.546, state is -0.004014960490167141, time/batch=-4.828\n",
      "Extract of training data : [3327] [2586]\n",
      "1598/16406, train loss is 10.545, state is 0.008858218789100647, time/batch=-4.821\n",
      "Extract of training data : [10] [3366]\n",
      "1599/16406, train loss is 10.546, state is -0.021549105644226074, time/batch=-4.786\n",
      "Extract of training data : [3] [3]\n",
      "1600/16406, train loss is 10.545, state is 0.01567547582089901, time/batch=-4.811\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [0] [0]\n",
      "1601/16406, train loss is 10.546, state is -0.0009766921866685152, time/batch=-5.059\n",
      "Extract of training data : [3] [3]\n",
      "1602/16406, train loss is 10.546, state is -0.006733647082000971, time/batch=-4.861\n",
      "Extract of training data : [10] [3155]\n",
      "1603/16406, train loss is 10.546, state is 0.0016098353080451488, time/batch=-4.827\n",
      "Extract of training data : [530] [10]\n",
      "1604/16406, train loss is 10.546, state is 0.005309689790010452, time/batch=-4.829\n",
      "Extract of training data : [801] [10142]\n",
      "1605/16406, train loss is 10.546, state is -0.006901395041495562, time/batch=-4.782\n",
      "Extract of training data : [277] [6179]\n",
      "1606/16406, train loss is 10.546, state is -0.004915905185043812, time/batch=-4.788\n",
      "Extract of training data : [6077] [10]\n",
      "1607/16406, train loss is 10.546, state is -0.008956336416304111, time/batch=-4.797\n",
      "Extract of training data : [10924] [10230]\n",
      "1608/16406, train loss is 10.546, state is -0.021467523649334908, time/batch=-4.799\n",
      "Extract of training data : [0] [0]\n",
      "1609/16406, train loss is 10.546, state is -0.006804526783525944, time/batch=-4.851\n",
      "Extract of training data : [3566] [413]\n",
      "1610/16406, train loss is 10.546, state is -0.014451684430241585, time/batch=-4.826\n",
      "Extract of training data : [3] [1707]\n",
      "1611/16406, train loss is 10.546, state is 0.005691901780664921, time/batch=-4.828\n",
      "Extract of training data : [1997] [16]\n",
      "1612/16406, train loss is 10.546, state is -0.004097484517842531, time/batch=-4.815\n",
      "Extract of training data : [3516] [2941]\n",
      "1613/16406, train loss is 10.546, state is -0.011678616516292095, time/batch=-4.907\n",
      "Extract of training data : [105] [1594]\n",
      "1614/16406, train loss is 10.546, state is 0.005605699028819799, time/batch=-4.904\n",
      "Extract of training data : [11697] [263]\n",
      "1615/16406, train loss is 10.546, state is -0.0016843852354213595, time/batch=-4.844\n",
      "Extract of training data : [548] [105]\n",
      "1616/16406, train loss is 10.545, state is 0.008693695068359375, time/batch=-4.760\n",
      "Extract of training data : [32] [3613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/16406, train loss is 10.546, state is 0.0037178564816713333, time/batch=-4.801\n",
      "Extract of training data : [3] [3]\n",
      "1618/16406, train loss is 10.546, state is 0.010968766175210476, time/batch=-4.822\n",
      "Extract of training data : [277] [12281]\n",
      "1619/16406, train loss is 10.545, state is 0.006129364017397165, time/batch=-4.809\n",
      "Extract of training data : [1220] [10]\n",
      "1620/16406, train loss is 10.546, state is -0.003972585778683424, time/batch=-4.898\n",
      "Extract of training data : [1480] [10]\n",
      "1621/16406, train loss is 10.546, state is -0.0007992672617547214, time/batch=-4.840\n",
      "Extract of training data : [6025] [10]\n",
      "1622/16406, train loss is 10.545, state is 0.009321247227489948, time/batch=-4.794\n",
      "Extract of training data : [10] [1971]\n",
      "1623/16406, train loss is 10.545, state is 0.0013809326337650418, time/batch=-4.781\n",
      "Extract of training data : [1021] [1161]\n",
      "1624/16406, train loss is 10.545, state is 0.003861738834530115, time/batch=-4.835\n",
      "Extract of training data : [13194] [1007]\n",
      "1625/16406, train loss is 10.546, state is 0.002408076310530305, time/batch=-4.757\n",
      "Extract of training data : [528] [877]\n",
      "1626/16406, train loss is 10.546, state is 0.006806390359997749, time/batch=-4.879\n",
      "Extract of training data : [3] [912]\n",
      "1627/16406, train loss is 10.546, state is 0.005389506462961435, time/batch=-5.221\n",
      "Extract of training data : [13562] [13563]\n",
      "1628/16406, train loss is 10.546, state is -0.006459418218582869, time/batch=-4.244\n",
      "Extract of training data : [1079] [105]\n",
      "1629/16406, train loss is 10.545, state is -0.006472736597061157, time/batch=-4.280\n",
      "Extract of training data : [3] [846]\n",
      "1630/16406, train loss is 10.545, state is -0.0024338122457265854, time/batch=-4.332\n",
      "Extract of training data : [5740] [9010]\n",
      "1631/16406, train loss is 10.545, state is -0.0029125679284334183, time/batch=-4.233\n",
      "Extract of training data : [4681] [10]\n",
      "1632/16406, train loss is 10.545, state is -0.0038489094004034996, time/batch=-4.259\n",
      "Extract of training data : [8] [277]\n",
      "1633/16406, train loss is 10.546, state is -0.0017000646330416203, time/batch=-4.248\n",
      "Extract of training data : [277] [2442]\n",
      "1634/16406, train loss is 10.545, state is -0.01845293864607811, time/batch=-4.257\n",
      "Extract of training data : [280] [0]\n",
      "1635/16406, train loss is 10.545, state is 0.010571868158876896, time/batch=-4.251\n",
      "Extract of training data : [11460] [10]\n",
      "1636/16406, train loss is 10.545, state is -0.01991966739296913, time/batch=-4.204\n",
      "Extract of training data : [924] [3938]\n",
      "1637/16406, train loss is 10.545, state is -0.018929634243249893, time/batch=-4.252\n",
      "Extract of training data : [3758] [688]\n",
      "1638/16406, train loss is 10.545, state is -0.007398972753435373, time/batch=-4.240\n",
      "Extract of training data : [14893] [1185]\n",
      "1639/16406, train loss is 10.545, state is 0.0023498644586652517, time/batch=-4.252\n",
      "Extract of training data : [492] [12]\n",
      "1640/16406, train loss is 10.545, state is -0.0037854614201933146, time/batch=-4.258\n",
      "Extract of training data : [505] [1177]\n",
      "1641/16406, train loss is 10.545, state is -0.007012973073869944, time/batch=-4.255\n",
      "Extract of training data : [4853] [16]\n",
      "1642/16406, train loss is 10.545, state is -0.009391740895807743, time/batch=-4.232\n",
      "Extract of training data : [46] [6974]\n",
      "1643/16406, train loss is 10.545, state is -0.004563589580357075, time/batch=-4.213\n",
      "Extract of training data : [3328] [6399]\n",
      "1644/16406, train loss is 10.545, state is 0.0022490646224468946, time/batch=-4.332\n",
      "Extract of training data : [3] [910]\n",
      "1645/16406, train loss is 10.546, state is 0.012748200446367264, time/batch=-4.500\n",
      "Extract of training data : [699] [16]\n",
      "1646/16406, train loss is 10.546, state is 0.00026419467758387327, time/batch=-4.937\n",
      "Extract of training data : [3758] [832]\n",
      "1647/16406, train loss is 10.546, state is -0.013547354377806187, time/batch=-4.838\n",
      "Extract of training data : [10] [1489]\n",
      "1648/16406, train loss is 10.545, state is -0.015497450716793537, time/batch=-4.829\n",
      "Extract of training data : [105] [371]\n",
      "1649/16406, train loss is 10.545, state is -0.004773005843162537, time/batch=-4.821\n",
      "Extract of training data : [1167] [873]\n",
      "1650/16406, train loss is 10.546, state is 0.004716816358268261, time/batch=-4.825\n",
      "Extract of training data : [910] [1803]\n",
      "1651/16406, train loss is 10.545, state is -0.005001395475119352, time/batch=-4.856\n",
      "Extract of training data : [1021] [811]\n",
      "1652/16406, train loss is 10.546, state is -0.003044955665245652, time/batch=-4.818\n",
      "Extract of training data : [0] [0]\n",
      "1653/16406, train loss is 10.546, state is -0.01023157499730587, time/batch=-4.798\n",
      "Extract of training data : [280] [0]\n",
      "1654/16406, train loss is 10.546, state is 0.010974030941724777, time/batch=-4.829\n",
      "Extract of training data : [16725] [14224]\n",
      "1655/16406, train loss is 10.546, state is -0.010874971747398376, time/batch=-4.827\n",
      "Extract of training data : [284] [285]\n",
      "1656/16406, train loss is 10.546, state is 0.008965777233242989, time/batch=-4.877\n",
      "Extract of training data : [0] [0]\n",
      "1657/16406, train loss is 10.546, state is 2.3469094230677e-05, time/batch=-4.819\n",
      "Extract of training data : [11071] [35]\n",
      "1658/16406, train loss is 10.546, state is -0.010406835936009884, time/batch=-4.830\n",
      "Extract of training data : [10] [17100]\n",
      "1659/16406, train loss is 10.545, state is 0.016072988510131836, time/batch=-4.805\n",
      "Extract of training data : [10] [6402]\n",
      "1660/16406, train loss is 10.545, state is -0.00045990737271495163, time/batch=-4.803\n",
      "Extract of training data : [14342] [17345]\n",
      "1661/16406, train loss is 10.546, state is -0.006543128751218319, time/batch=-4.843\n",
      "Extract of training data : [17464] [559]\n",
      "1662/16406, train loss is 10.545, state is -0.001895334804430604, time/batch=-4.902\n",
      "Extract of training data : [3516] [35]\n",
      "1663/16406, train loss is 10.545, state is -0.023857660591602325, time/batch=-4.838\n",
      "Extract of training data : [910] [378]\n",
      "1664/16406, train loss is 10.545, state is -0.008300624787807465, time/batch=-4.824\n",
      "Extract of training data : [3285] [1077]\n",
      "1665/16406, train loss is 10.546, state is -0.016262182965874672, time/batch=-4.881\n",
      "Extract of training data : [559] [3105]\n",
      "1666/16406, train loss is 10.546, state is -0.0033406305592507124, time/batch=-4.929\n",
      "Extract of training data : [10] [143]\n",
      "1667/16406, train loss is 10.545, state is 0.004835234489291906, time/batch=-4.808\n",
      "Extract of training data : [3] [3]\n",
      "1668/16406, train loss is 10.546, state is 0.006190972402691841, time/batch=-4.817\n",
      "Extract of training data : [1188] [12110]\n",
      "1669/16406, train loss is 10.546, state is 0.005486587528139353, time/batch=-4.842\n",
      "Extract of training data : [16451] [164]\n",
      "1670/16406, train loss is 10.545, state is -0.0035417473409324884, time/batch=-4.797\n",
      "Extract of training data : [3] [3]\n",
      "1671/16406, train loss is 10.545, state is -0.003438139334321022, time/batch=-4.804\n",
      "Extract of training data : [0] [3]\n",
      "1672/16406, train loss is 10.546, state is 0.004719607997685671, time/batch=-4.830\n",
      "Extract of training data : [3055] [10]\n",
      "1673/16406, train loss is 10.546, state is -0.004902885761111975, time/batch=-4.858\n",
      "Extract of training data : [3] [3]\n",
      "1674/16406, train loss is 10.546, state is -0.02049667201936245, time/batch=-4.802\n",
      "Extract of training data : [13381] [10]\n",
      "1675/16406, train loss is 10.546, state is -0.002196365501731634, time/batch=-4.808\n",
      "Extract of training data : [3] [3]\n",
      "1676/16406, train loss is 10.546, state is 0.0001981871173484251, time/batch=-4.830\n",
      "Extract of training data : [436] [283]\n",
      "1677/16406, train loss is 10.546, state is -0.0030327634885907173, time/batch=-4.808\n",
      "Extract of training data : [1137] [28]\n",
      "1678/16406, train loss is 10.546, state is 0.0032442857045680285, time/batch=-4.831\n",
      "Extract of training data : [413] [2442]\n",
      "1679/16406, train loss is 10.546, state is -0.008947995491325855, time/batch=-4.845\n",
      "Extract of training data : [11953] [17849]\n",
      "1680/16406, train loss is 10.545, state is 0.0006916298298165202, time/batch=-6.193\n",
      "Extract of training data : [3] [3]\n",
      "1681/16406, train loss is 10.546, state is -0.014774939976632595, time/batch=-4.951\n",
      "Extract of training data : [3] [3]\n",
      "1682/16406, train loss is 10.546, state is -0.004779044538736343, time/batch=-4.797\n",
      "Extract of training data : [10] [3860]\n",
      "1683/16406, train loss is 10.545, state is 0.006809432525187731, time/batch=-4.808\n",
      "Extract of training data : [146] [8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684/16406, train loss is 10.546, state is -0.01302236970514059, time/batch=-4.791\n",
      "Extract of training data : [4873] [2924]\n",
      "1685/16406, train loss is 10.546, state is -0.0020442320965230465, time/batch=-4.832\n",
      "Extract of training data : [10] [2398]\n",
      "1686/16406, train loss is 10.545, state is 0.00034398259595036507, time/batch=-4.778\n",
      "Extract of training data : [245] [10]\n",
      "1687/16406, train loss is 10.545, state is 0.009527900256216526, time/batch=-4.800\n",
      "Extract of training data : [561] [4309]\n",
      "1688/16406, train loss is 10.546, state is -0.00350311491638422, time/batch=-4.806\n",
      "Extract of training data : [14] [17716]\n",
      "1689/16406, train loss is 10.545, state is 0.00011707328667398542, time/batch=-4.830\n",
      "Extract of training data : [413] [17114]\n",
      "1690/16406, train loss is 10.545, state is 0.011752516962587833, time/batch=-4.794\n",
      "Extract of training data : [972] [883]\n",
      "1691/16406, train loss is 10.546, state is -0.005672984290868044, time/batch=-4.869\n",
      "Extract of training data : [1180] [35]\n",
      "1692/16406, train loss is 10.545, state is 0.006937530357390642, time/batch=-4.809\n",
      "Extract of training data : [0] [0]\n",
      "1693/16406, train loss is 10.545, state is 0.0059567950665950775, time/batch=-4.858\n",
      "Extract of training data : [3] [3]\n",
      "1694/16406, train loss is 10.546, state is -0.008096210658550262, time/batch=-4.773\n",
      "Extract of training data : [6982] [688]\n",
      "1695/16406, train loss is 10.546, state is -0.003960460424423218, time/batch=-4.800\n",
      "Extract of training data : [1185] [13445]\n",
      "1696/16406, train loss is 10.546, state is 0.003403632901608944, time/batch=-4.810\n",
      "Extract of training data : [10] [753]\n",
      "1697/16406, train loss is 10.545, state is 0.0013019901234656572, time/batch=-4.829\n",
      "Extract of training data : [533] [2221]\n",
      "1698/16406, train loss is 10.546, state is 0.017430976033210754, time/batch=-4.839\n",
      "Extract of training data : [3] [3]\n",
      "1699/16406, train loss is 10.546, state is 0.0054548573680222034, time/batch=-4.764\n",
      "Extract of training data : [1139] [10]\n",
      "1700/16406, train loss is 10.546, state is -0.023102344945073128, time/batch=-4.845\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [2611] [801]\n",
      "1701/16406, train loss is 10.546, state is -0.013295862823724747, time/batch=-5.055\n",
      "Extract of training data : [0] [3]\n",
      "1702/16406, train loss is 10.546, state is 0.006449043285101652, time/batch=-4.878\n",
      "Extract of training data : [3830] [478]\n",
      "1703/16406, train loss is 10.546, state is 0.007272956892848015, time/batch=-4.885\n",
      "Extract of training data : [1426] [16]\n",
      "1704/16406, train loss is 10.546, state is -0.005464424379169941, time/batch=-4.821\n",
      "Extract of training data : [422] [35]\n",
      "1705/16406, train loss is 10.546, state is 0.009521003812551498, time/batch=-4.825\n",
      "Extract of training data : [873] [29]\n",
      "1706/16406, train loss is 10.546, state is -0.003855601418763399, time/batch=-4.798\n",
      "Extract of training data : [19037] [21284]\n",
      "1707/16406, train loss is 10.545, state is 0.006762735079973936, time/batch=-4.795\n",
      "Extract of training data : [5214] [5809]\n",
      "1708/16406, train loss is 10.546, state is -0.00023811226128600538, time/batch=-4.772\n",
      "Extract of training data : [11789] [2007]\n",
      "1709/16406, train loss is 10.546, state is -0.02209370955824852, time/batch=-4.813\n",
      "Extract of training data : [1445] [9663]\n",
      "1710/16406, train loss is 10.546, state is -0.001777855446562171, time/batch=-4.831\n",
      "Extract of training data : [35] [826]\n",
      "1711/16406, train loss is 10.545, state is -0.00289031770080328, time/batch=-4.826\n",
      "Extract of training data : [10] [176]\n",
      "1712/16406, train loss is 10.545, state is -0.0048805284313857555, time/batch=-4.802\n",
      "Extract of training data : [422] [1289]\n",
      "1713/16406, train loss is 10.546, state is -0.004901772830635309, time/batch=-4.794\n",
      "Extract of training data : [0] [0]\n",
      "1714/16406, train loss is 10.546, state is -0.010913760401308537, time/batch=-4.786\n",
      "Extract of training data : [413] [4311]\n",
      "1715/16406, train loss is 10.545, state is 0.004289870150387287, time/batch=-4.794\n",
      "Extract of training data : [3] [3]\n",
      "1716/16406, train loss is 10.546, state is -0.005277599208056927, time/batch=-4.784\n",
      "Extract of training data : [11483] [2508]\n",
      "1717/16406, train loss is 10.546, state is 0.003697215346619487, time/batch=-4.806\n",
      "Extract of training data : [12] [972]\n",
      "1718/16406, train loss is 10.546, state is 0.001725316746160388, time/batch=-4.779\n",
      "Extract of training data : [4378] [16249]\n",
      "1719/16406, train loss is 10.546, state is -0.002846398623660207, time/batch=-4.782\n",
      "Extract of training data : [3] [3]\n",
      "1720/16406, train loss is 10.546, state is 0.0020110481418669224, time/batch=-4.845\n",
      "Extract of training data : [12] [22382]\n",
      "1721/16406, train loss is 10.546, state is -0.003492310643196106, time/batch=-4.797\n",
      "Extract of training data : [291] [495]\n",
      "1722/16406, train loss is 10.546, state is 0.006883881986141205, time/batch=-4.802\n",
      "Extract of training data : [16] [0]\n",
      "1723/16406, train loss is 10.546, state is 0.0070565687492489815, time/batch=-4.862\n",
      "Extract of training data : [22596] [12843]\n",
      "1724/16406, train loss is 10.545, state is -0.0016319812275469303, time/batch=-4.800\n",
      "Extract of training data : [3] [3]\n",
      "1725/16406, train loss is 10.545, state is -0.0062211682088673115, time/batch=-4.842\n",
      "Extract of training data : [3] [3]\n",
      "1726/16406, train loss is 10.546, state is 0.01161174662411213, time/batch=-4.804\n",
      "Extract of training data : [20707] [720]\n",
      "1727/16406, train loss is 10.546, state is 0.004867789801210165, time/batch=-4.834\n",
      "Extract of training data : [20510] [16]\n",
      "1728/16406, train loss is 10.546, state is 0.02103324607014656, time/batch=-4.829\n",
      "Extract of training data : [559] [464]\n",
      "1729/16406, train loss is 10.546, state is 0.000741019903216511, time/batch=-4.831\n",
      "Extract of training data : [5214] [1078]\n",
      "1730/16406, train loss is 10.546, state is 0.0006514526903629303, time/batch=-4.771\n",
      "Extract of training data : [1458] [9701]\n",
      "1731/16406, train loss is 10.546, state is -0.01851423643529415, time/batch=-4.808\n",
      "Extract of training data : [1234] [1842]\n",
      "1732/16406, train loss is 10.546, state is 0.004851995036005974, time/batch=-4.833\n",
      "Extract of training data : [10] [4307]\n",
      "1733/16406, train loss is 10.546, state is -0.018318599089980125, time/batch=-4.810\n",
      "Extract of training data : [105] [2045]\n",
      "1734/16406, train loss is 10.546, state is -0.015225324779748917, time/batch=-4.824\n",
      "Extract of training data : [3202] [10]\n",
      "1735/16406, train loss is 10.546, state is -0.015313719399273396, time/batch=-4.805\n",
      "Extract of training data : [23373] [16]\n",
      "1736/16406, train loss is 10.546, state is -0.01783085986971855, time/batch=-4.817\n",
      "Extract of training data : [3] [3]\n",
      "1737/16406, train loss is 10.546, state is -0.0004040659696329385, time/batch=-4.802\n",
      "Extract of training data : [2557] [3]\n",
      "1738/16406, train loss is 10.545, state is 0.0020310983527451754, time/batch=-4.821\n",
      "Extract of training data : [5593] [2392]\n",
      "1739/16406, train loss is 10.546, state is 0.005490757059305906, time/batch=-4.773\n",
      "Extract of training data : [1437] [16726]\n",
      "1740/16406, train loss is 10.546, state is -0.017529066652059555, time/batch=-4.856\n",
      "Extract of training data : [1308] [5313]\n",
      "1741/16406, train loss is 10.546, state is 0.011567101813852787, time/batch=-4.778\n",
      "Extract of training data : [280] [1228]\n",
      "1742/16406, train loss is 10.546, state is -0.029143568128347397, time/batch=-4.794\n",
      "Extract of training data : [3] [277]\n",
      "1743/16406, train loss is 10.546, state is -0.0033706538379192352, time/batch=-4.796\n",
      "Extract of training data : [13852] [2841]\n",
      "1744/16406, train loss is 10.546, state is 0.0005928957252763212, time/batch=-4.796\n",
      "Extract of training data : [378] [327]\n",
      "1745/16406, train loss is 10.546, state is 0.011276989243924618, time/batch=-4.788\n",
      "Extract of training data : [23552] [146]\n",
      "1746/16406, train loss is 10.546, state is -0.006294067949056625, time/batch=-4.879\n",
      "Extract of training data : [10] [14699]\n",
      "1747/16406, train loss is 10.546, state is -0.019905462861061096, time/batch=-4.812\n",
      "Extract of training data : [7937] [2082]\n",
      "1748/16406, train loss is 10.546, state is 0.0066664512269198895, time/batch=-4.815\n",
      "Extract of training data : [2442] [21812]\n",
      "1749/16406, train loss is 10.546, state is 0.00016386184142902493, time/batch=-4.795\n",
      "Extract of training data : [1575] [1419]\n",
      "1750/16406, train loss is 10.546, state is -0.004870673641562462, time/batch=-4.843\n",
      "Extract of training data : [10] [6154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/16406, train loss is 10.546, state is 0.009773899801075459, time/batch=-4.804\n",
      "Extract of training data : [3] [3]\n",
      "1752/16406, train loss is 10.546, state is -0.003118748776614666, time/batch=-4.800\n",
      "Extract of training data : [2039] [10]\n",
      "1753/16406, train loss is 10.546, state is -0.023193085566163063, time/batch=-4.789\n",
      "Extract of training data : [105] [16]\n",
      "1754/16406, train loss is 10.546, state is 0.001457269536331296, time/batch=-4.798\n",
      "Extract of training data : [413] [473]\n",
      "1755/16406, train loss is 10.546, state is -0.015276221558451653, time/batch=-4.797\n",
      "Extract of training data : [24668] [10]\n",
      "1756/16406, train loss is 10.546, state is -0.01439331192523241, time/batch=-4.806\n",
      "Extract of training data : [2045] [877]\n",
      "1757/16406, train loss is 10.546, state is 0.00816345401108265, time/batch=-4.774\n",
      "Extract of training data : [877] [877]\n",
      "1758/16406, train loss is 10.546, state is 0.006832045968621969, time/batch=-4.820\n",
      "Extract of training data : [71] [33]\n",
      "1759/16406, train loss is 10.546, state is -0.018114859238266945, time/batch=-4.845\n",
      "Extract of training data : [3] [3]\n",
      "1760/16406, train loss is 10.546, state is 0.0034499638713896275, time/batch=-4.800\n",
      "Extract of training data : [256] [3247]\n",
      "1761/16406, train loss is 10.546, state is 0.006636994890868664, time/batch=-4.817\n",
      "Extract of training data : [10] [3818]\n",
      "1762/16406, train loss is 10.545, state is 0.0044290125370025635, time/batch=-4.832\n",
      "Extract of training data : [146] [8]\n",
      "1763/16406, train loss is 10.546, state is 0.002944718347862363, time/batch=-4.829\n",
      "Extract of training data : [18743] [465]\n",
      "1764/16406, train loss is 10.546, state is -0.007810760289430618, time/batch=-4.837\n",
      "Extract of training data : [25375] [10]\n",
      "1765/16406, train loss is 10.545, state is -0.00012141910701757297, time/batch=-4.834\n",
      "Extract of training data : [1501] [10]\n",
      "1766/16406, train loss is 10.546, state is -0.015395530499517918, time/batch=-4.866\n",
      "Extract of training data : [1577] [1176]\n",
      "1767/16406, train loss is 10.546, state is 0.008844028227031231, time/batch=-4.853\n",
      "Extract of training data : [172] [10]\n",
      "1768/16406, train loss is 10.546, state is 0.004217600915580988, time/batch=-4.800\n",
      "Extract of training data : [3728] [33]\n",
      "1769/16406, train loss is 10.546, state is 0.0009552881238050759, time/batch=-4.773\n",
      "Extract of training data : [21] [10]\n",
      "1770/16406, train loss is 10.546, state is 0.0484369695186615, time/batch=-4.821\n",
      "Extract of training data : [344] [3219]\n",
      "1771/16406, train loss is 10.546, state is 0.014773616567254066, time/batch=-4.765\n",
      "Extract of training data : [1829] [1310]\n",
      "1772/16406, train loss is 10.546, state is -0.020348209887742996, time/batch=-4.876\n",
      "Extract of training data : [3] [3]\n",
      "1773/16406, train loss is 10.546, state is -0.0052412524819374084, time/batch=-4.827\n",
      "Extract of training data : [7051] [536]\n",
      "1774/16406, train loss is 10.546, state is -0.0029565736185759306, time/batch=-4.832\n",
      "Extract of training data : [544] [372]\n",
      "1775/16406, train loss is 10.546, state is 0.00561227323487401, time/batch=-4.835\n",
      "Extract of training data : [4329] [35]\n",
      "1776/16406, train loss is 10.545, state is -0.005487286485731602, time/batch=-4.814\n",
      "Extract of training data : [16] [280]\n",
      "1777/16406, train loss is 10.545, state is 0.005231561604887247, time/batch=-4.798\n",
      "Extract of training data : [12504] [7071]\n",
      "1778/16406, train loss is 10.546, state is -0.008014721795916557, time/batch=-4.774\n",
      "Extract of training data : [2305] [912]\n",
      "1779/16406, train loss is 10.546, state is -0.019076772034168243, time/batch=-4.761\n",
      "Extract of training data : [1161] [1191]\n",
      "1780/16406, train loss is 10.546, state is -0.014394979923963547, time/batch=-4.797\n",
      "Extract of training data : [12504] [7284]\n",
      "1781/16406, train loss is 10.546, state is -0.007472638506442308, time/batch=-4.808\n",
      "Extract of training data : [8454] [16]\n",
      "1782/16406, train loss is 10.546, state is 0.005311307497322559, time/batch=-4.774\n",
      "Extract of training data : [35] [3055]\n",
      "1783/16406, train loss is 10.546, state is 0.0038134553469717503, time/batch=-4.797\n",
      "Extract of training data : [10] [26159]\n",
      "1784/16406, train loss is 10.546, state is 0.000166494442964904, time/batch=-4.827\n",
      "Extract of training data : [699] [16]\n",
      "1785/16406, train loss is 10.546, state is 0.0149306645616889, time/batch=-4.929\n",
      "Extract of training data : [24499] [12504]\n",
      "1786/16406, train loss is 10.545, state is 0.001731770345941186, time/batch=-4.850\n",
      "Extract of training data : [275] [20945]\n",
      "1787/16406, train loss is 10.546, state is -4.134304617764428e-05, time/batch=-4.843\n",
      "Extract of training data : [10] [12]\n",
      "1788/16406, train loss is 10.546, state is -0.0023517291992902756, time/batch=-4.799\n",
      "Extract of training data : [3326] [722]\n",
      "1789/16406, train loss is 10.546, state is 0.01117544062435627, time/batch=-4.911\n",
      "Extract of training data : [26887] [105]\n",
      "1790/16406, train loss is 10.546, state is -0.0019134118920192122, time/batch=-4.844\n",
      "Extract of training data : [10188] [35]\n",
      "1791/16406, train loss is 10.546, state is -0.012018375098705292, time/batch=-4.775\n",
      "Extract of training data : [4309] [10]\n",
      "1792/16406, train loss is 10.545, state is 0.003793892217800021, time/batch=-4.804\n",
      "Extract of training data : [71] [2311]\n",
      "1793/16406, train loss is 10.546, state is -0.0066881622187793255, time/batch=-4.777\n",
      "Extract of training data : [0] [0]\n",
      "1794/16406, train loss is 10.546, state is 0.00737787876278162, time/batch=-4.843\n",
      "Extract of training data : [8] [277]\n",
      "1795/16406, train loss is 10.545, state is -0.007525317370891571, time/batch=-4.823\n",
      "Extract of training data : [3] [3]\n",
      "1796/16406, train loss is 10.546, state is -0.004163037054240704, time/batch=-4.838\n",
      "Extract of training data : [10] [667]\n",
      "1797/16406, train loss is 10.546, state is -0.0004307098570279777, time/batch=-4.828\n",
      "Extract of training data : [2267] [35]\n",
      "1798/16406, train loss is 10.546, state is -0.019359929487109184, time/batch=-4.856\n",
      "Extract of training data : [27448] [13378]\n",
      "1799/16406, train loss is 10.545, state is -0.01607534848153591, time/batch=-4.883\n",
      "Extract of training data : [10] [328]\n",
      "1800/16406, train loss is 10.545, state is 0.005173909943550825, time/batch=-4.834\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [2968] [10]\n",
      "1801/16406, train loss is 10.546, state is 0.004827294964343309, time/batch=-5.088\n",
      "Extract of training data : [326] [27664]\n",
      "1802/16406, train loss is 10.545, state is 0.016310956329107285, time/batch=-4.853\n",
      "Extract of training data : [16] [0]\n",
      "1803/16406, train loss is 10.545, state is -0.0018848635954782367, time/batch=-4.821\n",
      "Extract of training data : [10] [2438]\n",
      "1804/16406, train loss is 10.545, state is -0.007952779531478882, time/batch=-4.820\n",
      "Extract of training data : [3] [3]\n",
      "1805/16406, train loss is 10.545, state is -0.015621363185346127, time/batch=-4.791\n",
      "Extract of training data : [582] [4227]\n",
      "1806/16406, train loss is 10.546, state is -0.001594059867784381, time/batch=-4.848\n",
      "Extract of training data : [0] [3]\n",
      "1807/16406, train loss is 10.546, state is -0.019953208044171333, time/batch=-4.768\n",
      "Extract of training data : [1557] [422]\n",
      "1808/16406, train loss is 10.546, state is 0.010520759038627148, time/batch=-4.815\n",
      "Extract of training data : [20102] [11553]\n",
      "1809/16406, train loss is 10.546, state is 0.004098463803529739, time/batch=-4.835\n",
      "Extract of training data : [105] [688]\n",
      "1810/16406, train loss is 10.546, state is 0.013560626655817032, time/batch=-4.856\n",
      "Extract of training data : [16577] [11276]\n",
      "1811/16406, train loss is 10.546, state is -0.01700727641582489, time/batch=-4.777\n",
      "Extract of training data : [2708] [16]\n",
      "1812/16406, train loss is 10.546, state is -0.0007077532354742289, time/batch=-4.839\n",
      "Extract of training data : [283] [12524]\n",
      "1813/16406, train loss is 10.546, state is -0.009727485477924347, time/batch=-4.812\n",
      "Extract of training data : [28432] [1161]\n",
      "1814/16406, train loss is 10.546, state is -0.021524447947740555, time/batch=-4.872\n",
      "Extract of training data : [318] [35]\n",
      "1815/16406, train loss is 10.545, state is 0.011764434166252613, time/batch=-4.850\n",
      "Extract of training data : [13897] [35]\n",
      "1816/16406, train loss is 10.546, state is 0.010472007095813751, time/batch=-4.823\n",
      "Extract of training data : [0] [0]\n",
      "1817/16406, train loss is 10.545, state is 0.015918273478746414, time/batch=-4.814\n",
      "Extract of training data : [1515] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818/16406, train loss is 10.546, state is -0.0010760943405330181, time/batch=-4.761\n",
      "Extract of training data : [533] [259]\n",
      "1819/16406, train loss is 10.546, state is -0.016441667452454567, time/batch=-4.793\n",
      "Extract of training data : [3] [9745]\n",
      "1820/16406, train loss is 10.545, state is 0.016129856929183006, time/batch=-4.782\n",
      "Extract of training data : [6286] [292]\n",
      "1821/16406, train loss is 10.546, state is 0.009640540927648544, time/batch=-4.815\n",
      "Extract of training data : [877] [1601]\n",
      "1822/16406, train loss is 10.545, state is 0.004196035675704479, time/batch=-4.760\n",
      "Extract of training data : [3] [3980]\n",
      "1823/16406, train loss is 10.546, state is 0.009312927722930908, time/batch=-4.837\n",
      "Extract of training data : [10] [422]\n",
      "1824/16406, train loss is 10.546, state is 0.01456119492650032, time/batch=-4.780\n",
      "Extract of training data : [9144] [4211]\n",
      "1825/16406, train loss is 10.546, state is -0.0021880879066884518, time/batch=-4.801\n",
      "Extract of training data : [12699] [424]\n",
      "1826/16406, train loss is 10.546, state is 0.0032170559279620647, time/batch=-4.817\n",
      "Extract of training data : [458] [4016]\n",
      "1827/16406, train loss is 10.546, state is -0.0012131480034440756, time/batch=-4.846\n",
      "Extract of training data : [12482] [10]\n",
      "1828/16406, train loss is 10.545, state is 0.01762787625193596, time/batch=-4.833\n",
      "Extract of training data : [3] [3]\n",
      "1829/16406, train loss is 10.546, state is 0.011293253861367702, time/batch=-4.887\n",
      "Extract of training data : [548] [29227]\n",
      "1830/16406, train loss is 10.545, state is 0.010835612192749977, time/batch=-4.835\n",
      "Extract of training data : [4352] [10]\n",
      "1831/16406, train loss is 10.545, state is 0.017381452023983, time/batch=-4.810\n",
      "Extract of training data : [12986] [2127]\n",
      "1832/16406, train loss is 10.546, state is -0.011425563134253025, time/batch=-4.845\n",
      "Extract of training data : [3055] [15878]\n",
      "1833/16406, train loss is 10.546, state is 0.012200365774333477, time/batch=-4.818\n",
      "Extract of training data : [1188] [2398]\n",
      "1834/16406, train loss is 10.546, state is 0.002276109531521797, time/batch=-4.787\n",
      "Extract of training data : [4179] [10]\n",
      "1835/16406, train loss is 10.546, state is -0.002560961991548538, time/batch=-4.854\n",
      "Extract of training data : [1385] [5846]\n",
      "1836/16406, train loss is 10.546, state is 0.014936914667487144, time/batch=-4.865\n",
      "Extract of training data : [0] [3]\n",
      "1837/16406, train loss is 10.546, state is -0.0002931815979536623, time/batch=-4.847\n",
      "Extract of training data : [1299] [1419]\n",
      "1838/16406, train loss is 10.546, state is -0.009311527013778687, time/batch=-4.827\n",
      "Extract of training data : [3758] [796]\n",
      "1839/16406, train loss is 10.546, state is -0.0026801112107932568, time/batch=-4.837\n",
      "Extract of training data : [29609] [10]\n",
      "1840/16406, train loss is 10.545, state is -0.009210995398461819, time/batch=-4.796\n",
      "Extract of training data : [2574] [10]\n",
      "1841/16406, train loss is 10.546, state is -0.006955070421099663, time/batch=-4.866\n",
      "Extract of training data : [3] [3]\n",
      "1842/16406, train loss is 10.546, state is 0.005724200513213873, time/batch=-4.850\n",
      "Extract of training data : [1846] [1422]\n",
      "1843/16406, train loss is 10.545, state is 0.009319290518760681, time/batch=-4.775\n",
      "Extract of training data : [2271] [4130]\n",
      "1844/16406, train loss is 10.546, state is 0.007927779108285904, time/batch=-4.795\n",
      "Extract of training data : [10] [544]\n",
      "1845/16406, train loss is 10.546, state is 0.0008257427834905684, time/batch=-4.770\n",
      "Extract of training data : [21448] [29955]\n",
      "1846/16406, train loss is 10.546, state is 0.0016287657199427485, time/batch=-4.883\n",
      "Extract of training data : [10] [3611]\n",
      "1847/16406, train loss is 10.546, state is -0.005919860675930977, time/batch=-4.792\n",
      "Extract of training data : [3] [582]\n",
      "1848/16406, train loss is 10.545, state is -0.013897445052862167, time/batch=-4.783\n",
      "Extract of training data : [30161] [20610]\n",
      "1849/16406, train loss is 10.545, state is -0.004213299602270126, time/batch=-4.802\n",
      "Extract of training data : [2257] [10]\n",
      "1850/16406, train loss is 10.546, state is 0.006913222372531891, time/batch=-4.849\n",
      "Extract of training data : [15065] [4352]\n",
      "1851/16406, train loss is 10.546, state is 0.01822877861559391, time/batch=-4.930\n",
      "Extract of training data : [35] [16445]\n",
      "1852/16406, train loss is 10.546, state is -0.006559919565916061, time/batch=-4.868\n",
      "Extract of training data : [422] [532]\n",
      "1853/16406, train loss is 10.546, state is -0.009540028870105743, time/batch=-4.763\n",
      "Extract of training data : [843] [10]\n",
      "1854/16406, train loss is 10.546, state is 0.0030127963982522488, time/batch=-4.764\n",
      "Extract of training data : [10] [30502]\n",
      "1855/16406, train loss is 10.546, state is -0.0012603832874447107, time/batch=-4.812\n",
      "Extract of training data : [10] [4141]\n",
      "1856/16406, train loss is 10.545, state is 0.0028067126404494047, time/batch=-4.844\n",
      "Extract of training data : [413] [12916]\n",
      "1857/16406, train loss is 10.546, state is 0.01117593515664339, time/batch=-4.811\n",
      "Extract of training data : [30689] [399]\n",
      "1858/16406, train loss is 10.545, state is 0.0015973872505128384, time/batch=-4.826\n",
      "Extract of training data : [0] [3]\n",
      "1859/16406, train loss is 10.546, state is -0.009324410930275917, time/batch=-4.799\n",
      "Extract of training data : [29] [413]\n",
      "1860/16406, train loss is 10.546, state is -0.0005628576036542654, time/batch=-4.806\n",
      "Extract of training data : [10] [1185]\n",
      "1861/16406, train loss is 10.545, state is 0.0032490298617631197, time/batch=-4.803\n",
      "Extract of training data : [582] [472]\n",
      "1862/16406, train loss is 10.546, state is 0.005231259390711784, time/batch=-4.885\n",
      "Extract of training data : [0] [0]\n",
      "1863/16406, train loss is 10.546, state is -0.010216440074145794, time/batch=-4.806\n",
      "Extract of training data : [553] [3340]\n",
      "1864/16406, train loss is 10.545, state is -0.005402303766459227, time/batch=-4.797\n",
      "Extract of training data : [5196] [1220]\n",
      "1865/16406, train loss is 10.546, state is -0.005317017901688814, time/batch=-4.830\n",
      "Extract of training data : [46] [1295]\n",
      "1866/16406, train loss is 10.546, state is -0.015643958002328873, time/batch=-4.900\n",
      "Extract of training data : [3] [3]\n",
      "1867/16406, train loss is 10.546, state is -0.00766307907178998, time/batch=-4.823\n",
      "Extract of training data : [50] [1963]\n",
      "1868/16406, train loss is 10.546, state is -0.010566171258687973, time/batch=-4.763\n",
      "Extract of training data : [174] [12]\n",
      "1869/16406, train loss is 10.546, state is 0.013245606794953346, time/batch=-4.817\n",
      "Extract of training data : [3408] [111]\n",
      "1870/16406, train loss is 10.545, state is -0.02085809037089348, time/batch=-4.801\n",
      "Extract of training data : [0] [0]\n",
      "1871/16406, train loss is 10.545, state is 0.00457909656688571, time/batch=-4.922\n",
      "Extract of training data : [10] [293]\n",
      "1872/16406, train loss is 10.545, state is 0.008487098850309849, time/batch=-4.826\n",
      "Extract of training data : [2720] [1628]\n",
      "1873/16406, train loss is 10.546, state is -0.010879943147301674, time/batch=-4.851\n",
      "Extract of training data : [15444] [1575]\n",
      "1874/16406, train loss is 10.546, state is -0.0038534870836883783, time/batch=-4.818\n",
      "Extract of training data : [422] [9376]\n",
      "1875/16406, train loss is 10.546, state is -0.005086612422019243, time/batch=-4.801\n",
      "Extract of training data : [28979] [413]\n",
      "1876/16406, train loss is 10.546, state is -0.007115359418094158, time/batch=-4.809\n",
      "Extract of training data : [105] [938]\n",
      "1877/16406, train loss is 10.546, state is -0.011820483952760696, time/batch=-4.826\n",
      "Extract of training data : [18981] [31828]\n",
      "1878/16406, train loss is 10.546, state is -0.010185746476054192, time/batch=-4.787\n",
      "Extract of training data : [14014] [13306]\n",
      "1879/16406, train loss is 10.546, state is -0.007612329442054033, time/batch=-4.807\n",
      "Extract of training data : [16355] [31920]\n",
      "1880/16406, train loss is 10.546, state is -0.013075937516987324, time/batch=-4.828\n",
      "Extract of training data : [957] [811]\n",
      "1881/16406, train loss is 10.545, state is 0.0026602253783494234, time/batch=-4.778\n",
      "Extract of training data : [3515] [3516]\n",
      "1882/16406, train loss is 10.546, state is 0.006806541234254837, time/batch=-4.794\n",
      "Extract of training data : [413] [21]\n",
      "1883/16406, train loss is 10.546, state is -0.00393250584602356, time/batch=-4.801\n",
      "Extract of training data : [1591] [28]\n",
      "1884/16406, train loss is 10.546, state is -0.01757194660604, time/batch=-4.794\n",
      "Extract of training data : [32107] [5180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1885/16406, train loss is 10.546, state is 0.00283954874612391, time/batch=-4.790\n",
      "Extract of training data : [12] [9745]\n",
      "1886/16406, train loss is 10.546, state is 0.003927003126591444, time/batch=-4.816\n",
      "Extract of training data : [144] [16]\n",
      "1887/16406, train loss is 10.545, state is -0.004197993315756321, time/batch=-4.818\n",
      "Extract of training data : [3] [3]\n",
      "1888/16406, train loss is 10.546, state is 0.018569784238934517, time/batch=-4.807\n",
      "Extract of training data : [0] [0]\n",
      "1889/16406, train loss is 10.546, state is -0.010683265514671803, time/batch=-4.804\n",
      "Extract of training data : [877] [280]\n",
      "1890/16406, train loss is 10.545, state is -0.0012969571398571134, time/batch=-4.817\n",
      "Extract of training data : [15481] [29328]\n",
      "1891/16406, train loss is 10.545, state is -0.0028908320236951113, time/batch=-4.795\n",
      "Extract of training data : [3] [3]\n",
      "1892/16406, train loss is 10.545, state is 0.0030078624840825796, time/batch=-4.766\n",
      "Extract of training data : [3] [3366]\n",
      "1893/16406, train loss is 10.545, state is -0.005888014566153288, time/batch=-4.797\n",
      "Extract of training data : [27445] [920]\n",
      "1894/16406, train loss is 10.546, state is -0.025706926360726357, time/batch=-4.805\n",
      "Extract of training data : [873] [2875]\n",
      "1895/16406, train loss is 10.545, state is -0.020222963765263557, time/batch=-4.768\n",
      "Extract of training data : [1597] [442]\n",
      "1896/16406, train loss is 10.546, state is 0.006545661482959986, time/batch=-4.783\n",
      "Extract of training data : [582] [1293]\n",
      "1897/16406, train loss is 10.546, state is -0.0067983572371304035, time/batch=-4.801\n",
      "Extract of training data : [877] [280]\n",
      "1898/16406, train loss is 10.545, state is -0.021270107477903366, time/batch=-4.775\n",
      "Extract of training data : [5590] [850]\n",
      "1899/16406, train loss is 10.546, state is 0.00971989519894123, time/batch=-4.801\n",
      "Extract of training data : [1014] [71]\n",
      "1900/16406, train loss is 10.546, state is -0.0015684987884014845, time/batch=-4.796\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [10] [143]\n",
      "1901/16406, train loss is 10.545, state is -0.000382515718229115, time/batch=-5.047\n",
      "Extract of training data : [4088] [1321]\n",
      "1902/16406, train loss is 10.545, state is -0.010199276730418205, time/batch=-4.915\n",
      "Extract of training data : [8] [1599]\n",
      "1903/16406, train loss is 10.546, state is 0.009990926831960678, time/batch=-4.870\n",
      "Extract of training data : [1599] [873]\n",
      "1904/16406, train loss is 10.546, state is -0.015401647426187992, time/batch=-4.799\n",
      "Extract of training data : [10378] [912]\n",
      "1905/16406, train loss is 10.546, state is 0.000497751752845943, time/batch=-4.785\n",
      "Extract of training data : [105] [371]\n",
      "1906/16406, train loss is 10.546, state is -0.002592438366264105, time/batch=-4.826\n",
      "Extract of training data : [371] [10]\n",
      "1907/16406, train loss is 10.546, state is 0.008897969499230385, time/batch=-4.823\n",
      "Extract of training data : [35] [1553]\n",
      "1908/16406, train loss is 10.546, state is -0.007623222656548023, time/batch=-4.847\n",
      "Extract of training data : [3] [23546]\n",
      "1909/16406, train loss is 10.546, state is 0.007190164644271135, time/batch=-4.815\n",
      "Extract of training data : [1745] [2853]\n",
      "1910/16406, train loss is 10.546, state is 0.014002691954374313, time/batch=-4.782\n",
      "Extract of training data : [3] [3]\n",
      "1911/16406, train loss is 10.546, state is -0.00027996228891424835, time/batch=-4.803\n",
      "Extract of training data : [3137] [10]\n",
      "1912/16406, train loss is 10.546, state is 0.014455494470894337, time/batch=-4.910\n",
      "Extract of training data : [256] [1078]\n",
      "1913/16406, train loss is 10.546, state is -0.02083374187350273, time/batch=-4.855\n",
      "Extract of training data : [5551] [571]\n",
      "1914/16406, train loss is 10.546, state is -0.006059036590158939, time/batch=-4.811\n",
      "Extract of training data : [164] [117]\n",
      "1915/16406, train loss is 10.546, state is -0.0030256586614996195, time/batch=-4.834\n",
      "Extract of training data : [1002] [21402]\n",
      "1916/16406, train loss is 10.546, state is -0.010606453754007816, time/batch=-4.860\n",
      "Extract of training data : [1265] [1289]\n",
      "1917/16406, train loss is 10.546, state is 0.015215776860713959, time/batch=-4.810\n",
      "Extract of training data : [10] [413]\n",
      "1918/16406, train loss is 10.546, state is -0.008640749379992485, time/batch=-4.803\n",
      "Extract of training data : [33275] [10]\n",
      "1919/16406, train loss is 10.546, state is -0.004399675410240889, time/batch=-4.798\n",
      "Extract of training data : [1197] [10]\n",
      "1920/16406, train loss is 10.546, state is 0.005334016866981983, time/batch=-4.831\n",
      "Extract of training data : [1188] [13896]\n",
      "1921/16406, train loss is 10.545, state is -0.009180027060210705, time/batch=-4.791\n",
      "Extract of training data : [344] [16557]\n",
      "1922/16406, train loss is 10.545, state is 0.0019073649309575558, time/batch=-4.837\n",
      "Extract of training data : [1198] [105]\n",
      "1923/16406, train loss is 10.546, state is 0.005638912785798311, time/batch=-4.798\n",
      "Extract of training data : [561] [1108]\n",
      "1924/16406, train loss is 10.546, state is -0.0027822665870189667, time/batch=-4.838\n",
      "Extract of training data : [50] [3792]\n",
      "1925/16406, train loss is 10.545, state is 0.003921572584658861, time/batch=-4.782\n",
      "Extract of training data : [32] [77]\n",
      "1926/16406, train loss is 10.545, state is 0.0038438141345977783, time/batch=-4.831\n",
      "Extract of training data : [24371] [35]\n",
      "1927/16406, train loss is 10.546, state is 0.01416975911706686, time/batch=-4.799\n",
      "Extract of training data : [33733] [10]\n",
      "1928/16406, train loss is 10.546, state is -0.0015504722250625491, time/batch=-4.801\n",
      "Extract of training data : [3] [3]\n",
      "1929/16406, train loss is 10.546, state is -0.010473544709384441, time/batch=-4.818\n",
      "Extract of training data : [4299] [14537]\n",
      "1930/16406, train loss is 10.546, state is 0.0015422697179019451, time/batch=-4.843\n",
      "Extract of training data : [10] [146]\n",
      "1931/16406, train loss is 10.545, state is -0.008629048243165016, time/batch=-4.803\n",
      "Extract of training data : [2985] [3315]\n",
      "1932/16406, train loss is 10.545, state is -0.0008067575981840491, time/batch=-4.787\n",
      "Extract of training data : [3] [164]\n",
      "1933/16406, train loss is 10.545, state is -0.002943585626780987, time/batch=-4.784\n",
      "Extract of training data : [105] [16]\n",
      "1934/16406, train loss is 10.546, state is -0.004557873122394085, time/batch=-4.767\n",
      "Extract of training data : [3] [27283]\n",
      "1935/16406, train loss is 10.546, state is 0.024849388748407364, time/batch=-4.867\n",
      "Extract of training data : [15444] [26029]\n",
      "1936/16406, train loss is 10.545, state is -0.0026613608933985233, time/batch=-4.863\n",
      "Extract of training data : [10] [34177]\n",
      "1937/16406, train loss is 10.546, state is -0.00922116544097662, time/batch=-4.782\n",
      "Extract of training data : [2121] [51]\n",
      "1938/16406, train loss is 10.546, state is 0.010079729370772839, time/batch=-4.823\n",
      "Extract of training data : [71] [5846]\n",
      "1939/16406, train loss is 10.546, state is 0.004754167515784502, time/batch=-4.830\n",
      "Extract of training data : [13476] [35]\n",
      "1940/16406, train loss is 10.545, state is 0.01015760563313961, time/batch=-4.769\n",
      "Extract of training data : [951] [105]\n",
      "1941/16406, train loss is 10.546, state is -0.0184633769094944, time/batch=-4.766\n",
      "Extract of training data : [3] [3]\n",
      "1942/16406, train loss is 10.546, state is 0.013757647015154362, time/batch=-4.801\n",
      "Extract of training data : [66] [10]\n",
      "1943/16406, train loss is 10.546, state is -0.011439413763582706, time/batch=-4.784\n",
      "Extract of training data : [111] [1416]\n",
      "1944/16406, train loss is 10.546, state is -0.015913138166069984, time/batch=-4.803\n",
      "Extract of training data : [1874] [256]\n",
      "1945/16406, train loss is 10.546, state is -0.0015394941437989473, time/batch=-4.829\n",
      "Extract of training data : [943] [2559]\n",
      "1946/16406, train loss is 10.546, state is -0.011100604198873043, time/batch=-4.798\n",
      "Extract of training data : [10] [1108]\n",
      "1947/16406, train loss is 10.545, state is -0.01716703549027443, time/batch=-4.772\n",
      "Extract of training data : [3732] [289]\n",
      "1948/16406, train loss is 10.546, state is -0.012871486134827137, time/batch=-4.789\n",
      "Extract of training data : [5351] [4130]\n",
      "1949/16406, train loss is 10.545, state is -0.005014303606003523, time/batch=-4.804\n",
      "Extract of training data : [277] [873]\n",
      "1950/16406, train loss is 10.546, state is -0.022363021969795227, time/batch=-4.886\n",
      "Extract of training data : [5780] [31849]\n",
      "1951/16406, train loss is 10.547, state is 0.008167915977537632, time/batch=-5.028\n",
      "Extract of training data : [0] [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1952/16406, train loss is 10.546, state is 0.005431664641946554, time/batch=-4.845\n",
      "Extract of training data : [6253] [10]\n",
      "1953/16406, train loss is 10.546, state is -0.0040220231749117374, time/batch=-4.800\n",
      "Extract of training data : [904] [34937]\n",
      "1954/16406, train loss is 10.547, state is 0.02975098043680191, time/batch=-4.774\n",
      "Extract of training data : [7281] [117]\n",
      "1955/16406, train loss is 10.546, state is 0.003570378292351961, time/batch=-4.796\n",
      "Extract of training data : [16] [280]\n",
      "1956/16406, train loss is 10.545, state is -0.00589317362755537, time/batch=-4.788\n",
      "Extract of training data : [35109] [2861]\n",
      "1957/16406, train loss is 10.545, state is 0.007175080943852663, time/batch=-4.842\n",
      "Extract of training data : [35] [24498]\n",
      "1958/16406, train loss is 10.545, state is 0.0019252789206802845, time/batch=-4.848\n",
      "Extract of training data : [2736] [920]\n",
      "1959/16406, train loss is 10.545, state is -0.014512055553495884, time/batch=-4.828\n",
      "Extract of training data : [2284] [675]\n",
      "1960/16406, train loss is 10.546, state is -0.005495884921401739, time/batch=-4.840\n",
      "Extract of training data : [22143] [16]\n",
      "1961/16406, train loss is 10.546, state is -0.004900468047708273, time/batch=-4.792\n",
      "Extract of training data : [532] [71]\n",
      "1962/16406, train loss is 10.546, state is -0.01156393252313137, time/batch=-4.767\n",
      "Extract of training data : [1] [1]\n",
      "1963/16406, train loss is 10.545, state is -0.013242245651781559, time/batch=-4.816\n",
      "Extract of training data : [2135] [10245]\n",
      "1964/16406, train loss is 10.546, state is -0.023016436025500298, time/batch=-4.845\n",
      "Extract of training data : [699] [436]\n",
      "1965/16406, train loss is 10.545, state is 0.008641145192086697, time/batch=-4.805\n",
      "Extract of training data : [1137] [35]\n",
      "1966/16406, train loss is 10.545, state is 0.012898963876068592, time/batch=-4.843\n",
      "Extract of training data : [35660] [912]\n",
      "1967/16406, train loss is 10.546, state is -0.0013367810752242804, time/batch=-4.768\n",
      "Extract of training data : [15010] [3268]\n",
      "1968/16406, train loss is 10.546, state is 0.005176798440515995, time/batch=-4.832\n",
      "Extract of training data : [6962] [164]\n",
      "1969/16406, train loss is 10.546, state is -0.0018254215829074383, time/batch=-4.762\n",
      "Extract of training data : [3] [3]\n",
      "1970/16406, train loss is 10.545, state is 0.014761723577976227, time/batch=-4.810\n",
      "Extract of training data : [666] [10]\n",
      "1971/16406, train loss is 10.545, state is -0.01845943182706833, time/batch=-4.896\n",
      "Extract of training data : [10] [1785]\n",
      "1972/16406, train loss is 10.546, state is -0.01330582145601511, time/batch=-4.789\n",
      "Extract of training data : [177] [105]\n",
      "1973/16406, train loss is 10.545, state is -0.0024599856697022915, time/batch=-4.812\n",
      "Extract of training data : [581] [105]\n",
      "1974/16406, train loss is 10.545, state is -0.015078271739184856, time/batch=-4.823\n",
      "Extract of training data : [10] [6891]\n",
      "1975/16406, train loss is 10.545, state is -0.011005662381649017, time/batch=-4.853\n",
      "Extract of training data : [36002] [10]\n",
      "1976/16406, train loss is 10.545, state is -0.010503210127353668, time/batch=-4.884\n",
      "Extract of training data : [10] [1626]\n",
      "1977/16406, train loss is 10.546, state is -0.010159413330256939, time/batch=-4.796\n",
      "Extract of training data : [811] [10839]\n",
      "1978/16406, train loss is 10.546, state is -0.012443658895790577, time/batch=-4.806\n",
      "Extract of training data : [16018] [10]\n",
      "1979/16406, train loss is 10.545, state is -0.001183388289064169, time/batch=-4.814\n",
      "Extract of training data : [6027] [35]\n",
      "1980/16406, train loss is 10.545, state is 0.014371911995112896, time/batch=-4.804\n",
      "Extract of training data : [1872] [45]\n",
      "1981/16406, train loss is 10.546, state is -0.005471858195960522, time/batch=-4.785\n",
      "Extract of training data : [3758] [423]\n",
      "1982/16406, train loss is 10.545, state is -0.0138357849791646, time/batch=-4.804\n",
      "Extract of training data : [3] [3]\n",
      "1983/16406, train loss is 10.546, state is -0.005413620732724667, time/batch=-4.784\n",
      "Extract of training data : [35] [2802]\n",
      "1984/16406, train loss is 10.545, state is -0.0035282764583826065, time/batch=-4.786\n",
      "Extract of training data : [811] [10]\n",
      "1985/16406, train loss is 10.545, state is -0.00022296389215625823, time/batch=-4.956\n",
      "Extract of training data : [3] [3]\n",
      "1986/16406, train loss is 10.546, state is 0.004397292155772448, time/batch=-4.789\n",
      "Extract of training data : [0] [0]\n",
      "1987/16406, train loss is 10.545, state is -0.023751823231577873, time/batch=-4.842\n",
      "Extract of training data : [8130] [10]\n",
      "1988/16406, train loss is 10.545, state is 0.005756548140197992, time/batch=-4.805\n",
      "Extract of training data : [5556] [10]\n",
      "1989/16406, train loss is 10.545, state is 0.012270977720618248, time/batch=-4.833\n",
      "Extract of training data : [10378] [35]\n",
      "1990/16406, train loss is 10.545, state is -0.0012049599317833781, time/batch=-4.832\n",
      "Extract of training data : [14454] [595]\n",
      "1991/16406, train loss is 10.545, state is 0.00202298816293478, time/batch=-4.818\n",
      "Extract of training data : [6962] [35]\n",
      "1992/16406, train loss is 10.546, state is 0.01848519779741764, time/batch=-4.830\n",
      "Extract of training data : [2492] [105]\n",
      "1993/16406, train loss is 10.545, state is 7.907242252258584e-05, time/batch=-4.775\n",
      "Extract of training data : [35] [2039]\n",
      "1994/16406, train loss is 10.546, state is -0.009504263289272785, time/batch=-4.858\n",
      "Extract of training data : [1348] [6566]\n",
      "1995/16406, train loss is 10.545, state is 0.005942056886851788, time/batch=-4.913\n",
      "Extract of training data : [5499] [10]\n",
      "1996/16406, train loss is 10.545, state is -0.0019497134489938617, time/batch=-4.820\n",
      "Extract of training data : [1078] [280]\n",
      "1997/16406, train loss is 10.546, state is 0.010319959372282028, time/batch=-4.794\n",
      "Extract of training data : [901] [559]\n",
      "1998/16406, train loss is 10.546, state is 0.010255761444568634, time/batch=-4.819\n",
      "Extract of training data : [0] [1]\n",
      "1999/16406, train loss is 10.547, state is 0.00017631259106565267, time/batch=-4.798\n",
      "Extract of training data : [3] [3]\n",
      "2000/16406, train loss is 10.547, state is -0.0024916338734328747, time/batch=-4.821\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [280] [3763]\n",
      "2001/16406, train loss is 10.546, state is 0.0045667411759495735, time/batch=-5.098\n",
      "Extract of training data : [105] [10]\n",
      "2002/16406, train loss is 10.546, state is 0.009655112400650978, time/batch=-4.832\n",
      "Extract of training data : [4213] [29]\n",
      "2003/16406, train loss is 10.546, state is -0.006229587830603123, time/batch=-4.787\n",
      "Extract of training data : [10] [777]\n",
      "2004/16406, train loss is 10.545, state is -0.01784955896437168, time/batch=-4.794\n",
      "Extract of training data : [556] [10]\n",
      "2005/16406, train loss is 10.545, state is 0.007444330956786871, time/batch=-4.838\n",
      "Extract of training data : [0] [0]\n",
      "2006/16406, train loss is 10.546, state is -0.005221391562372446, time/batch=-4.857\n",
      "Extract of training data : [105] [1742]\n",
      "2007/16406, train loss is 10.545, state is 0.008281507529318333, time/batch=-4.883\n",
      "Extract of training data : [3149] [5259]\n",
      "2008/16406, train loss is 10.546, state is -0.004712603986263275, time/batch=-4.837\n",
      "Extract of training data : [3] [3408]\n",
      "2009/16406, train loss is 10.546, state is 0.007659093476831913, time/batch=-4.899\n",
      "Extract of training data : [3674] [16]\n",
      "2010/16406, train loss is 10.546, state is -0.004739841911941767, time/batch=-4.790\n",
      "Extract of training data : [4581] [105]\n",
      "2011/16406, train loss is 10.545, state is -0.011647190898656845, time/batch=-4.834\n",
      "Extract of training data : [344] [4086]\n",
      "2012/16406, train loss is 10.545, state is 0.012213155627250671, time/batch=-4.845\n",
      "Extract of training data : [9275] [1601]\n",
      "2013/16406, train loss is 10.546, state is 0.018289882689714432, time/batch=-4.833\n",
      "Extract of training data : [16] [280]\n",
      "2014/16406, train loss is 10.545, state is -0.00011610302317421883, time/batch=-4.801\n",
      "Extract of training data : [4422] [7432]\n",
      "2015/16406, train loss is 10.546, state is 0.006786859594285488, time/batch=-4.809\n",
      "Extract of training data : [0] [3]\n",
      "2016/16406, train loss is 10.546, state is -0.015427044592797756, time/batch=-4.849\n",
      "Extract of training data : [6585] [2825]\n",
      "2017/16406, train loss is 10.546, state is -0.010686850175261497, time/batch=-4.818\n",
      "Extract of training data : [105] [10066]\n",
      "2018/16406, train loss is 10.545, state is 0.006002063397318125, time/batch=-4.816\n",
      "Extract of training data : [16] [912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/16406, train loss is 10.546, state is -0.005960332229733467, time/batch=-4.815\n",
      "Extract of training data : [647] [1826]\n",
      "2020/16406, train loss is 10.545, state is -0.0061074779368937016, time/batch=-4.816\n",
      "Extract of training data : [0] [1]\n",
      "2021/16406, train loss is 10.545, state is 0.02005310356616974, time/batch=-4.802\n",
      "Extract of training data : [4842] [10]\n",
      "2022/16406, train loss is 10.546, state is -0.0057656848803162575, time/batch=-4.809\n",
      "Extract of training data : [105] [980]\n",
      "2023/16406, train loss is 10.546, state is -0.021705348044633865, time/batch=-4.790\n",
      "Extract of training data : [10739] [12]\n",
      "2024/16406, train loss is 10.546, state is 0.015273623168468475, time/batch=-4.817\n",
      "Extract of training data : [0] [0]\n",
      "2025/16406, train loss is 10.545, state is 0.008279846049845219, time/batch=-4.833\n",
      "Extract of training data : [458] [174]\n",
      "2026/16406, train loss is 10.545, state is 0.004146073013544083, time/batch=-4.855\n",
      "Extract of training data : [4450] [105]\n",
      "2027/16406, train loss is 10.546, state is -0.004925969988107681, time/batch=-4.798\n",
      "Extract of training data : [117] [16]\n",
      "2028/16406, train loss is 10.546, state is -0.010875588282942772, time/batch=-4.827\n",
      "Extract of training data : [0] [3]\n",
      "2029/16406, train loss is 10.546, state is -0.003876669332385063, time/batch=-4.802\n",
      "Extract of training data : [105] [10]\n",
      "2030/16406, train loss is 10.546, state is -0.014710734598338604, time/batch=-4.820\n",
      "Extract of training data : [2377] [10]\n",
      "2031/16406, train loss is 10.546, state is -0.004424432758241892, time/batch=-4.829\n",
      "Extract of training data : [8] [277]\n",
      "2032/16406, train loss is 10.546, state is -0.008097855374217033, time/batch=-4.819\n",
      "Extract of training data : [10] [3732]\n",
      "2033/16406, train loss is 10.545, state is -0.004720955155789852, time/batch=-4.810\n",
      "Extract of training data : [4167] [245]\n",
      "2034/16406, train loss is 10.545, state is -0.002551381243392825, time/batch=-4.774\n",
      "Extract of training data : [943] [10]\n",
      "2035/16406, train loss is 10.546, state is -0.0023319607134908438, time/batch=-4.921\n",
      "Extract of training data : [35] [10]\n",
      "2036/16406, train loss is 10.546, state is -0.011800598353147507, time/batch=-4.835\n",
      "Extract of training data : [820] [12377]\n",
      "2037/16406, train loss is 10.546, state is 0.0072078825905919075, time/batch=-4.836\n",
      "Extract of training data : [12511] [10]\n",
      "2038/16406, train loss is 10.546, state is 0.011498693376779556, time/batch=-4.928\n",
      "Extract of training data : [12] [6027]\n",
      "2039/16406, train loss is 10.546, state is 0.003954026382416487, time/batch=-4.905\n",
      "Extract of training data : [259] [10]\n",
      "2040/16406, train loss is 10.546, state is -0.021868130192160606, time/batch=-4.949\n",
      "Extract of training data : [12970] [1119]\n",
      "2041/16406, train loss is 10.545, state is -0.022119224071502686, time/batch=-4.892\n",
      "Extract of training data : [524] [844]\n",
      "2042/16406, train loss is 10.546, state is 0.014258584007620811, time/batch=-4.847\n",
      "Extract of training data : [2147] [12]\n",
      "2043/16406, train loss is 10.546, state is 0.0026257229037582874, time/batch=-4.803\n",
      "Extract of training data : [1171] [11230]\n",
      "2044/16406, train loss is 10.546, state is -0.025815660133957863, time/batch=-4.847\n",
      "Extract of training data : [13473] [10]\n",
      "2045/16406, train loss is 10.546, state is -0.004789472557604313, time/batch=-4.853\n",
      "Extract of training data : [13794] [2045]\n",
      "2046/16406, train loss is 10.545, state is 0.005394291132688522, time/batch=-4.786\n",
      "Extract of training data : [29] [12581]\n",
      "2047/16406, train loss is 10.545, state is -0.004666214808821678, time/batch=-4.786\n",
      "Extract of training data : [13483] [10]\n",
      "2048/16406, train loss is 10.545, state is 0.015615278854966164, time/batch=-4.803\n",
      "Extract of training data : [359] [2039]\n",
      "2049/16406, train loss is 10.545, state is -0.03019680455327034, time/batch=-4.827\n",
      "Extract of training data : [2050] [13961]\n",
      "2050/16406, train loss is 10.545, state is -0.0010377226863056421, time/batch=-4.861\n",
      "Extract of training data : [10] [2886]\n",
      "2051/16406, train loss is 10.545, state is -0.005374572705477476, time/batch=-4.814\n",
      "Extract of training data : [277] [3379]\n",
      "2052/16406, train loss is 10.546, state is 0.00022906294907443225, time/batch=-4.889\n",
      "Extract of training data : [10] [14567]\n",
      "2053/16406, train loss is 10.545, state is -0.009940250776708126, time/batch=-4.824\n",
      "Extract of training data : [13293] [3285]\n",
      "2054/16406, train loss is 10.545, state is -0.017111342400312424, time/batch=-4.799\n",
      "Extract of training data : [877] [280]\n",
      "2055/16406, train loss is 10.545, state is -0.01553407870233059, time/batch=-4.824\n",
      "Extract of training data : [413] [71]\n",
      "2056/16406, train loss is 10.545, state is -0.0021627526730298996, time/batch=-4.848\n",
      "Extract of training data : [10] [1637]\n",
      "2057/16406, train loss is 10.545, state is -0.012802801094949245, time/batch=-4.799\n",
      "Extract of training data : [151] [10]\n",
      "2058/16406, train loss is 10.545, state is -0.01723419316112995, time/batch=-4.914\n",
      "Extract of training data : [906] [13737]\n",
      "2059/16406, train loss is 10.546, state is -0.0033263368532061577, time/batch=-4.789\n",
      "Extract of training data : [10] [15284]\n",
      "2060/16406, train loss is 10.545, state is 0.007555937394499779, time/batch=-4.777\n",
      "Extract of training data : [15218] [514]\n",
      "2061/16406, train loss is 10.545, state is -0.0059199766255915165, time/batch=-4.839\n",
      "Extract of training data : [465] [146]\n",
      "2062/16406, train loss is 10.545, state is -0.008267443627119064, time/batch=-4.797\n",
      "Extract of training data : [3] [910]\n",
      "2063/16406, train loss is 10.546, state is -0.0029610188212245703, time/batch=-4.829\n",
      "Extract of training data : [0] [3]\n",
      "2064/16406, train loss is 10.546, state is -0.007661733310669661, time/batch=-4.820\n",
      "Extract of training data : [55] [15900]\n",
      "2065/16406, train loss is 10.546, state is -0.0023732439149171114, time/batch=-4.880\n",
      "Extract of training data : [16019] [10]\n",
      "2066/16406, train loss is 10.545, state is 0.006784879602491856, time/batch=-4.789\n",
      "Extract of training data : [495] [50]\n",
      "2067/16406, train loss is 10.546, state is 0.007669499143958092, time/batch=-4.811\n",
      "Extract of training data : [3] [582]\n",
      "2068/16406, train loss is 10.546, state is -0.010248948819935322, time/batch=-4.820\n",
      "Extract of training data : [283] [2275]\n",
      "2069/16406, train loss is 10.545, state is -0.0014605573378503323, time/batch=-4.829\n",
      "Extract of training data : [924] [3196]\n",
      "2070/16406, train loss is 10.546, state is 0.009198940359055996, time/batch=-4.862\n",
      "Extract of training data : [10] [6213]\n",
      "2071/16406, train loss is 10.546, state is 0.01293516717851162, time/batch=-4.909\n",
      "Extract of training data : [10] [1038]\n",
      "2072/16406, train loss is 10.546, state is 0.007036148104816675, time/batch=-4.826\n",
      "Extract of training data : [3611] [71]\n",
      "2073/16406, train loss is 10.546, state is -0.00029944017296656966, time/batch=-4.799\n",
      "Extract of training data : [16] [846]\n",
      "2074/16406, train loss is 10.545, state is -0.008735204115509987, time/batch=-4.836\n",
      "Extract of training data : [3142] [5653]\n",
      "2075/16406, train loss is 10.546, state is -0.0019321935251355171, time/batch=-4.885\n",
      "Extract of training data : [35] [5065]\n",
      "2076/16406, train loss is 10.546, state is -0.012478743679821491, time/batch=-4.845\n",
      "Extract of training data : [5710] [2135]\n",
      "2077/16406, train loss is 10.545, state is -0.005380965303629637, time/batch=-4.804\n",
      "Extract of training data : [9458] [280]\n",
      "2078/16406, train loss is 10.545, state is 0.002951785223558545, time/batch=-4.820\n",
      "Extract of training data : [13587] [10231]\n",
      "2079/16406, train loss is 10.546, state is 0.006250837817788124, time/batch=-4.803\n",
      "Extract of training data : [0] [0]\n",
      "2080/16406, train loss is 10.545, state is 0.016783256083726883, time/batch=-4.805\n",
      "Extract of training data : [877] [0]\n",
      "2081/16406, train loss is 10.546, state is 0.0004352547985035926, time/batch=-4.822\n",
      "Extract of training data : [3] [3]\n",
      "2082/16406, train loss is 10.545, state is -0.010322642512619495, time/batch=-4.790\n",
      "Extract of training data : [2437] [559]\n",
      "2083/16406, train loss is 10.546, state is 0.021621419116854668, time/batch=-4.790\n",
      "Extract of training data : [3] [3]\n",
      "2084/16406, train loss is 10.546, state is 0.016797631978988647, time/batch=-4.801\n",
      "Extract of training data : [16] [0]\n",
      "2085/16406, train loss is 10.545, state is -0.0052885799668729305, time/batch=-4.770\n",
      "Extract of training data : [17913] [164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086/16406, train loss is 10.546, state is -0.006477902643382549, time/batch=-4.831\n",
      "Extract of training data : [371] [10]\n",
      "2087/16406, train loss is 10.545, state is -0.0021820191759616137, time/batch=-4.817\n",
      "Extract of training data : [344] [901]\n",
      "2088/16406, train loss is 10.545, state is 0.0031353498343378305, time/batch=-4.779\n",
      "Extract of training data : [10] [23]\n",
      "2089/16406, train loss is 10.545, state is -0.0026490408927202225, time/batch=-4.769\n",
      "Extract of training data : [8] [277]\n",
      "2090/16406, train loss is 10.545, state is 0.01804332062602043, time/batch=-4.805\n",
      "Extract of training data : [3] [3]\n",
      "2091/16406, train loss is 10.546, state is 0.012190230190753937, time/batch=-4.784\n",
      "Extract of training data : [442] [6530]\n",
      "2092/16406, train loss is 10.545, state is 0.01512851007282734, time/batch=-4.812\n",
      "Extract of training data : [3] [3]\n",
      "2093/16406, train loss is 10.545, state is -0.006553475745022297, time/batch=-4.809\n",
      "Extract of training data : [10] [121]\n",
      "2094/16406, train loss is 10.546, state is 0.0061034406535327435, time/batch=-4.818\n",
      "Extract of training data : [2854] [10]\n",
      "2095/16406, train loss is 10.545, state is -5.580902143265121e-05, time/batch=-4.784\n",
      "Extract of training data : [0] [3]\n",
      "2096/16406, train loss is 10.546, state is 0.007092057261615992, time/batch=-4.800\n",
      "Extract of training data : [108] [17042]\n",
      "2097/16406, train loss is 10.546, state is 0.012855039909482002, time/batch=-4.853\n",
      "Extract of training data : [16049] [811]\n",
      "2098/16406, train loss is 10.545, state is -0.016670124605298042, time/batch=-4.810\n",
      "Extract of training data : [21674] [2742]\n",
      "2099/16406, train loss is 10.545, state is -0.008386939764022827, time/batch=-4.857\n",
      "Extract of training data : [2137] [10]\n",
      "2100/16406, train loss is 10.545, state is 0.022410985082387924, time/batch=-4.854\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [10] [1133]\n",
      "2101/16406, train loss is 10.546, state is 0.000734193017706275, time/batch=-4.940\n",
      "Extract of training data : [10] [4950]\n",
      "2102/16406, train loss is 10.546, state is 0.010040005668997765, time/batch=-4.774\n",
      "Extract of training data : [910] [1006]\n",
      "2103/16406, train loss is 10.546, state is 0.011128460057079792, time/batch=-4.863\n",
      "Extract of training data : [920] [28]\n",
      "2104/16406, train loss is 10.546, state is -0.0030113288667052984, time/batch=-4.772\n",
      "Extract of training data : [0] [0]\n",
      "2105/16406, train loss is 10.545, state is 0.0019348332425579429, time/batch=-4.854\n",
      "Extract of training data : [10] [2639]\n",
      "2106/16406, train loss is 10.546, state is -0.00032805048977024853, time/batch=-4.835\n",
      "Extract of training data : [1575] [50]\n",
      "2107/16406, train loss is 10.546, state is -0.011942173354327679, time/batch=-4.818\n",
      "Extract of training data : [3] [873]\n",
      "2108/16406, train loss is 10.546, state is 0.0013847565278410912, time/batch=-4.776\n",
      "Extract of training data : [16] [894]\n",
      "2109/16406, train loss is 10.545, state is 0.0010058608604595065, time/batch=-4.808\n",
      "Extract of training data : [2398] [3515]\n",
      "2110/16406, train loss is 10.546, state is -0.006398740224540234, time/batch=-4.792\n",
      "Extract of training data : [623] [8391]\n",
      "2111/16406, train loss is 10.546, state is 0.0025621766690164804, time/batch=-4.815\n",
      "Extract of training data : [1131] [13365]\n",
      "2112/16406, train loss is 10.545, state is 0.00017216427659150213, time/batch=-4.824\n",
      "Extract of training data : [174] [3383]\n",
      "2113/16406, train loss is 10.545, state is 0.003580772550776601, time/batch=-4.871\n",
      "Extract of training data : [548] [2132]\n",
      "2114/16406, train loss is 10.546, state is -0.014694707468152046, time/batch=-4.806\n",
      "Extract of training data : [6891] [16]\n",
      "2115/16406, train loss is 10.545, state is -0.010125108063220978, time/batch=-4.817\n",
      "Extract of training data : [3749] [471]\n",
      "2116/16406, train loss is 10.545, state is -0.00381552055478096, time/batch=-4.844\n",
      "Extract of training data : [35] [3211]\n",
      "2117/16406, train loss is 10.546, state is 0.006127453409135342, time/batch=-4.832\n",
      "Extract of training data : [10] [413]\n",
      "2118/16406, train loss is 10.546, state is -0.012405200861394405, time/batch=-4.829\n",
      "Extract of training data : [16] [0]\n",
      "2119/16406, train loss is 10.546, state is -0.01591157168149948, time/batch=-4.809\n",
      "Extract of training data : [3732] [10]\n",
      "2120/16406, train loss is 10.545, state is 0.003962880931794643, time/batch=-4.797\n",
      "Extract of training data : [1507] [10]\n",
      "2121/16406, train loss is 10.546, state is -0.010031739249825478, time/batch=-4.806\n",
      "Extract of training data : [7183] [2051]\n",
      "2122/16406, train loss is 10.546, state is 0.0006287692813202739, time/batch=-4.797\n",
      "Extract of training data : [174] [105]\n",
      "2123/16406, train loss is 10.546, state is -0.014361893758177757, time/batch=-4.831\n",
      "Extract of training data : [10] [1741]\n",
      "2124/16406, train loss is 10.546, state is 0.0006636774051003158, time/batch=-4.885\n",
      "Extract of training data : [20707] [10]\n",
      "2125/16406, train loss is 10.546, state is 0.0024201509077101946, time/batch=-4.820\n",
      "Extract of training data : [164] [2159]\n",
      "2126/16406, train loss is 10.545, state is 0.008516193367540836, time/batch=-4.805\n",
      "Extract of training data : [524] [624]\n",
      "2127/16406, train loss is 10.546, state is -0.007929257117211819, time/batch=-4.799\n",
      "Extract of training data : [0] [3]\n",
      "2128/16406, train loss is 10.545, state is -0.001982783665880561, time/batch=-4.801\n",
      "Extract of training data : [10] [557]\n",
      "2129/16406, train loss is 10.546, state is -0.010041149333119392, time/batch=-4.768\n",
      "Extract of training data : [35] [2039]\n",
      "2130/16406, train loss is 10.546, state is 0.00481748953461647, time/batch=-4.856\n",
      "Extract of training data : [7] [8]\n",
      "2131/16406, train loss is 10.546, state is 0.001594429835677147, time/batch=-4.813\n",
      "Extract of training data : [10] [1825]\n",
      "2132/16406, train loss is 10.546, state is -0.000919711368624121, time/batch=-4.824\n",
      "Extract of training data : [3024] [35]\n",
      "2133/16406, train loss is 10.546, state is -0.003527172841131687, time/batch=-4.765\n",
      "Extract of training data : [583] [71]\n",
      "2134/16406, train loss is 10.545, state is -0.001999092288315296, time/batch=-4.814\n",
      "Extract of training data : [1481] [804]\n",
      "2135/16406, train loss is 10.546, state is 0.025248514488339424, time/batch=-4.835\n",
      "Extract of training data : [3] [29]\n",
      "2136/16406, train loss is 10.546, state is 0.015088318847119808, time/batch=-4.845\n",
      "Extract of training data : [13960] [10]\n",
      "2137/16406, train loss is 10.546, state is 0.012541168369352818, time/batch=-4.895\n",
      "Extract of training data : [19037] [5004]\n",
      "2138/16406, train loss is 10.546, state is 0.009567022323608398, time/batch=-4.808\n",
      "Extract of training data : [545] [86]\n",
      "2139/16406, train loss is 10.546, state is -0.01805434748530388, time/batch=-4.787\n",
      "Extract of training data : [10] [5157]\n",
      "2140/16406, train loss is 10.545, state is -0.011524133384227753, time/batch=-4.811\n",
      "Extract of training data : [458] [2304]\n",
      "2141/16406, train loss is 10.545, state is -0.01187680009752512, time/batch=-4.774\n",
      "Extract of training data : [20] [3230]\n",
      "2142/16406, train loss is 10.545, state is -0.0028956588357686996, time/batch=-4.853\n",
      "Extract of training data : [3] [3]\n",
      "2143/16406, train loss is 10.546, state is 0.0012996059376746416, time/batch=-4.839\n",
      "Extract of training data : [6429] [35]\n",
      "2144/16406, train loss is 10.546, state is -0.0053183538839221, time/batch=-4.792\n",
      "Extract of training data : [912] [1569]\n",
      "2145/16406, train loss is 10.546, state is -0.016993805766105652, time/batch=-4.844\n",
      "Extract of training data : [33] [23035]\n",
      "2146/16406, train loss is 10.546, state is 0.0030589685775339603, time/batch=-4.786\n",
      "Extract of training data : [1188] [29]\n",
      "2147/16406, train loss is 10.546, state is -0.008455293253064156, time/batch=-4.752\n",
      "Extract of training data : [3208] [1185]\n",
      "2148/16406, train loss is 10.546, state is 0.0023021860979497433, time/batch=-4.822\n",
      "Extract of training data : [2050] [2679]\n",
      "2149/16406, train loss is 10.546, state is 0.013446938246488571, time/batch=-4.874\n",
      "Extract of training data : [0] [0]\n",
      "2150/16406, train loss is 10.546, state is 0.00554271973669529, time/batch=-4.792\n",
      "Extract of training data : [6838] [2225]\n",
      "2151/16406, train loss is 10.546, state is -0.009820827282965183, time/batch=-4.783\n",
      "Extract of training data : [3] [1085]\n",
      "2152/16406, train loss is 10.546, state is -0.005599189084023237, time/batch=-4.915\n",
      "Extract of training data : [3] [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2153/16406, train loss is 10.545, state is -0.006237817462533712, time/batch=-5.154\n",
      "Extract of training data : [77] [105]\n",
      "2154/16406, train loss is 10.546, state is 0.00939340889453888, time/batch=-4.413\n",
      "Extract of training data : [16] [846]\n",
      "2155/16406, train loss is 10.546, state is 0.0027023879811167717, time/batch=-4.266\n",
      "Extract of training data : [6077] [10]\n",
      "2156/16406, train loss is 10.546, state is 0.010784102603793144, time/batch=-4.397\n",
      "Extract of training data : [9927] [2492]\n",
      "2157/16406, train loss is 10.545, state is -0.004596737679094076, time/batch=-4.345\n",
      "Extract of training data : [10563] [1699]\n",
      "2158/16406, train loss is 10.546, state is -0.0068716974928975105, time/batch=-4.762\n",
      "Extract of training data : [2853] [6286]\n",
      "2159/16406, train loss is 10.546, state is -0.008408264257013798, time/batch=-4.789\n",
      "Extract of training data : [21477] [23543]\n",
      "2160/16406, train loss is 10.546, state is -0.0030953919049352407, time/batch=-4.160\n",
      "Extract of training data : [737] [10]\n",
      "2161/16406, train loss is 10.546, state is -0.008528818376362324, time/batch=-4.281\n",
      "Extract of training data : [16] [12344]\n",
      "2162/16406, train loss is 10.546, state is 0.0021011349745094776, time/batch=-4.187\n",
      "Extract of training data : [328] [1273]\n",
      "2163/16406, train loss is 10.546, state is 0.004190689884126186, time/batch=-4.266\n",
      "Extract of training data : [2308] [6146]\n",
      "2164/16406, train loss is 10.546, state is 0.002575047081336379, time/batch=-4.254\n",
      "Extract of training data : [196] [10]\n",
      "2165/16406, train loss is 10.546, state is 0.015781832858920097, time/batch=-4.149\n",
      "Extract of training data : [61] [1780]\n",
      "2166/16406, train loss is 10.546, state is 0.008311795070767403, time/batch=-4.305\n",
      "Extract of training data : [0] [3]\n",
      "2167/16406, train loss is 10.546, state is -0.009542044252157211, time/batch=-4.722\n",
      "Extract of training data : [5356] [10]\n",
      "2168/16406, train loss is 10.546, state is -0.01846333034336567, time/batch=-4.688\n",
      "Extract of training data : [37560] [10]\n",
      "2169/16406, train loss is 10.546, state is 0.010719235055148602, time/batch=-4.187\n",
      "Extract of training data : [35] [24863]\n",
      "2170/16406, train loss is 10.546, state is -0.0034398287534713745, time/batch=-4.504\n",
      "Extract of training data : [3] [23535]\n",
      "2171/16406, train loss is 10.546, state is 0.0017098269890993834, time/batch=-4.920\n",
      "Extract of training data : [10] [1165]\n",
      "2172/16406, train loss is 10.546, state is 0.006481895688921213, time/batch=-4.846\n",
      "Extract of training data : [13159] [5930]\n",
      "2173/16406, train loss is 10.546, state is 0.0018918124260380864, time/batch=-4.864\n",
      "Extract of training data : [3197] [23950]\n",
      "2174/16406, train loss is 10.546, state is 0.008911952376365662, time/batch=-4.795\n",
      "Extract of training data : [2404] [3270]\n",
      "2175/16406, train loss is 10.546, state is 0.00042260659392923117, time/batch=-4.816\n",
      "Extract of training data : [850] [1481]\n",
      "2176/16406, train loss is 10.546, state is -0.004215030465275049, time/batch=-4.834\n",
      "Extract of training data : [18303] [1]\n",
      "2177/16406, train loss is 10.546, state is 0.0021554394625127316, time/batch=-4.791\n",
      "Extract of training data : [280] [422]\n",
      "2178/16406, train loss is 10.546, state is -0.0022000721655786037, time/batch=-4.831\n",
      "Extract of training data : [3] [3]\n",
      "2179/16406, train loss is 10.546, state is -0.012487808242440224, time/batch=-4.793\n",
      "Extract of training data : [10] [3125]\n",
      "2180/16406, train loss is 10.546, state is 0.003971627447754145, time/batch=-4.851\n",
      "Extract of training data : [10177] [10]\n",
      "2181/16406, train loss is 10.546, state is -0.016256973147392273, time/batch=-4.827\n",
      "Extract of training data : [29] [5880]\n",
      "2182/16406, train loss is 10.546, state is -0.010176138952374458, time/batch=-4.820\n",
      "Extract of training data : [35] [1293]\n",
      "2183/16406, train loss is 10.546, state is -0.0024084928445518017, time/batch=-4.835\n",
      "Extract of training data : [2883] [51]\n",
      "2184/16406, train loss is 10.546, state is -0.0006876033148728311, time/batch=-4.826\n",
      "Extract of training data : [3] [3]\n",
      "2185/16406, train loss is 10.546, state is 0.00396078871563077, time/batch=-4.794\n",
      "Extract of training data : [4281] [1483]\n",
      "2186/16406, train loss is 10.545, state is -0.0018423872534185648, time/batch=-4.833\n",
      "Extract of training data : [1293] [26201]\n",
      "2187/16406, train loss is 10.546, state is 0.0016292735235765576, time/batch=-4.807\n",
      "Extract of training data : [2597] [10]\n",
      "2188/16406, train loss is 10.546, state is -0.013925133273005486, time/batch=-4.895\n",
      "Extract of training data : [21] [17647]\n",
      "2189/16406, train loss is 10.546, state is -0.009808552451431751, time/batch=-4.841\n",
      "Extract of training data : [13628] [12]\n",
      "2190/16406, train loss is 10.546, state is 0.01280942466109991, time/batch=-4.796\n",
      "Extract of training data : [5313] [105]\n",
      "2191/16406, train loss is 10.546, state is -0.01368027739226818, time/batch=-4.824\n",
      "Extract of training data : [3] [3]\n",
      "2192/16406, train loss is 10.546, state is 0.0022226539440453053, time/batch=-4.793\n",
      "Extract of training data : [0] [3]\n",
      "2193/16406, train loss is 10.546, state is 0.005502075422555208, time/batch=-4.846\n",
      "Extract of training data : [737] [35]\n",
      "2194/16406, train loss is 10.546, state is 0.0037414671387523413, time/batch=-4.821\n",
      "Extract of training data : [21] [1171]\n",
      "2195/16406, train loss is 10.546, state is 0.009014569222927094, time/batch=-4.851\n",
      "Extract of training data : [10] [344]\n",
      "2196/16406, train loss is 10.546, state is 0.0015534533886238933, time/batch=-4.862\n",
      "Extract of training data : [3414] [16]\n",
      "2197/16406, train loss is 10.546, state is 0.005061393603682518, time/batch=-4.864\n",
      "Extract of training data : [2341] [7289]\n",
      "2198/16406, train loss is 10.545, state is 0.00564809562638402, time/batch=-4.807\n",
      "Extract of training data : [0] [0]\n",
      "2199/16406, train loss is 10.546, state is 0.0031388066709041595, time/batch=-4.832\n",
      "Extract of training data : [6485] [2970]\n",
      "2200/16406, train loss is 10.545, state is 0.0030108275823295116, time/batch=-4.942\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [8] [277]\n",
      "2201/16406, train loss is 10.546, state is -0.006528761703521013, time/batch=-5.262\n",
      "Extract of training data : [10] [159]\n",
      "2202/16406, train loss is 10.545, state is -0.011108706705272198, time/batch=-4.920\n",
      "Extract of training data : [458] [15872]\n",
      "2203/16406, train loss is 10.545, state is 0.0138628501445055, time/batch=-4.830\n",
      "Extract of training data : [422] [143]\n",
      "2204/16406, train loss is 10.545, state is -0.02462073601782322, time/batch=-4.790\n",
      "Extract of training data : [7539] [27618]\n",
      "2205/16406, train loss is 10.546, state is -0.02253490872681141, time/batch=-4.844\n",
      "Extract of training data : [10] [901]\n",
      "2206/16406, train loss is 10.545, state is -0.0015079618897289038, time/batch=-4.834\n",
      "Extract of training data : [1087] [237]\n",
      "2207/16406, train loss is 10.545, state is -0.001112168887630105, time/batch=-4.839\n",
      "Extract of training data : [6528] [1220]\n",
      "2208/16406, train loss is 10.545, state is -0.019249795004725456, time/batch=-4.829\n",
      "Extract of training data : [1180] [10]\n",
      "2209/16406, train loss is 10.546, state is 0.0038329854141920805, time/batch=-4.831\n",
      "Extract of training data : [10] [50]\n",
      "2210/16406, train loss is 10.546, state is -0.006615308579057455, time/batch=-4.828\n",
      "Extract of training data : [19388] [51]\n",
      "2211/16406, train loss is 10.546, state is 0.0087824622169137, time/batch=-4.877\n",
      "Extract of training data : [1946] [2612]\n",
      "2212/16406, train loss is 10.546, state is 0.002690482186153531, time/batch=-4.875\n",
      "Extract of training data : [2300] [10]\n",
      "2213/16406, train loss is 10.546, state is -0.0005490605253726244, time/batch=-4.810\n",
      "Extract of training data : [105] [715]\n",
      "2214/16406, train loss is 10.546, state is 0.006783760152757168, time/batch=-4.882\n",
      "Extract of training data : [10] [28405]\n",
      "2215/16406, train loss is 10.546, state is 0.00923440046608448, time/batch=-4.805\n",
      "Extract of training data : [29] [28482]\n",
      "2216/16406, train loss is 10.545, state is -0.011513189412653446, time/batch=-4.852\n",
      "Extract of training data : [71] [5777]\n",
      "2217/16406, train loss is 10.546, state is -0.00015173100109677762, time/batch=-4.878\n",
      "Extract of training data : [1185] [29]\n",
      "2218/16406, train loss is 10.545, state is -0.005637248512357473, time/batch=-4.825\n",
      "Extract of training data : [105] [850]\n",
      "2219/16406, train loss is 10.546, state is 0.002486602170392871, time/batch=-4.813\n",
      "Extract of training data : [9745] [4441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220/16406, train loss is 10.545, state is -0.01023935154080391, time/batch=-4.854\n",
      "Extract of training data : [3154] [2844]\n",
      "2221/16406, train loss is 10.546, state is 0.014548239298164845, time/batch=-4.851\n",
      "Extract of training data : [16] [1785]\n",
      "2222/16406, train loss is 10.545, state is -0.009919741190969944, time/batch=-4.822\n",
      "Extract of training data : [688] [1846]\n",
      "2223/16406, train loss is 10.546, state is -0.011926905252039433, time/batch=-4.769\n",
      "Extract of training data : [1599] [6409]\n",
      "2224/16406, train loss is 10.546, state is 0.010678739286959171, time/batch=-4.795\n",
      "Extract of training data : [10886] [10]\n",
      "2225/16406, train loss is 10.546, state is -0.009289628826081753, time/batch=-4.901\n",
      "Extract of training data : [1507] [10]\n",
      "2226/16406, train loss is 10.546, state is 0.008330798707902431, time/batch=-4.839\n",
      "Extract of training data : [2182] [3404]\n",
      "2227/16406, train loss is 10.546, state is -0.006118223071098328, time/batch=-4.876\n",
      "Extract of training data : [1821] [51]\n",
      "2228/16406, train loss is 10.546, state is -0.014374040998518467, time/batch=-4.826\n",
      "Extract of training data : [10] [2910]\n",
      "2229/16406, train loss is 10.546, state is -0.0009416656102985144, time/batch=-4.828\n",
      "Extract of training data : [28963] [3743]\n",
      "2230/16406, train loss is 10.545, state is -0.012144183740019798, time/batch=-4.828\n",
      "Extract of training data : [29174] [35]\n",
      "2231/16406, train loss is 10.546, state is 0.0031979915220290422, time/batch=-4.898\n",
      "Extract of training data : [3203] [10]\n",
      "2232/16406, train loss is 10.545, state is 0.0031799646094441414, time/batch=-4.758\n",
      "Extract of training data : [16878] [35]\n",
      "2233/16406, train loss is 10.545, state is 0.0058794766664505005, time/batch=-4.811\n",
      "Extract of training data : [1081] [5124]\n",
      "2234/16406, train loss is 10.546, state is -0.01836451143026352, time/batch=-4.843\n",
      "Extract of training data : [3980] [2679]\n",
      "2235/16406, train loss is 10.545, state is 0.0080353282392025, time/batch=-4.839\n",
      "Extract of training data : [3] [5168]\n",
      "2236/16406, train loss is 10.546, state is 0.0003987153177149594, time/batch=-4.781\n",
      "Extract of training data : [10] [344]\n",
      "2237/16406, train loss is 10.546, state is 0.00893367175012827, time/batch=-4.844\n",
      "Extract of training data : [571] [6997]\n",
      "2238/16406, train loss is 10.546, state is 0.0122043676674366, time/batch=-4.814\n",
      "Extract of training data : [10] [571]\n",
      "2239/16406, train loss is 10.546, state is 0.012728283181786537, time/batch=-4.792\n",
      "Extract of training data : [910] [963]\n",
      "2240/16406, train loss is 10.546, state is -0.0021537868306040764, time/batch=-4.770\n",
      "Extract of training data : [1051] [8]\n",
      "2241/16406, train loss is 10.546, state is 0.004745887592434883, time/batch=-4.828\n",
      "Extract of training data : [2913] [16549]\n",
      "2242/16406, train loss is 10.545, state is 0.007783267181366682, time/batch=-4.954\n",
      "Extract of training data : [29715] [32]\n",
      "2243/16406, train loss is 10.545, state is 0.004639059770852327, time/batch=-4.809\n",
      "Extract of training data : [10] [688]\n",
      "2244/16406, train loss is 10.546, state is -0.0031460104510188103, time/batch=-4.806\n",
      "Extract of training data : [3] [3]\n",
      "2245/16406, train loss is 10.546, state is -0.0029283887706696987, time/batch=-4.808\n",
      "Extract of training data : [10] [633]\n",
      "2246/16406, train loss is 10.546, state is -0.01173478364944458, time/batch=-4.796\n",
      "Extract of training data : [3] [291]\n",
      "2247/16406, train loss is 10.545, state is -0.01649087853729725, time/batch=-4.779\n",
      "Extract of training data : [3055] [71]\n",
      "2248/16406, train loss is 10.546, state is 0.010913657024502754, time/batch=-4.806\n",
      "Extract of training data : [10] [9562]\n",
      "2249/16406, train loss is 10.546, state is -0.008633296936750412, time/batch=-4.790\n",
      "Extract of training data : [9027] [10]\n",
      "2250/16406, train loss is 10.545, state is -0.001837227726355195, time/batch=-4.776\n",
      "Extract of training data : [5507] [4610]\n",
      "2251/16406, train loss is 10.545, state is 0.019485604017972946, time/batch=-4.865\n",
      "Extract of training data : [105] [1078]\n",
      "2252/16406, train loss is 10.546, state is -0.002664069179445505, time/batch=-4.806\n",
      "Extract of training data : [0] [0]\n",
      "2253/16406, train loss is 10.546, state is -0.00091306131798774, time/batch=-4.787\n",
      "Extract of training data : [1366] [1553]\n",
      "2254/16406, train loss is 10.545, state is -0.016388721764087677, time/batch=-4.833\n",
      "Extract of training data : [8] [277]\n",
      "2255/16406, train loss is 10.545, state is -0.014265654608607292, time/batch=-4.873\n",
      "Extract of training data : [11486] [10]\n",
      "2256/16406, train loss is 10.545, state is -0.014208431355655193, time/batch=-4.834\n",
      "Extract of training data : [3] [20583]\n",
      "2257/16406, train loss is 10.545, state is 0.008895602077245712, time/batch=-4.839\n",
      "Extract of training data : [378] [720]\n",
      "2258/16406, train loss is 10.545, state is -0.01388834323734045, time/batch=-4.826\n",
      "Extract of training data : [46] [22852]\n",
      "2259/16406, train loss is 10.545, state is 0.004868092946708202, time/batch=-4.802\n",
      "Extract of training data : [3493] [35]\n",
      "2260/16406, train loss is 10.545, state is -0.006126058287918568, time/batch=-4.837\n",
      "Extract of training data : [3] [20583]\n",
      "2261/16406, train loss is 10.545, state is 0.01743476465344429, time/batch=-4.863\n",
      "Extract of training data : [10987] [105]\n",
      "2262/16406, train loss is 10.545, state is -0.0202338844537735, time/batch=-4.843\n",
      "Extract of training data : [7001] [29526]\n",
      "2263/16406, train loss is 10.545, state is -0.0003228276618756354, time/batch=-4.799\n",
      "Extract of training data : [7166] [12]\n",
      "2264/16406, train loss is 10.545, state is -0.004601106513291597, time/batch=-4.793\n",
      "Extract of training data : [12524] [174]\n",
      "2265/16406, train loss is 10.546, state is 0.008679439313709736, time/batch=-4.833\n",
      "Extract of training data : [3524] [1256]\n",
      "2266/16406, train loss is 10.546, state is -0.0008091233321465552, time/batch=-4.865\n",
      "Extract of training data : [55] [174]\n",
      "2267/16406, train loss is 10.546, state is -0.0033280756324529648, time/batch=-4.829\n",
      "Extract of training data : [1636] [10]\n",
      "2268/16406, train loss is 10.545, state is -0.0012543214252218604, time/batch=-4.806\n",
      "Extract of training data : [31476] [10]\n",
      "2269/16406, train loss is 10.545, state is -0.012147797271609306, time/batch=-4.831\n",
      "Extract of training data : [3] [3]\n",
      "2270/16406, train loss is 10.545, state is -0.01106482744216919, time/batch=-4.770\n",
      "Extract of training data : [12] [150]\n",
      "2271/16406, train loss is 10.546, state is -0.011083731427788734, time/batch=-4.824\n",
      "Extract of training data : [60] [6578]\n",
      "2272/16406, train loss is 10.546, state is -0.003065172815695405, time/batch=-4.830\n",
      "Extract of training data : [3] [3]\n",
      "2273/16406, train loss is 10.546, state is -0.014126492664217949, time/batch=-4.844\n",
      "Extract of training data : [8837] [10]\n",
      "2274/16406, train loss is 10.546, state is 0.009686185047030449, time/batch=-4.881\n",
      "Extract of training data : [8467] [2704]\n",
      "2275/16406, train loss is 10.546, state is -0.035365693271160126, time/batch=-4.782\n",
      "Extract of training data : [31897] [2159]\n",
      "2276/16406, train loss is 10.546, state is -0.020160213112831116, time/batch=-4.832\n",
      "Extract of training data : [3] [31950]\n",
      "2277/16406, train loss is 10.545, state is -0.00816623866558075, time/batch=-4.837\n",
      "Extract of training data : [1006] [1769]\n",
      "2278/16406, train loss is 10.545, state is 4.985529085388407e-05, time/batch=-4.802\n",
      "Extract of training data : [301] [10]\n",
      "2279/16406, train loss is 10.546, state is -0.007312382105737925, time/batch=-4.818\n",
      "Extract of training data : [50] [71]\n",
      "2280/16406, train loss is 10.546, state is 0.0022983206436038017, time/batch=-4.826\n",
      "Extract of training data : [10] [588]\n",
      "2281/16406, train loss is 10.545, state is 0.02370678074657917, time/batch=-4.822\n",
      "Extract of training data : [0] [0]\n",
      "2282/16406, train loss is 10.546, state is -0.011429151520133018, time/batch=-4.798\n",
      "Extract of training data : [413] [4118]\n",
      "2283/16406, train loss is 10.545, state is -0.011292128823697567, time/batch=-4.816\n",
      "Extract of training data : [1273] [51]\n",
      "2284/16406, train loss is 10.546, state is -0.0006034210091456771, time/batch=-4.883\n",
      "Extract of training data : [8] [277]\n",
      "2285/16406, train loss is 10.546, state is -0.006502967793494463, time/batch=-4.840\n",
      "Extract of training data : [2946] [544]\n",
      "2286/16406, train loss is 10.546, state is -0.009426411241292953, time/batch=-4.795\n",
      "Extract of training data : [10] [1190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2287/16406, train loss is 10.546, state is -0.0047447835095226765, time/batch=-4.895\n",
      "Extract of training data : [24694] [19548]\n",
      "2288/16406, train loss is 10.545, state is -0.004500968847423792, time/batch=-4.818\n",
      "Extract of training data : [8725] [105]\n",
      "2289/16406, train loss is 10.545, state is 0.007668078411370516, time/batch=-4.872\n",
      "Extract of training data : [2075] [105]\n",
      "2290/16406, train loss is 10.545, state is 0.00787117425352335, time/batch=-4.839\n",
      "Extract of training data : [1575] [5137]\n",
      "2291/16406, train loss is 10.545, state is 0.002752172527834773, time/batch=-4.827\n",
      "Extract of training data : [10] [9645]\n",
      "2292/16406, train loss is 10.546, state is -0.006335888989269733, time/batch=-4.828\n",
      "Extract of training data : [6531] [51]\n",
      "2293/16406, train loss is 10.546, state is -0.012910652905702591, time/batch=-4.797\n",
      "Extract of training data : [3] [3]\n",
      "2294/16406, train loss is 10.546, state is 0.01829640194773674, time/batch=-4.788\n",
      "Extract of training data : [5284] [21127]\n",
      "2295/16406, train loss is 10.546, state is 0.005359960719943047, time/batch=-4.785\n",
      "Extract of training data : [873] [2105]\n",
      "2296/16406, train loss is 10.546, state is 0.00538655323907733, time/batch=-5.050\n",
      "Extract of training data : [35] [277]\n",
      "2297/16406, train loss is 10.546, state is -0.0023165990132838488, time/batch=-4.831\n",
      "Extract of training data : [3610] [0]\n",
      "2298/16406, train loss is 10.545, state is 0.010919641703367233, time/batch=-4.908\n",
      "Extract of training data : [1507] [631]\n",
      "2299/16406, train loss is 10.545, state is 0.00011647355131572112, time/batch=-4.879\n",
      "Extract of training data : [1207] [105]\n",
      "2300/16406, train loss is 10.545, state is 0.0038861341308802366, time/batch=-4.869\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [280] [0]\n",
      "2301/16406, train loss is 10.545, state is -0.021327301859855652, time/batch=-5.068\n",
      "Extract of training data : [32906] [3758]\n",
      "2302/16406, train loss is 10.545, state is 0.0034648918081074953, time/batch=-4.920\n",
      "Extract of training data : [35] [2633]\n",
      "2303/16406, train loss is 10.546, state is 0.003163686254993081, time/batch=-4.908\n",
      "Extract of training data : [3] [8821]\n",
      "2304/16406, train loss is 10.546, state is -0.015421727672219276, time/batch=-4.876\n",
      "Extract of training data : [3] [3]\n",
      "2305/16406, train loss is 10.545, state is -0.00518085528165102, time/batch=-4.917\n",
      "Extract of training data : [0] [3]\n",
      "2306/16406, train loss is 10.546, state is 0.005338555201888084, time/batch=-4.873\n",
      "Extract of training data : [12284] [29]\n",
      "2307/16406, train loss is 10.546, state is -0.0116635262966156, time/batch=-4.804\n",
      "Extract of training data : [13192] [0]\n",
      "2308/16406, train loss is 10.546, state is 0.0011426208075135946, time/batch=-4.852\n",
      "Extract of training data : [1572] [35]\n",
      "2309/16406, train loss is 10.546, state is -0.00038682378362864256, time/batch=-4.819\n",
      "Extract of training data : [9822] [10]\n",
      "2310/16406, train loss is 10.546, state is -0.0015894329408183694, time/batch=-4.818\n",
      "Extract of training data : [0] [0]\n",
      "2311/16406, train loss is 10.546, state is -0.0015260863583534956, time/batch=-4.813\n",
      "Extract of training data : [35] [16632]\n",
      "2312/16406, train loss is 10.546, state is 0.006344159599393606, time/batch=-4.786\n",
      "Extract of training data : [6929] [10]\n",
      "2313/16406, train loss is 10.546, state is -0.0388193354010582, time/batch=-4.798\n",
      "Extract of training data : [2985] [2892]\n",
      "2314/16406, train loss is 10.546, state is -0.00983317568898201, time/batch=-4.784\n",
      "Extract of training data : [561] [882]\n",
      "2315/16406, train loss is 10.545, state is -0.0163645651191473, time/batch=-4.796\n",
      "Extract of training data : [5654] [35]\n",
      "2316/16406, train loss is 10.545, state is -0.01861458644270897, time/batch=-4.888\n",
      "Extract of training data : [10] [783]\n",
      "2317/16406, train loss is 10.545, state is 0.006463649217039347, time/batch=-4.866\n",
      "Extract of training data : [1017] [1988]\n",
      "2318/16406, train loss is 10.545, state is 0.0001381499314447865, time/batch=-4.802\n",
      "Extract of training data : [3367] [1079]\n",
      "2319/16406, train loss is 10.545, state is 0.016570990905165672, time/batch=-4.795\n",
      "Extract of training data : [18518] [378]\n",
      "2320/16406, train loss is 10.545, state is -0.00593913160264492, time/batch=-4.858\n",
      "Extract of training data : [35] [3127]\n",
      "2321/16406, train loss is 10.545, state is 0.008222317323088646, time/batch=-4.806\n",
      "Extract of training data : [10] [1477]\n",
      "2322/16406, train loss is 10.545, state is -0.017539221793413162, time/batch=-4.828\n",
      "Extract of training data : [5067] [35]\n",
      "2323/16406, train loss is 10.546, state is 0.008045691065490246, time/batch=-4.827\n",
      "Extract of training data : [3] [3]\n",
      "2324/16406, train loss is 10.546, state is -0.011134590022265911, time/batch=-4.779\n",
      "Extract of training data : [3] [3]\n",
      "2325/16406, train loss is 10.545, state is -0.0013261535204946995, time/batch=-4.815\n",
      "Extract of training data : [105] [10]\n",
      "2326/16406, train loss is 10.545, state is 0.005717557854950428, time/batch=-4.898\n",
      "Extract of training data : [12504] [29]\n",
      "2327/16406, train loss is 10.545, state is -0.024307511746883392, time/batch=-4.843\n",
      "Extract of training data : [20583] [2791]\n",
      "2328/16406, train loss is 10.545, state is -0.0010319435968995094, time/batch=-4.849\n",
      "Extract of training data : [13349] [413]\n",
      "2329/16406, train loss is 10.546, state is 0.007977865636348724, time/batch=-4.854\n",
      "Extract of training data : [29] [6899]\n",
      "2330/16406, train loss is 10.545, state is 0.012062881141901016, time/batch=-4.841\n",
      "Extract of training data : [1180] [10]\n",
      "2331/16406, train loss is 10.545, state is -0.0062864082865417, time/batch=-4.836\n",
      "Extract of training data : [11] [2923]\n",
      "2332/16406, train loss is 10.545, state is -0.0002488106256350875, time/batch=-4.831\n",
      "Extract of training data : [675] [3904]\n",
      "2333/16406, train loss is 10.545, state is -0.009431895799934864, time/batch=-4.819\n",
      "Extract of training data : [10] [2050]\n",
      "2334/16406, train loss is 10.546, state is -0.010508817620575428, time/batch=-4.803\n",
      "Extract of training data : [2063] [2311]\n",
      "2335/16406, train loss is 10.546, state is 0.011697519570589066, time/batch=-4.842\n",
      "Extract of training data : [3] [7243]\n",
      "2336/16406, train loss is 10.545, state is 0.002295283367857337, time/batch=-4.821\n",
      "Extract of training data : [16717] [327]\n",
      "2337/16406, train loss is 10.546, state is -0.009998932480812073, time/batch=-4.866\n",
      "Extract of training data : [34576] [1182]\n",
      "2338/16406, train loss is 10.546, state is -0.00867338664829731, time/batch=-4.837\n",
      "Extract of training data : [6286] [2398]\n",
      "2339/16406, train loss is 10.545, state is 0.01203810703009367, time/batch=-4.811\n",
      "Extract of training data : [10] [439]\n",
      "2340/16406, train loss is 10.545, state is -0.0009164625080302358, time/batch=-4.950\n",
      "Extract of training data : [1529] [10]\n",
      "2341/16406, train loss is 10.546, state is 0.009730976074934006, time/batch=-4.795\n",
      "Extract of training data : [916] [920]\n",
      "2342/16406, train loss is 10.545, state is -0.012612531892955303, time/batch=-4.867\n",
      "Extract of training data : [15508] [3104]\n",
      "2343/16406, train loss is 10.546, state is -0.02032272145152092, time/batch=-4.944\n",
      "Extract of training data : [0] [0]\n",
      "2344/16406, train loss is 10.546, state is 0.0020999773405492306, time/batch=-4.798\n",
      "Extract of training data : [592] [1134]\n",
      "2345/16406, train loss is 10.545, state is 0.02046218514442444, time/batch=-4.826\n",
      "Extract of training data : [10] [4266]\n",
      "2346/16406, train loss is 10.545, state is -0.0041428618133068085, time/batch=-4.888\n",
      "Extract of training data : [4990] [46]\n",
      "2347/16406, train loss is 10.546, state is -0.014444615691900253, time/batch=-4.846\n",
      "Extract of training data : [23] [3758]\n",
      "2348/16406, train loss is 10.545, state is 0.007996040396392345, time/batch=-4.834\n",
      "Extract of training data : [105] [1661]\n",
      "2349/16406, train loss is 10.546, state is 0.014692520722746849, time/batch=-4.853\n",
      "Extract of training data : [12] [1273]\n",
      "2350/16406, train loss is 10.546, state is 0.006051812320947647, time/batch=-4.883\n",
      "Extract of training data : [2925] [13914]\n",
      "2351/16406, train loss is 10.546, state is -0.003256151918321848, time/batch=-4.826\n",
      "Extract of training data : [413] [71]\n",
      "2352/16406, train loss is 10.546, state is -0.007867022417485714, time/batch=-4.821\n",
      "Extract of training data : [877] [280]\n",
      "2353/16406, train loss is 10.545, state is 0.011587855406105518, time/batch=-4.873\n",
      "Extract of training data : [8539] [35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2354/16406, train loss is 10.546, state is -0.00046485502389259636, time/batch=-4.840\n",
      "Extract of training data : [35565] [35566]\n",
      "2355/16406, train loss is 10.545, state is 0.00623356644064188, time/batch=-4.809\n",
      "Extract of training data : [1515] [10]\n",
      "2356/16406, train loss is 10.545, state is -0.012439814396202564, time/batch=-4.879\n",
      "Extract of training data : [20818] [127]\n",
      "2357/16406, train loss is 10.545, state is 0.002185635268688202, time/batch=-4.830\n",
      "Extract of training data : [1636] [10]\n",
      "2358/16406, train loss is 10.545, state is -0.004553989972919226, time/batch=-4.825\n",
      "Extract of training data : [4143] [34218]\n",
      "2359/16406, train loss is 10.546, state is -0.013060009106993675, time/batch=-4.869\n",
      "Extract of training data : [190] [555]\n",
      "2360/16406, train loss is 10.545, state is 0.005026515107601881, time/batch=-4.947\n",
      "Extract of training data : [4765] [10]\n",
      "2361/16406, train loss is 10.546, state is 0.0022110973950475454, time/batch=-4.842\n",
      "Extract of training data : [0] [0]\n",
      "2362/16406, train loss is 10.545, state is -0.0024830454494804144, time/batch=-4.819\n",
      "Extract of training data : [1014] [17764]\n",
      "2363/16406, train loss is 10.546, state is 0.00021651192218996584, time/batch=-4.938\n",
      "Extract of training data : [6873] [2813]\n",
      "2364/16406, train loss is 10.545, state is 0.004628794267773628, time/batch=-4.850\n",
      "Extract of training data : [2076] [633]\n",
      "2365/16406, train loss is 10.545, state is -0.0019414351554587483, time/batch=-4.814\n",
      "Extract of training data : [1507] [10]\n",
      "2366/16406, train loss is 10.546, state is -0.010455025359988213, time/batch=-4.816\n",
      "Extract of training data : [3] [3]\n",
      "2367/16406, train loss is 10.545, state is -0.003397571388632059, time/batch=-4.900\n",
      "Extract of training data : [4945] [499]\n",
      "2368/16406, train loss is 10.545, state is 0.008712349459528923, time/batch=-4.802\n",
      "Extract of training data : [1675] [4162]\n",
      "2369/16406, train loss is 10.546, state is -0.024707717821002007, time/batch=-4.804\n",
      "Extract of training data : [1386] [0]\n",
      "2370/16406, train loss is 10.545, state is -0.007512431591749191, time/batch=-4.816\n",
      "Extract of training data : [2633] [906]\n",
      "2371/16406, train loss is 10.546, state is -0.016179794445633888, time/batch=-4.812\n",
      "Extract of training data : [422] [35]\n",
      "2372/16406, train loss is 10.546, state is -0.019355246797204018, time/batch=-4.839\n",
      "Extract of training data : [176] [7949]\n",
      "2373/16406, train loss is 10.545, state is 0.008895439095795155, time/batch=-4.847\n",
      "Extract of training data : [51] [106]\n",
      "2374/16406, train loss is 10.546, state is -0.009298210963606834, time/batch=-4.823\n",
      "Extract of training data : [3] [277]\n",
      "2375/16406, train loss is 10.545, state is 0.0036600674502551556, time/batch=-4.826\n",
      "Extract of training data : [10] [3485]\n",
      "2376/16406, train loss is 10.545, state is 0.005481223110109568, time/batch=-4.865\n",
      "Extract of training data : [105] [910]\n",
      "2377/16406, train loss is 10.545, state is -0.0073976884596049786, time/batch=-4.776\n",
      "Extract of training data : [2119] [10]\n",
      "2378/16406, train loss is 10.546, state is 0.0050607468001544476, time/batch=-4.832\n",
      "Extract of training data : [28829] [2007]\n",
      "2379/16406, train loss is 10.546, state is 0.0009735851781442761, time/batch=-4.841\n",
      "Extract of training data : [0] [3]\n",
      "2380/16406, train loss is 10.545, state is 0.009570901282131672, time/batch=-4.821\n",
      "Extract of training data : [0] [3]\n",
      "2381/16406, train loss is 10.545, state is 0.002897409023717046, time/batch=-4.797\n",
      "Extract of training data : [3] [3]\n",
      "2382/16406, train loss is 10.546, state is -0.006604486145079136, time/batch=-4.811\n",
      "Extract of training data : [3] [3]\n",
      "2383/16406, train loss is 10.546, state is -0.015059249475598335, time/batch=-4.798\n",
      "Extract of training data : [9167] [12915]\n",
      "2384/16406, train loss is 10.545, state is -0.005648376885801554, time/batch=-4.790\n",
      "Extract of training data : [0] [1]\n",
      "2385/16406, train loss is 10.545, state is -0.0044733574613928795, time/batch=-4.831\n",
      "Extract of training data : [883] [10]\n",
      "2386/16406, train loss is 10.545, state is -0.021404201164841652, time/batch=-4.812\n",
      "Extract of training data : [277] [1137]\n",
      "2387/16406, train loss is 10.545, state is -0.004695568699389696, time/batch=-4.814\n",
      "Extract of training data : [3] [3]\n",
      "2388/16406, train loss is 10.545, state is -0.0010061119683086872, time/batch=-4.776\n",
      "Extract of training data : [1935] [422]\n",
      "2389/16406, train loss is 10.546, state is -0.023029591888189316, time/batch=-4.790\n",
      "Extract of training data : [2605] [359]\n",
      "2390/16406, train loss is 10.545, state is -0.00988466665148735, time/batch=-4.824\n",
      "Extract of training data : [3516] [14]\n",
      "2391/16406, train loss is 10.545, state is -0.022142594680190086, time/batch=-4.856\n",
      "Extract of training data : [3516] [3701]\n",
      "2392/16406, train loss is 10.546, state is 0.016209742054343224, time/batch=-4.842\n",
      "Extract of training data : [359] [804]\n",
      "2393/16406, train loss is 10.545, state is 0.009600860066711903, time/batch=-4.791\n",
      "Extract of training data : [806] [105]\n",
      "2394/16406, train loss is 10.545, state is -0.006050491705536842, time/batch=-4.816\n",
      "Extract of training data : [4868] [105]\n",
      "2395/16406, train loss is 10.545, state is 0.009009649977087975, time/batch=-4.831\n",
      "Extract of training data : [10] [2854]\n",
      "2396/16406, train loss is 10.545, state is -0.018926337361335754, time/batch=-4.824\n",
      "Extract of training data : [3] [1021]\n",
      "2397/16406, train loss is 10.545, state is -0.019610639661550522, time/batch=-4.847\n",
      "Extract of training data : [10] [5860]\n",
      "2398/16406, train loss is 10.545, state is 0.016460902988910675, time/batch=-4.819\n",
      "Extract of training data : [3] [292]\n",
      "2399/16406, train loss is 10.545, state is 0.0010569465812295675, time/batch=-4.806\n",
      "Extract of training data : [6327] [811]\n",
      "2400/16406, train loss is 10.545, state is 0.0064763836562633514, time/batch=-4.787\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [291] [643]\n",
      "2401/16406, train loss is 10.545, state is 0.0017881820676848292, time/batch=-4.986\n",
      "Extract of training data : [413] [876]\n",
      "2402/16406, train loss is 10.545, state is 0.011829150840640068, time/batch=-4.794\n",
      "Extract of training data : [1056] [7122]\n",
      "2403/16406, train loss is 10.545, state is -0.008585824631154537, time/batch=-4.797\n",
      "Extract of training data : [25] [1437]\n",
      "2404/16406, train loss is 10.546, state is -0.021565953269600868, time/batch=-4.798\n",
      "Extract of training data : [2141] [28]\n",
      "2405/16406, train loss is 10.545, state is -0.011277369223535061, time/batch=-4.795\n",
      "Extract of training data : [559] [71]\n",
      "2406/16406, train loss is 10.545, state is -0.011220208369195461, time/batch=-4.901\n",
      "Extract of training data : [3] [3]\n",
      "2407/16406, train loss is 10.545, state is -0.00892542488873005, time/batch=-4.850\n",
      "Extract of training data : [110] [10]\n",
      "2408/16406, train loss is 10.545, state is -0.002315860241651535, time/batch=-4.844\n",
      "Extract of training data : [8197] [16]\n",
      "2409/16406, train loss is 10.545, state is 0.0010711046634241939, time/batch=-4.813\n",
      "Extract of training data : [6749] [8411]\n",
      "2410/16406, train loss is 10.545, state is -0.017882555723190308, time/batch=-4.911\n",
      "Extract of training data : [8606] [1220]\n",
      "2411/16406, train loss is 10.545, state is 0.00994658563286066, time/batch=-4.783\n",
      "Extract of training data : [3] [699]\n",
      "2412/16406, train loss is 10.546, state is -0.005166932474821806, time/batch=-4.804\n",
      "Extract of training data : [277] [4505]\n",
      "2413/16406, train loss is 10.545, state is -0.0030309646390378475, time/batch=-4.797\n",
      "Extract of training data : [3] [422]\n",
      "2414/16406, train loss is 10.545, state is -0.012387212365865707, time/batch=-4.814\n",
      "Extract of training data : [3552] [3553]\n",
      "2415/16406, train loss is 10.546, state is -0.0010731220245361328, time/batch=-4.810\n",
      "Extract of training data : [9380] [51]\n",
      "2416/16406, train loss is 10.545, state is 0.0007960355142131448, time/batch=-4.808\n",
      "Extract of training data : [35] [2404]\n",
      "2417/16406, train loss is 10.546, state is -0.004014960490167141, time/batch=-4.813\n",
      "Extract of training data : [3327] [2586]\n",
      "2418/16406, train loss is 10.545, state is 0.008858218789100647, time/batch=-4.807\n",
      "Extract of training data : [10] [3366]\n",
      "2419/16406, train loss is 10.546, state is -0.021549105644226074, time/batch=-4.810\n",
      "Extract of training data : [3] [3]\n",
      "2420/16406, train loss is 10.545, state is 0.01567547582089901, time/batch=-4.785\n",
      "Extract of training data : [0] [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2421/16406, train loss is 10.546, state is -0.0009766921866685152, time/batch=-4.833\n",
      "Extract of training data : [3] [3]\n",
      "2422/16406, train loss is 10.546, state is -0.006733647082000971, time/batch=-4.841\n",
      "Extract of training data : [10] [3155]\n",
      "2423/16406, train loss is 10.546, state is 0.0016098353080451488, time/batch=-4.815\n",
      "Extract of training data : [530] [10]\n",
      "2424/16406, train loss is 10.546, state is 0.005309689790010452, time/batch=-4.834\n",
      "Extract of training data : [801] [10142]\n",
      "2425/16406, train loss is 10.546, state is -0.006901395041495562, time/batch=-4.821\n",
      "Extract of training data : [277] [6179]\n",
      "2426/16406, train loss is 10.546, state is -0.004915905185043812, time/batch=-4.819\n",
      "Extract of training data : [6077] [10]\n",
      "2427/16406, train loss is 10.546, state is -0.008956336416304111, time/batch=-4.778\n",
      "Extract of training data : [10924] [10230]\n",
      "2428/16406, train loss is 10.546, state is -0.021467523649334908, time/batch=-4.813\n",
      "Extract of training data : [0] [0]\n",
      "2429/16406, train loss is 10.546, state is -0.006804526783525944, time/batch=-4.802\n",
      "Extract of training data : [3566] [413]\n",
      "2430/16406, train loss is 10.546, state is -0.014451684430241585, time/batch=-4.813\n",
      "Extract of training data : [3] [1707]\n",
      "2431/16406, train loss is 10.546, state is 0.005691901780664921, time/batch=-4.809\n",
      "Extract of training data : [1997] [16]\n",
      "2432/16406, train loss is 10.546, state is -0.004097484517842531, time/batch=-4.844\n",
      "Extract of training data : [3516] [2941]\n",
      "2433/16406, train loss is 10.546, state is -0.011678616516292095, time/batch=-4.801\n",
      "Extract of training data : [105] [1594]\n",
      "2434/16406, train loss is 10.546, state is 0.005605699028819799, time/batch=-4.824\n",
      "Extract of training data : [11697] [263]\n",
      "2435/16406, train loss is 10.546, state is -0.0016843852354213595, time/batch=-4.814\n",
      "Extract of training data : [548] [105]\n",
      "2436/16406, train loss is 10.545, state is 0.008693695068359375, time/batch=-4.817\n",
      "Extract of training data : [32] [3613]\n",
      "2437/16406, train loss is 10.546, state is 0.0037178564816713333, time/batch=-4.810\n",
      "Extract of training data : [3] [3]\n",
      "2438/16406, train loss is 10.546, state is 0.010968766175210476, time/batch=-4.783\n",
      "Extract of training data : [277] [12281]\n",
      "2439/16406, train loss is 10.545, state is 0.006129364017397165, time/batch=-4.825\n",
      "Extract of training data : [1220] [10]\n",
      "2440/16406, train loss is 10.546, state is -0.003972585778683424, time/batch=-4.796\n",
      "Extract of training data : [1480] [10]\n",
      "2441/16406, train loss is 10.546, state is -0.0007992672617547214, time/batch=-4.826\n",
      "Extract of training data : [6025] [10]\n",
      "2442/16406, train loss is 10.545, state is 0.009321247227489948, time/batch=-4.924\n",
      "Extract of training data : [10] [1971]\n",
      "2443/16406, train loss is 10.545, state is 0.0013809326337650418, time/batch=-4.822\n",
      "Extract of training data : [1021] [1161]\n",
      "2444/16406, train loss is 10.545, state is 0.003861738834530115, time/batch=-4.844\n",
      "Extract of training data : [13194] [1007]\n",
      "2445/16406, train loss is 10.546, state is 0.002408076310530305, time/batch=-4.838\n",
      "Extract of training data : [528] [877]\n",
      "2446/16406, train loss is 10.546, state is 0.006806390359997749, time/batch=-4.951\n",
      "Extract of training data : [3] [912]\n",
      "2447/16406, train loss is 10.546, state is 0.005389506462961435, time/batch=-4.846\n",
      "Extract of training data : [13562] [13563]\n",
      "2448/16406, train loss is 10.546, state is -0.006459418218582869, time/batch=-4.778\n",
      "Extract of training data : [1079] [105]\n",
      "2449/16406, train loss is 10.545, state is -0.006472736597061157, time/batch=-4.871\n",
      "Extract of training data : [3] [846]\n",
      "2450/16406, train loss is 10.545, state is -0.0024338122457265854, time/batch=-4.864\n",
      "Extract of training data : [5740] [9010]\n",
      "2451/16406, train loss is 10.545, state is -0.0029125679284334183, time/batch=-4.765\n",
      "Extract of training data : [4681] [10]\n",
      "2452/16406, train loss is 10.545, state is -0.0038489094004034996, time/batch=-4.807\n",
      "Extract of training data : [8] [277]\n",
      "2453/16406, train loss is 10.546, state is -0.0017000646330416203, time/batch=-4.836\n",
      "Extract of training data : [277] [2442]\n",
      "2454/16406, train loss is 10.545, state is -0.01845293864607811, time/batch=-4.811\n",
      "Extract of training data : [280] [0]\n",
      "2455/16406, train loss is 10.545, state is 0.010571868158876896, time/batch=-4.793\n",
      "Extract of training data : [11460] [10]\n",
      "2456/16406, train loss is 10.545, state is -0.01991966739296913, time/batch=-4.791\n",
      "Extract of training data : [924] [3938]\n",
      "2457/16406, train loss is 10.545, state is -0.018929634243249893, time/batch=-4.830\n",
      "Extract of training data : [3758] [688]\n",
      "2458/16406, train loss is 10.545, state is -0.007398972753435373, time/batch=-4.826\n",
      "Extract of training data : [14893] [1185]\n",
      "2459/16406, train loss is 10.545, state is 0.0023498644586652517, time/batch=-4.833\n",
      "Extract of training data : [492] [12]\n",
      "2460/16406, train loss is 10.545, state is -0.0037854614201933146, time/batch=-4.846\n",
      "Extract of training data : [505] [1177]\n",
      "2461/16406, train loss is 10.545, state is -0.007012973073869944, time/batch=-4.812\n",
      "Extract of training data : [4853] [16]\n",
      "2462/16406, train loss is 10.545, state is -0.009391740895807743, time/batch=-4.827\n",
      "Extract of training data : [46] [6974]\n",
      "2463/16406, train loss is 10.545, state is -0.004563589580357075, time/batch=-4.815\n",
      "Extract of training data : [3328] [6399]\n",
      "2464/16406, train loss is 10.545, state is 0.0022490646224468946, time/batch=-4.853\n",
      "Extract of training data : [3] [910]\n",
      "2465/16406, train loss is 10.546, state is 0.012748200446367264, time/batch=-4.836\n",
      "Extract of training data : [699] [16]\n",
      "2466/16406, train loss is 10.546, state is 0.00026419467758387327, time/batch=-4.842\n",
      "Extract of training data : [3758] [832]\n",
      "2467/16406, train loss is 10.546, state is -0.013547354377806187, time/batch=-4.886\n",
      "Extract of training data : [10] [1489]\n",
      "2468/16406, train loss is 10.545, state is -0.015497450716793537, time/batch=-4.815\n",
      "Extract of training data : [105] [371]\n",
      "2469/16406, train loss is 10.545, state is -0.004773005843162537, time/batch=-4.836\n",
      "Extract of training data : [1167] [873]\n",
      "2470/16406, train loss is 10.546, state is 0.004716816358268261, time/batch=-4.820\n",
      "Extract of training data : [910] [1803]\n",
      "2471/16406, train loss is 10.545, state is -0.005001395475119352, time/batch=-4.855\n",
      "Extract of training data : [1021] [811]\n",
      "2472/16406, train loss is 10.546, state is -0.003044955665245652, time/batch=-4.894\n",
      "Extract of training data : [0] [0]\n",
      "2473/16406, train loss is 10.546, state is -0.01023157499730587, time/batch=-4.818\n",
      "Extract of training data : [280] [0]\n",
      "2474/16406, train loss is 10.546, state is 0.010974030941724777, time/batch=-4.796\n",
      "Extract of training data : [16725] [14224]\n",
      "2475/16406, train loss is 10.546, state is -0.010874971747398376, time/batch=-4.840\n",
      "Extract of training data : [284] [285]\n",
      "2476/16406, train loss is 10.546, state is 0.008965777233242989, time/batch=-4.804\n",
      "Extract of training data : [0] [0]\n",
      "2477/16406, train loss is 10.546, state is 2.3469094230677e-05, time/batch=-4.790\n",
      "Extract of training data : [11071] [35]\n",
      "2478/16406, train loss is 10.546, state is -0.010406835936009884, time/batch=-4.845\n",
      "Extract of training data : [10] [17100]\n",
      "2479/16406, train loss is 10.545, state is 0.016072988510131836, time/batch=-4.832\n",
      "Extract of training data : [10] [6402]\n",
      "2480/16406, train loss is 10.545, state is -0.00045990737271495163, time/batch=-4.898\n",
      "Extract of training data : [14342] [17345]\n",
      "2481/16406, train loss is 10.546, state is -0.006543128751218319, time/batch=-4.858\n",
      "Extract of training data : [17464] [559]\n",
      "2482/16406, train loss is 10.545, state is -0.001895334804430604, time/batch=-4.838\n",
      "Extract of training data : [3516] [35]\n",
      "2483/16406, train loss is 10.545, state is -0.023857660591602325, time/batch=-4.884\n",
      "Extract of training data : [910] [378]\n",
      "2484/16406, train loss is 10.545, state is -0.008300624787807465, time/batch=-4.850\n",
      "Extract of training data : [3285] [1077]\n",
      "2485/16406, train loss is 10.546, state is -0.016262182965874672, time/batch=-4.988\n",
      "Extract of training data : [559] [3105]\n",
      "2486/16406, train loss is 10.546, state is -0.0033406305592507124, time/batch=-4.840\n",
      "Extract of training data : [10] [143]\n",
      "2487/16406, train loss is 10.545, state is 0.004835234489291906, time/batch=-4.814\n",
      "Extract of training data : [3] [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2488/16406, train loss is 10.546, state is 0.006190972402691841, time/batch=-4.800\n",
      "Extract of training data : [1188] [12110]\n",
      "2489/16406, train loss is 10.546, state is 0.005486587528139353, time/batch=-4.864\n",
      "Extract of training data : [16451] [164]\n",
      "2490/16406, train loss is 10.545, state is -0.0035417473409324884, time/batch=-4.852\n",
      "Extract of training data : [3] [3]\n",
      "2491/16406, train loss is 10.545, state is -0.003438139334321022, time/batch=-4.819\n",
      "Extract of training data : [0] [3]\n",
      "2492/16406, train loss is 10.546, state is 0.004719607997685671, time/batch=-4.809\n",
      "Extract of training data : [3055] [10]\n",
      "2493/16406, train loss is 10.546, state is -0.004902885761111975, time/batch=-4.824\n",
      "Extract of training data : [3] [3]\n",
      "2494/16406, train loss is 10.546, state is -0.02049667201936245, time/batch=-4.833\n",
      "Extract of training data : [13381] [10]\n",
      "2495/16406, train loss is 10.546, state is -0.002196365501731634, time/batch=-4.876\n",
      "Extract of training data : [3] [3]\n",
      "2496/16406, train loss is 10.546, state is 0.0001981871173484251, time/batch=-4.822\n",
      "Extract of training data : [436] [283]\n",
      "2497/16406, train loss is 10.546, state is -0.0030327634885907173, time/batch=-4.889\n",
      "Extract of training data : [1137] [28]\n",
      "2498/16406, train loss is 10.546, state is 0.0032442857045680285, time/batch=-4.818\n",
      "Extract of training data : [413] [2442]\n",
      "2499/16406, train loss is 10.546, state is -0.008947995491325855, time/batch=-4.875\n",
      "Extract of training data : [11953] [17849]\n",
      "2500/16406, train loss is 10.545, state is 0.0006916298298165202, time/batch=-4.760\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [3] [3]\n",
      "2501/16406, train loss is 10.546, state is -0.014774939976632595, time/batch=-5.051\n",
      "Extract of training data : [3] [3]\n",
      "2502/16406, train loss is 10.546, state is -0.004779044538736343, time/batch=-4.871\n",
      "Extract of training data : [10] [3860]\n",
      "2503/16406, train loss is 10.545, state is 0.006809432525187731, time/batch=-4.791\n",
      "Extract of training data : [146] [8]\n",
      "2504/16406, train loss is 10.546, state is -0.01302236970514059, time/batch=-4.802\n",
      "Extract of training data : [4873] [2924]\n",
      "2505/16406, train loss is 10.546, state is -0.0020442320965230465, time/batch=-4.813\n",
      "Extract of training data : [10] [2398]\n",
      "2506/16406, train loss is 10.545, state is 0.00034398259595036507, time/batch=-4.808\n",
      "Extract of training data : [245] [10]\n",
      "2507/16406, train loss is 10.545, state is 0.009527900256216526, time/batch=-4.818\n",
      "Extract of training data : [561] [4309]\n",
      "2508/16406, train loss is 10.546, state is -0.00350311491638422, time/batch=-4.771\n",
      "Extract of training data : [14] [17716]\n",
      "2509/16406, train loss is 10.545, state is 0.00011707328667398542, time/batch=-4.829\n",
      "Extract of training data : [413] [17114]\n",
      "2510/16406, train loss is 10.545, state is 0.011752516962587833, time/batch=-4.817\n",
      "Extract of training data : [972] [883]\n",
      "2511/16406, train loss is 10.546, state is -0.005672984290868044, time/batch=-4.805\n",
      "Extract of training data : [1180] [35]\n",
      "2512/16406, train loss is 10.545, state is 0.006937530357390642, time/batch=-4.792\n",
      "Extract of training data : [0] [0]\n",
      "2513/16406, train loss is 10.545, state is 0.0059567950665950775, time/batch=-4.845\n",
      "Extract of training data : [3] [3]\n",
      "2514/16406, train loss is 10.546, state is -0.008096210658550262, time/batch=-4.814\n",
      "Extract of training data : [6982] [688]\n",
      "2515/16406, train loss is 10.546, state is -0.003960460424423218, time/batch=-4.824\n",
      "Extract of training data : [1185] [13445]\n",
      "2516/16406, train loss is 10.546, state is 0.003403632901608944, time/batch=-4.838\n",
      "Extract of training data : [10] [753]\n",
      "2517/16406, train loss is 10.545, state is 0.0013019901234656572, time/batch=-4.820\n",
      "Extract of training data : [533] [2221]\n",
      "2518/16406, train loss is 10.546, state is 0.017430976033210754, time/batch=-4.805\n",
      "Extract of training data : [3] [3]\n",
      "2519/16406, train loss is 10.546, state is 0.0054548573680222034, time/batch=-4.822\n",
      "Extract of training data : [1139] [10]\n",
      "2520/16406, train loss is 10.546, state is -0.023102344945073128, time/batch=-4.838\n",
      "Extract of training data : [2611] [801]\n",
      "2521/16406, train loss is 10.546, state is -0.013295862823724747, time/batch=-4.843\n",
      "Extract of training data : [0] [3]\n",
      "2522/16406, train loss is 10.546, state is 0.006449043285101652, time/batch=-4.836\n",
      "Extract of training data : [3830] [478]\n",
      "2523/16406, train loss is 10.546, state is 0.007272956892848015, time/batch=-4.779\n",
      "Extract of training data : [1426] [16]\n",
      "2524/16406, train loss is 10.546, state is -0.005464424379169941, time/batch=-4.796\n",
      "Extract of training data : [422] [35]\n",
      "2525/16406, train loss is 10.546, state is 0.009521003812551498, time/batch=-4.814\n",
      "Extract of training data : [873] [29]\n",
      "2526/16406, train loss is 10.546, state is -0.003855601418763399, time/batch=-4.825\n",
      "Extract of training data : [19037] [21284]\n",
      "2527/16406, train loss is 10.545, state is 0.006762735079973936, time/batch=-4.833\n",
      "Extract of training data : [5214] [5809]\n",
      "2528/16406, train loss is 10.546, state is -0.00023811226128600538, time/batch=-4.870\n",
      "Extract of training data : [11789] [2007]\n",
      "2529/16406, train loss is 10.546, state is -0.02209370955824852, time/batch=-4.942\n",
      "Extract of training data : [1445] [9663]\n",
      "2530/16406, train loss is 10.546, state is -0.001777855446562171, time/batch=-4.854\n",
      "Extract of training data : [35] [826]\n",
      "2531/16406, train loss is 10.545, state is -0.00289031770080328, time/batch=-4.883\n",
      "Extract of training data : [10] [176]\n",
      "2532/16406, train loss is 10.545, state is -0.0048805284313857555, time/batch=-4.842\n",
      "Extract of training data : [422] [1289]\n",
      "2533/16406, train loss is 10.546, state is -0.004901772830635309, time/batch=-4.804\n",
      "Extract of training data : [0] [0]\n",
      "2534/16406, train loss is 10.546, state is -0.010913760401308537, time/batch=-4.847\n",
      "Extract of training data : [413] [4311]\n",
      "2535/16406, train loss is 10.545, state is 0.004289870150387287, time/batch=-4.848\n",
      "Extract of training data : [3] [3]\n",
      "2536/16406, train loss is 10.546, state is -0.005277599208056927, time/batch=-4.819\n",
      "Extract of training data : [11483] [2508]\n",
      "2537/16406, train loss is 10.546, state is 0.003697215346619487, time/batch=-4.790\n",
      "Extract of training data : [12] [972]\n",
      "2538/16406, train loss is 10.546, state is 0.001725316746160388, time/batch=-4.830\n",
      "Extract of training data : [4378] [16249]\n",
      "2539/16406, train loss is 10.546, state is -0.002846398623660207, time/batch=-4.802\n",
      "Extract of training data : [3] [3]\n",
      "2540/16406, train loss is 10.546, state is 0.0020110481418669224, time/batch=-4.824\n",
      "Extract of training data : [12] [22382]\n",
      "2541/16406, train loss is 10.546, state is -0.003492310643196106, time/batch=-4.806\n",
      "Extract of training data : [291] [495]\n",
      "2542/16406, train loss is 10.546, state is 0.006883881986141205, time/batch=-4.865\n",
      "Extract of training data : [16] [0]\n",
      "2543/16406, train loss is 10.546, state is 0.0070565687492489815, time/batch=-4.835\n",
      "Extract of training data : [22596] [12843]\n",
      "2544/16406, train loss is 10.545, state is -0.0016319812275469303, time/batch=-4.809\n",
      "Extract of training data : [3] [3]\n",
      "2545/16406, train loss is 10.545, state is -0.0062211682088673115, time/batch=-4.802\n",
      "Extract of training data : [3] [3]\n",
      "2546/16406, train loss is 10.546, state is 0.01161174662411213, time/batch=-4.854\n",
      "Extract of training data : [20707] [720]\n",
      "2547/16406, train loss is 10.546, state is 0.004867789801210165, time/batch=-4.785\n",
      "Extract of training data : [20510] [16]\n",
      "2548/16406, train loss is 10.546, state is 0.02103324607014656, time/batch=-4.770\n",
      "Extract of training data : [559] [464]\n",
      "2549/16406, train loss is 10.546, state is 0.000741019903216511, time/batch=-4.801\n",
      "Extract of training data : [5214] [1078]\n",
      "2550/16406, train loss is 10.546, state is 0.0006514526903629303, time/batch=-4.831\n",
      "Extract of training data : [1458] [9701]\n",
      "2551/16406, train loss is 10.546, state is -0.01851423643529415, time/batch=-4.779\n",
      "Extract of training data : [1234] [1842]\n",
      "2552/16406, train loss is 10.546, state is 0.004851995036005974, time/batch=-4.826\n",
      "Extract of training data : [10] [4307]\n",
      "2553/16406, train loss is 10.546, state is -0.018318599089980125, time/batch=-4.784\n",
      "Extract of training data : [105] [2045]\n",
      "2554/16406, train loss is 10.546, state is -0.015225324779748917, time/batch=-4.812\n",
      "Extract of training data : [3202] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2555/16406, train loss is 10.546, state is -0.015313719399273396, time/batch=-4.816\n",
      "Extract of training data : [23373] [16]\n",
      "2556/16406, train loss is 10.546, state is -0.01783085986971855, time/batch=-4.838\n",
      "Extract of training data : [3] [3]\n",
      "2557/16406, train loss is 10.546, state is -0.0004040659696329385, time/batch=-4.813\n",
      "Extract of training data : [2557] [3]\n",
      "2558/16406, train loss is 10.545, state is 0.0020310983527451754, time/batch=-4.805\n",
      "Extract of training data : [5593] [2392]\n",
      "2559/16406, train loss is 10.546, state is 0.005490757059305906, time/batch=-4.809\n",
      "Extract of training data : [1437] [16726]\n",
      "2560/16406, train loss is 10.546, state is -0.017529066652059555, time/batch=-4.830\n",
      "Extract of training data : [1308] [5313]\n",
      "2561/16406, train loss is 10.546, state is 0.011567101813852787, time/batch=-4.851\n",
      "Extract of training data : [280] [1228]\n",
      "2562/16406, train loss is 10.546, state is -0.029143568128347397, time/batch=-4.800\n",
      "Extract of training data : [3] [277]\n",
      "2563/16406, train loss is 10.546, state is -0.0033706538379192352, time/batch=-4.788\n",
      "Extract of training data : [13852] [2841]\n",
      "2564/16406, train loss is 10.546, state is 0.0005928957252763212, time/batch=-4.842\n",
      "Extract of training data : [378] [327]\n",
      "2565/16406, train loss is 10.546, state is 0.011276989243924618, time/batch=-4.824\n",
      "Extract of training data : [23552] [146]\n",
      "2566/16406, train loss is 10.546, state is -0.006294067949056625, time/batch=-4.851\n",
      "Extract of training data : [10] [14699]\n",
      "2567/16406, train loss is 10.546, state is -0.019905462861061096, time/batch=-4.807\n",
      "Extract of training data : [7937] [2082]\n",
      "2568/16406, train loss is 10.546, state is 0.0066664512269198895, time/batch=-4.848\n",
      "Extract of training data : [2442] [21812]\n",
      "2569/16406, train loss is 10.546, state is 0.00016386184142902493, time/batch=-4.831\n",
      "Extract of training data : [1575] [1419]\n",
      "2570/16406, train loss is 10.546, state is -0.004870673641562462, time/batch=-4.784\n",
      "Extract of training data : [10] [6154]\n",
      "2571/16406, train loss is 10.546, state is 0.009773899801075459, time/batch=-4.947\n",
      "Extract of training data : [3] [3]\n",
      "2572/16406, train loss is 10.546, state is -0.003118748776614666, time/batch=-4.837\n",
      "Extract of training data : [2039] [10]\n",
      "2573/16406, train loss is 10.546, state is -0.023193085566163063, time/batch=-4.809\n",
      "Extract of training data : [105] [16]\n",
      "2574/16406, train loss is 10.546, state is 0.001457269536331296, time/batch=-4.804\n",
      "Extract of training data : [413] [473]\n",
      "2575/16406, train loss is 10.546, state is -0.015276221558451653, time/batch=-4.804\n",
      "Extract of training data : [24668] [10]\n",
      "2576/16406, train loss is 10.546, state is -0.01439331192523241, time/batch=-4.782\n",
      "Extract of training data : [2045] [877]\n",
      "2577/16406, train loss is 10.546, state is 0.00816345401108265, time/batch=-4.812\n",
      "Extract of training data : [877] [877]\n",
      "2578/16406, train loss is 10.546, state is 0.006832045968621969, time/batch=-4.824\n",
      "Extract of training data : [71] [33]\n",
      "2579/16406, train loss is 10.546, state is -0.018114859238266945, time/batch=-4.813\n",
      "Extract of training data : [3] [3]\n",
      "2580/16406, train loss is 10.546, state is 0.0034499638713896275, time/batch=-4.859\n",
      "Extract of training data : [256] [3247]\n",
      "2581/16406, train loss is 10.546, state is 0.006636994890868664, time/batch=-4.830\n",
      "Extract of training data : [10] [3818]\n",
      "2582/16406, train loss is 10.545, state is 0.0044290125370025635, time/batch=-4.867\n",
      "Extract of training data : [146] [8]\n",
      "2583/16406, train loss is 10.546, state is 0.002944718347862363, time/batch=-4.959\n",
      "Extract of training data : [18743] [465]\n",
      "2584/16406, train loss is 10.546, state is -0.007810760289430618, time/batch=-4.813\n",
      "Extract of training data : [25375] [10]\n",
      "2585/16406, train loss is 10.545, state is -0.00012141910701757297, time/batch=-4.823\n",
      "Extract of training data : [1501] [10]\n",
      "2586/16406, train loss is 10.546, state is -0.015395530499517918, time/batch=-4.822\n",
      "Extract of training data : [1577] [1176]\n",
      "2587/16406, train loss is 10.546, state is 0.008844028227031231, time/batch=-4.895\n",
      "Extract of training data : [172] [10]\n",
      "2588/16406, train loss is 10.546, state is 0.004217600915580988, time/batch=-4.811\n",
      "Extract of training data : [3728] [33]\n",
      "2589/16406, train loss is 10.546, state is 0.0009552881238050759, time/batch=-4.853\n",
      "Extract of training data : [21] [10]\n",
      "2590/16406, train loss is 10.546, state is 0.0484369695186615, time/batch=-4.784\n",
      "Extract of training data : [344] [3219]\n",
      "2591/16406, train loss is 10.546, state is 0.014773616567254066, time/batch=-4.818\n",
      "Extract of training data : [1829] [1310]\n",
      "2592/16406, train loss is 10.546, state is -0.020348209887742996, time/batch=-4.802\n",
      "Extract of training data : [3] [3]\n",
      "2593/16406, train loss is 10.546, state is -0.0052412524819374084, time/batch=-4.787\n",
      "Extract of training data : [7051] [536]\n",
      "2594/16406, train loss is 10.546, state is -0.0029565736185759306, time/batch=-4.819\n",
      "Extract of training data : [544] [372]\n",
      "2595/16406, train loss is 10.546, state is 0.00561227323487401, time/batch=-4.887\n",
      "Extract of training data : [4329] [35]\n",
      "2596/16406, train loss is 10.545, state is -0.005487286485731602, time/batch=-4.794\n",
      "Extract of training data : [16] [280]\n",
      "2597/16406, train loss is 10.545, state is 0.005231561604887247, time/batch=-4.869\n",
      "Extract of training data : [12504] [7071]\n",
      "2598/16406, train loss is 10.546, state is -0.008014721795916557, time/batch=-4.838\n",
      "Extract of training data : [2305] [912]\n",
      "2599/16406, train loss is 10.546, state is -0.019076772034168243, time/batch=-4.794\n",
      "Extract of training data : [1161] [1191]\n",
      "2600/16406, train loss is 10.546, state is -0.014394979923963547, time/batch=-4.782\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [12504] [7284]\n",
      "2601/16406, train loss is 10.546, state is -0.007472638506442308, time/batch=-5.414\n",
      "Extract of training data : [8454] [16]\n",
      "2602/16406, train loss is 10.546, state is 0.005311307497322559, time/batch=-4.874\n",
      "Extract of training data : [35] [3055]\n",
      "2603/16406, train loss is 10.546, state is 0.0038134553469717503, time/batch=-4.842\n",
      "Extract of training data : [10] [26159]\n",
      "2604/16406, train loss is 10.546, state is 0.000166494442964904, time/batch=-4.799\n",
      "Extract of training data : [699] [16]\n",
      "2605/16406, train loss is 10.546, state is 0.0149306645616889, time/batch=-4.840\n",
      "Extract of training data : [24499] [12504]\n",
      "2606/16406, train loss is 10.545, state is 0.001731770345941186, time/batch=-4.824\n",
      "Extract of training data : [275] [20945]\n",
      "2607/16406, train loss is 10.546, state is -4.134304617764428e-05, time/batch=-4.846\n",
      "Extract of training data : [10] [12]\n",
      "2608/16406, train loss is 10.546, state is -0.0023517291992902756, time/batch=-4.867\n",
      "Extract of training data : [3326] [722]\n",
      "2609/16406, train loss is 10.546, state is 0.01117544062435627, time/batch=-4.849\n",
      "Extract of training data : [26887] [105]\n",
      "2610/16406, train loss is 10.546, state is -0.0019134118920192122, time/batch=-4.814\n",
      "Extract of training data : [10188] [35]\n",
      "2611/16406, train loss is 10.546, state is -0.012018375098705292, time/batch=-4.869\n",
      "Extract of training data : [4309] [10]\n",
      "2612/16406, train loss is 10.545, state is 0.003793892217800021, time/batch=-4.832\n",
      "Extract of training data : [71] [2311]\n",
      "2613/16406, train loss is 10.546, state is -0.0066881622187793255, time/batch=-4.845\n",
      "Extract of training data : [0] [0]\n",
      "2614/16406, train loss is 10.546, state is 0.00737787876278162, time/batch=-4.789\n",
      "Extract of training data : [8] [277]\n",
      "2615/16406, train loss is 10.545, state is -0.007525317370891571, time/batch=-4.836\n",
      "Extract of training data : [3] [3]\n",
      "2616/16406, train loss is 10.546, state is -0.004163037054240704, time/batch=-4.814\n",
      "Extract of training data : [10] [667]\n",
      "2617/16406, train loss is 10.546, state is -0.0004307098570279777, time/batch=-4.842\n",
      "Extract of training data : [2267] [35]\n",
      "2618/16406, train loss is 10.546, state is -0.019359929487109184, time/batch=-4.800\n",
      "Extract of training data : [27448] [13378]\n",
      "2619/16406, train loss is 10.545, state is -0.01607534848153591, time/batch=-4.795\n",
      "Extract of training data : [10] [328]\n",
      "2620/16406, train loss is 10.545, state is 0.005173909943550825, time/batch=-4.839\n",
      "Extract of training data : [2968] [10]\n",
      "2621/16406, train loss is 10.546, state is 0.004827294964343309, time/batch=-4.811\n",
      "Extract of training data : [326] [27664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/16406, train loss is 10.545, state is 0.016310956329107285, time/batch=-4.933\n",
      "Extract of training data : [16] [0]\n",
      "2623/16406, train loss is 10.545, state is -0.0018848635954782367, time/batch=-4.825\n",
      "Extract of training data : [10] [2438]\n",
      "2624/16406, train loss is 10.545, state is -0.007952779531478882, time/batch=-4.881\n",
      "Extract of training data : [3] [3]\n",
      "2625/16406, train loss is 10.545, state is -0.015621363185346127, time/batch=-4.800\n",
      "Extract of training data : [582] [4227]\n",
      "2626/16406, train loss is 10.546, state is -0.001594059867784381, time/batch=-4.897\n",
      "Extract of training data : [0] [3]\n",
      "2627/16406, train loss is 10.546, state is -0.019953208044171333, time/batch=-4.860\n",
      "Extract of training data : [1557] [422]\n",
      "2628/16406, train loss is 10.546, state is 0.010520759038627148, time/batch=-4.789\n",
      "Extract of training data : [20102] [11553]\n",
      "2629/16406, train loss is 10.546, state is 0.004098463803529739, time/batch=-4.799\n",
      "Extract of training data : [105] [688]\n",
      "2630/16406, train loss is 10.546, state is 0.013560626655817032, time/batch=-4.829\n",
      "Extract of training data : [16577] [11276]\n",
      "2631/16406, train loss is 10.546, state is -0.01700727641582489, time/batch=-4.799\n",
      "Extract of training data : [2708] [16]\n",
      "2632/16406, train loss is 10.546, state is -0.0007077532354742289, time/batch=-4.818\n",
      "Extract of training data : [283] [12524]\n",
      "2633/16406, train loss is 10.546, state is -0.009727485477924347, time/batch=-4.772\n",
      "Extract of training data : [28432] [1161]\n",
      "2634/16406, train loss is 10.546, state is -0.021524447947740555, time/batch=-4.828\n",
      "Extract of training data : [318] [35]\n",
      "2635/16406, train loss is 10.545, state is 0.011764434166252613, time/batch=-4.798\n",
      "Extract of training data : [13897] [35]\n",
      "2636/16406, train loss is 10.546, state is 0.010472007095813751, time/batch=-4.795\n",
      "Extract of training data : [0] [0]\n",
      "2637/16406, train loss is 10.545, state is 0.015918273478746414, time/batch=-4.824\n",
      "Extract of training data : [1515] [10]\n",
      "2638/16406, train loss is 10.546, state is -0.0010760943405330181, time/batch=-4.786\n",
      "Extract of training data : [533] [259]\n",
      "2639/16406, train loss is 10.546, state is -0.016441667452454567, time/batch=-4.871\n",
      "Extract of training data : [3] [9745]\n",
      "2640/16406, train loss is 10.545, state is 0.016129856929183006, time/batch=-4.832\n",
      "Extract of training data : [6286] [292]\n",
      "2641/16406, train loss is 10.546, state is 0.009640540927648544, time/batch=-4.828\n",
      "Extract of training data : [877] [1601]\n",
      "2642/16406, train loss is 10.545, state is 0.004196035675704479, time/batch=-4.773\n",
      "Extract of training data : [3] [3980]\n",
      "2643/16406, train loss is 10.546, state is 0.009312927722930908, time/batch=-4.776\n",
      "Extract of training data : [10] [422]\n",
      "2644/16406, train loss is 10.546, state is 0.01456119492650032, time/batch=-4.816\n",
      "Extract of training data : [9144] [4211]\n",
      "2645/16406, train loss is 10.546, state is -0.0021880879066884518, time/batch=-4.849\n",
      "Extract of training data : [12699] [424]\n",
      "2646/16406, train loss is 10.546, state is 0.0032170559279620647, time/batch=-4.796\n",
      "Extract of training data : [458] [4016]\n",
      "2647/16406, train loss is 10.546, state is -0.0012131480034440756, time/batch=-4.791\n",
      "Extract of training data : [12482] [10]\n",
      "2648/16406, train loss is 10.545, state is 0.01762787625193596, time/batch=-4.821\n",
      "Extract of training data : [3] [3]\n",
      "2649/16406, train loss is 10.546, state is 0.011293253861367702, time/batch=-4.804\n",
      "Extract of training data : [548] [29227]\n",
      "2650/16406, train loss is 10.545, state is 0.010835612192749977, time/batch=-4.762\n",
      "Extract of training data : [4352] [10]\n",
      "2651/16406, train loss is 10.545, state is 0.017381452023983, time/batch=-4.796\n",
      "Extract of training data : [12986] [2127]\n",
      "2652/16406, train loss is 10.546, state is -0.011425563134253025, time/batch=-4.817\n",
      "Extract of training data : [3055] [15878]\n",
      "2653/16406, train loss is 10.546, state is 0.012200365774333477, time/batch=-4.812\n",
      "Extract of training data : [1188] [2398]\n",
      "2654/16406, train loss is 10.546, state is 0.002276109531521797, time/batch=-4.796\n",
      "Extract of training data : [4179] [10]\n",
      "2655/16406, train loss is 10.546, state is -0.002560961991548538, time/batch=-4.895\n",
      "Extract of training data : [1385] [5846]\n",
      "2656/16406, train loss is 10.546, state is 0.014936914667487144, time/batch=-4.792\n",
      "Extract of training data : [0] [3]\n",
      "2657/16406, train loss is 10.546, state is -0.0002931815979536623, time/batch=-4.812\n",
      "Extract of training data : [1299] [1419]\n",
      "2658/16406, train loss is 10.546, state is -0.009311527013778687, time/batch=-4.893\n",
      "Extract of training data : [3758] [796]\n",
      "2659/16406, train loss is 10.546, state is -0.0026801112107932568, time/batch=-4.793\n",
      "Extract of training data : [29609] [10]\n",
      "2660/16406, train loss is 10.545, state is -0.009210995398461819, time/batch=-4.809\n",
      "Extract of training data : [2574] [10]\n",
      "2661/16406, train loss is 10.546, state is -0.006955070421099663, time/batch=-4.778\n",
      "Extract of training data : [3] [3]\n",
      "2662/16406, train loss is 10.546, state is 0.005724200513213873, time/batch=-4.818\n",
      "Extract of training data : [1846] [1422]\n",
      "2663/16406, train loss is 10.545, state is 0.009319290518760681, time/batch=-4.813\n",
      "Extract of training data : [2271] [4130]\n",
      "2664/16406, train loss is 10.546, state is 0.007927779108285904, time/batch=-5.072\n",
      "Extract of training data : [10] [544]\n",
      "2665/16406, train loss is 10.546, state is 0.0008257427834905684, time/batch=-4.299\n",
      "Extract of training data : [21448] [29955]\n",
      "2666/16406, train loss is 10.546, state is 0.0016287657199427485, time/batch=-4.263\n",
      "Extract of training data : [10] [3611]\n",
      "2667/16406, train loss is 10.546, state is -0.005919860675930977, time/batch=-4.288\n",
      "Extract of training data : [3] [582]\n",
      "2668/16406, train loss is 10.545, state is -0.013897445052862167, time/batch=-4.232\n",
      "Extract of training data : [30161] [20610]\n",
      "2669/16406, train loss is 10.545, state is -0.004213299602270126, time/batch=-4.247\n",
      "Extract of training data : [2257] [10]\n",
      "2670/16406, train loss is 10.546, state is 0.006913222372531891, time/batch=-4.244\n",
      "Extract of training data : [15065] [4352]\n",
      "2671/16406, train loss is 10.546, state is 0.01822877861559391, time/batch=-4.478\n",
      "Extract of training data : [35] [16445]\n",
      "2672/16406, train loss is 10.546, state is -0.006559919565916061, time/batch=-4.468\n",
      "Extract of training data : [422] [532]\n",
      "2673/16406, train loss is 10.546, state is -0.009540028870105743, time/batch=-4.441\n",
      "Extract of training data : [843] [10]\n",
      "2674/16406, train loss is 10.546, state is 0.0030127963982522488, time/batch=-4.605\n",
      "Extract of training data : [10] [30502]\n",
      "2675/16406, train loss is 10.546, state is -0.0012603832874447107, time/batch=-4.374\n",
      "Extract of training data : [10] [4141]\n",
      "2676/16406, train loss is 10.545, state is 0.0028067126404494047, time/batch=-4.244\n",
      "Extract of training data : [413] [12916]\n",
      "2677/16406, train loss is 10.546, state is 0.01117593515664339, time/batch=-4.311\n",
      "Extract of training data : [30689] [399]\n",
      "2678/16406, train loss is 10.545, state is 0.0015973872505128384, time/batch=-4.210\n",
      "Extract of training data : [0] [3]\n",
      "2679/16406, train loss is 10.546, state is -0.009324410930275917, time/batch=-4.249\n",
      "Extract of training data : [29] [413]\n",
      "2680/16406, train loss is 10.546, state is -0.0005628576036542654, time/batch=-4.236\n",
      "Extract of training data : [10] [1185]\n",
      "2681/16406, train loss is 10.545, state is 0.0032490298617631197, time/batch=-4.330\n",
      "Extract of training data : [582] [472]\n",
      "2682/16406, train loss is 10.546, state is 0.005231259390711784, time/batch=-4.539\n",
      "Extract of training data : [0] [0]\n",
      "2683/16406, train loss is 10.546, state is -0.010216440074145794, time/batch=-4.524\n",
      "Extract of training data : [553] [3340]\n",
      "2684/16406, train loss is 10.545, state is -0.005402303766459227, time/batch=-4.493\n",
      "Extract of training data : [5196] [1220]\n",
      "2685/16406, train loss is 10.546, state is -0.005317017901688814, time/batch=-4.746\n",
      "Extract of training data : [46] [1295]\n",
      "2686/16406, train loss is 10.546, state is -0.015643958002328873, time/batch=-4.952\n",
      "Extract of training data : [3] [3]\n",
      "2687/16406, train loss is 10.546, state is -0.00766307907178998, time/batch=-4.796\n",
      "Extract of training data : [50] [1963]\n",
      "2688/16406, train loss is 10.546, state is -0.010566171258687973, time/batch=-4.805\n",
      "Extract of training data : [174] [12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2689/16406, train loss is 10.546, state is 0.013245606794953346, time/batch=-4.826\n",
      "Extract of training data : [3408] [111]\n",
      "2690/16406, train loss is 10.545, state is -0.02085809037089348, time/batch=-4.805\n",
      "Extract of training data : [0] [0]\n",
      "2691/16406, train loss is 10.545, state is 0.00457909656688571, time/batch=-4.810\n",
      "Extract of training data : [10] [293]\n",
      "2692/16406, train loss is 10.545, state is 0.008487098850309849, time/batch=-4.789\n",
      "Extract of training data : [2720] [1628]\n",
      "2693/16406, train loss is 10.546, state is -0.010879943147301674, time/batch=-4.835\n",
      "Extract of training data : [15444] [1575]\n",
      "2694/16406, train loss is 10.546, state is -0.0038534870836883783, time/batch=-4.875\n",
      "Extract of training data : [422] [9376]\n",
      "2695/16406, train loss is 10.546, state is -0.005086612422019243, time/batch=-4.812\n",
      "Extract of training data : [28979] [413]\n",
      "2696/16406, train loss is 10.546, state is -0.007115359418094158, time/batch=-4.936\n",
      "Extract of training data : [105] [938]\n",
      "2697/16406, train loss is 10.546, state is -0.011820483952760696, time/batch=-4.819\n",
      "Extract of training data : [18981] [31828]\n",
      "2698/16406, train loss is 10.546, state is -0.010185746476054192, time/batch=-4.841\n",
      "Extract of training data : [14014] [13306]\n",
      "2699/16406, train loss is 10.546, state is -0.007612329442054033, time/batch=-4.777\n",
      "Extract of training data : [16355] [31920]\n",
      "2700/16406, train loss is 10.546, state is -0.013075937516987324, time/batch=-4.769\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [957] [811]\n",
      "2701/16406, train loss is 10.545, state is 0.0026602253783494234, time/batch=-5.141\n",
      "Extract of training data : [3515] [3516]\n",
      "2702/16406, train loss is 10.546, state is 0.006806541234254837, time/batch=-4.885\n",
      "Extract of training data : [413] [21]\n",
      "2703/16406, train loss is 10.546, state is -0.00393250584602356, time/batch=-4.839\n",
      "Extract of training data : [1591] [28]\n",
      "2704/16406, train loss is 10.546, state is -0.01757194660604, time/batch=-4.793\n",
      "Extract of training data : [32107] [5180]\n",
      "2705/16406, train loss is 10.546, state is 0.00283954874612391, time/batch=-4.781\n",
      "Extract of training data : [12] [9745]\n",
      "2706/16406, train loss is 10.546, state is 0.003927003126591444, time/batch=-4.787\n",
      "Extract of training data : [144] [16]\n",
      "2707/16406, train loss is 10.545, state is -0.004197993315756321, time/batch=-4.786\n",
      "Extract of training data : [3] [3]\n",
      "2708/16406, train loss is 10.546, state is 0.018569784238934517, time/batch=-4.834\n",
      "Extract of training data : [0] [0]\n",
      "2709/16406, train loss is 10.546, state is -0.010683265514671803, time/batch=-4.806\n",
      "Extract of training data : [877] [280]\n",
      "2710/16406, train loss is 10.545, state is -0.0012969571398571134, time/batch=-4.808\n",
      "Extract of training data : [15481] [29328]\n",
      "2711/16406, train loss is 10.545, state is -0.0028908320236951113, time/batch=-4.785\n",
      "Extract of training data : [3] [3]\n",
      "2712/16406, train loss is 10.545, state is 0.0030078624840825796, time/batch=-4.823\n",
      "Extract of training data : [3] [3366]\n",
      "2713/16406, train loss is 10.545, state is -0.005888014566153288, time/batch=-4.824\n",
      "Extract of training data : [27445] [920]\n",
      "2714/16406, train loss is 10.546, state is -0.025706926360726357, time/batch=-4.822\n",
      "Extract of training data : [873] [2875]\n",
      "2715/16406, train loss is 10.545, state is -0.020222963765263557, time/batch=-4.840\n",
      "Extract of training data : [1597] [442]\n",
      "2716/16406, train loss is 10.546, state is 0.006545661482959986, time/batch=-4.792\n",
      "Extract of training data : [582] [1293]\n",
      "2717/16406, train loss is 10.546, state is -0.0067983572371304035, time/batch=-4.797\n",
      "Extract of training data : [877] [280]\n",
      "2718/16406, train loss is 10.545, state is -0.021270107477903366, time/batch=-4.798\n",
      "Extract of training data : [5590] [850]\n",
      "2719/16406, train loss is 10.546, state is 0.00971989519894123, time/batch=-4.819\n",
      "Extract of training data : [1014] [71]\n",
      "2720/16406, train loss is 10.546, state is -0.0015684987884014845, time/batch=-4.919\n",
      "Extract of training data : [10] [143]\n",
      "2721/16406, train loss is 10.545, state is -0.000382515718229115, time/batch=-4.810\n",
      "Extract of training data : [4088] [1321]\n",
      "2722/16406, train loss is 10.545, state is -0.010199276730418205, time/batch=-4.828\n",
      "Extract of training data : [8] [1599]\n",
      "2723/16406, train loss is 10.546, state is 0.009990926831960678, time/batch=-4.778\n",
      "Extract of training data : [1599] [873]\n",
      "2724/16406, train loss is 10.546, state is -0.015401647426187992, time/batch=-4.787\n",
      "Extract of training data : [10378] [912]\n",
      "2725/16406, train loss is 10.546, state is 0.000497751752845943, time/batch=-4.811\n",
      "Extract of training data : [105] [371]\n",
      "2726/16406, train loss is 10.546, state is -0.002592438366264105, time/batch=-4.833\n",
      "Extract of training data : [371] [10]\n",
      "2727/16406, train loss is 10.546, state is 0.008897969499230385, time/batch=-4.814\n",
      "Extract of training data : [35] [1553]\n",
      "2728/16406, train loss is 10.546, state is -0.007623222656548023, time/batch=-4.811\n",
      "Extract of training data : [3] [23546]\n",
      "2729/16406, train loss is 10.546, state is 0.007190164644271135, time/batch=-4.977\n",
      "Extract of training data : [1745] [2853]\n",
      "2730/16406, train loss is 10.546, state is 0.014002691954374313, time/batch=-4.849\n",
      "Extract of training data : [3] [3]\n",
      "2731/16406, train loss is 10.546, state is -0.00027996228891424835, time/batch=-4.818\n",
      "Extract of training data : [3137] [10]\n",
      "2732/16406, train loss is 10.546, state is 0.014455494470894337, time/batch=-4.847\n",
      "Extract of training data : [256] [1078]\n",
      "2733/16406, train loss is 10.546, state is -0.02083374187350273, time/batch=-4.812\n",
      "Extract of training data : [5551] [571]\n",
      "2734/16406, train loss is 10.546, state is -0.006059036590158939, time/batch=-4.803\n",
      "Extract of training data : [164] [117]\n",
      "2735/16406, train loss is 10.546, state is -0.0030256586614996195, time/batch=-4.847\n",
      "Extract of training data : [1002] [21402]\n",
      "2736/16406, train loss is 10.546, state is -0.010606453754007816, time/batch=-4.792\n",
      "Extract of training data : [1265] [1289]\n",
      "2737/16406, train loss is 10.546, state is 0.015215776860713959, time/batch=-4.869\n",
      "Extract of training data : [10] [413]\n",
      "2738/16406, train loss is 10.546, state is -0.008640749379992485, time/batch=-4.848\n",
      "Extract of training data : [33275] [10]\n",
      "2739/16406, train loss is 10.546, state is -0.004399675410240889, time/batch=-4.802\n",
      "Extract of training data : [1197] [10]\n",
      "2740/16406, train loss is 10.546, state is 0.005334016866981983, time/batch=-4.805\n",
      "Extract of training data : [1188] [13896]\n",
      "2741/16406, train loss is 10.545, state is -0.009180027060210705, time/batch=-4.775\n",
      "Extract of training data : [344] [16557]\n",
      "2742/16406, train loss is 10.545, state is 0.0019073649309575558, time/batch=-4.791\n",
      "Extract of training data : [1198] [105]\n",
      "2743/16406, train loss is 10.546, state is 0.005638912785798311, time/batch=-4.833\n",
      "Extract of training data : [561] [1108]\n",
      "2744/16406, train loss is 10.546, state is -0.0027822665870189667, time/batch=-4.801\n",
      "Extract of training data : [50] [3792]\n",
      "2745/16406, train loss is 10.545, state is 0.003921572584658861, time/batch=-4.806\n",
      "Extract of training data : [32] [77]\n",
      "2746/16406, train loss is 10.545, state is 0.0038438141345977783, time/batch=-4.841\n",
      "Extract of training data : [24371] [35]\n",
      "2747/16406, train loss is 10.546, state is 0.01416975911706686, time/batch=-4.802\n",
      "Extract of training data : [33733] [10]\n",
      "2748/16406, train loss is 10.546, state is -0.0015504722250625491, time/batch=-4.804\n",
      "Extract of training data : [3] [3]\n",
      "2749/16406, train loss is 10.546, state is -0.010473544709384441, time/batch=-4.820\n",
      "Extract of training data : [4299] [14537]\n",
      "2750/16406, train loss is 10.546, state is 0.0015422697179019451, time/batch=-4.790\n",
      "Extract of training data : [10] [146]\n",
      "2751/16406, train loss is 10.545, state is -0.008629048243165016, time/batch=-4.785\n",
      "Extract of training data : [2985] [3315]\n",
      "2752/16406, train loss is 10.545, state is -0.0008067575981840491, time/batch=-4.842\n",
      "Extract of training data : [3] [164]\n",
      "2753/16406, train loss is 10.545, state is -0.002943585626780987, time/batch=-4.799\n",
      "Extract of training data : [105] [16]\n",
      "2754/16406, train loss is 10.546, state is -0.004557873122394085, time/batch=-4.772\n",
      "Extract of training data : [3] [27283]\n",
      "2755/16406, train loss is 10.546, state is 0.024849388748407364, time/batch=-4.775\n",
      "Extract of training data : [15444] [26029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2756/16406, train loss is 10.545, state is -0.0026613608933985233, time/batch=-4.832\n",
      "Extract of training data : [10] [34177]\n",
      "2757/16406, train loss is 10.546, state is -0.00922116544097662, time/batch=-4.833\n",
      "Extract of training data : [2121] [51]\n",
      "2758/16406, train loss is 10.546, state is 0.010079729370772839, time/batch=-4.819\n",
      "Extract of training data : [71] [5846]\n",
      "2759/16406, train loss is 10.546, state is 0.004754167515784502, time/batch=-4.830\n",
      "Extract of training data : [13476] [35]\n",
      "2760/16406, train loss is 10.545, state is 0.01015760563313961, time/batch=-4.809\n",
      "Extract of training data : [951] [105]\n",
      "2761/16406, train loss is 10.546, state is -0.0184633769094944, time/batch=-4.784\n",
      "Extract of training data : [3] [3]\n",
      "2762/16406, train loss is 10.546, state is 0.013757647015154362, time/batch=-4.767\n",
      "Extract of training data : [66] [10]\n",
      "2763/16406, train loss is 10.546, state is -0.011439413763582706, time/batch=-4.896\n",
      "Extract of training data : [111] [1416]\n",
      "2764/16406, train loss is 10.546, state is -0.015913138166069984, time/batch=-4.786\n",
      "Extract of training data : [1874] [256]\n",
      "2765/16406, train loss is 10.546, state is -0.0015394941437989473, time/batch=-4.777\n",
      "Extract of training data : [943] [2559]\n",
      "2766/16406, train loss is 10.546, state is -0.011100604198873043, time/batch=-4.802\n",
      "Extract of training data : [10] [1108]\n",
      "2767/16406, train loss is 10.545, state is -0.01716703549027443, time/batch=-4.794\n",
      "Extract of training data : [3732] [289]\n",
      "2768/16406, train loss is 10.546, state is -0.012871486134827137, time/batch=-4.797\n",
      "Extract of training data : [5351] [4130]\n",
      "2769/16406, train loss is 10.545, state is -0.005014303606003523, time/batch=-4.806\n",
      "Extract of training data : [277] [873]\n",
      "2770/16406, train loss is 10.546, state is -0.022363021969795227, time/batch=-4.817\n",
      "Extract of training data : [5780] [31849]\n",
      "2771/16406, train loss is 10.547, state is 0.008167915977537632, time/batch=-4.900\n",
      "Extract of training data : [0] [0]\n",
      "2772/16406, train loss is 10.546, state is 0.005431664641946554, time/batch=-4.800\n",
      "Extract of training data : [6253] [10]\n",
      "2773/16406, train loss is 10.546, state is -0.0040220231749117374, time/batch=-4.789\n",
      "Extract of training data : [904] [34937]\n",
      "2774/16406, train loss is 10.547, state is 0.02975098043680191, time/batch=-4.797\n",
      "Extract of training data : [7281] [117]\n",
      "2775/16406, train loss is 10.546, state is 0.003570378292351961, time/batch=-4.807\n",
      "Extract of training data : [16] [280]\n",
      "2776/16406, train loss is 10.545, state is -0.00589317362755537, time/batch=-4.817\n",
      "Extract of training data : [35109] [2861]\n",
      "2777/16406, train loss is 10.545, state is 0.007175080943852663, time/batch=-4.990\n",
      "Extract of training data : [35] [24498]\n",
      "2778/16406, train loss is 10.545, state is 0.0019252789206802845, time/batch=-4.882\n",
      "Extract of training data : [2736] [920]\n",
      "2779/16406, train loss is 10.545, state is -0.014512055553495884, time/batch=-4.792\n",
      "Extract of training data : [2284] [675]\n",
      "2780/16406, train loss is 10.546, state is -0.005495884921401739, time/batch=-4.826\n",
      "Extract of training data : [22143] [16]\n",
      "2781/16406, train loss is 10.546, state is -0.004900468047708273, time/batch=-4.872\n",
      "Extract of training data : [532] [71]\n",
      "2782/16406, train loss is 10.546, state is -0.01156393252313137, time/batch=-4.795\n",
      "Extract of training data : [1] [1]\n",
      "2783/16406, train loss is 10.545, state is -0.013242245651781559, time/batch=-4.835\n",
      "Extract of training data : [2135] [10245]\n",
      "2784/16406, train loss is 10.546, state is -0.023016436025500298, time/batch=-4.876\n",
      "Extract of training data : [699] [436]\n",
      "2785/16406, train loss is 10.545, state is 0.008641145192086697, time/batch=-4.929\n",
      "Extract of training data : [1137] [35]\n",
      "2786/16406, train loss is 10.545, state is 0.012898963876068592, time/batch=-4.795\n",
      "Extract of training data : [35660] [912]\n",
      "2787/16406, train loss is 10.546, state is -0.0013367810752242804, time/batch=-4.783\n",
      "Extract of training data : [15010] [3268]\n",
      "2788/16406, train loss is 10.546, state is 0.005176798440515995, time/batch=-4.784\n",
      "Extract of training data : [6962] [164]\n",
      "2789/16406, train loss is 10.546, state is -0.0018254215829074383, time/batch=-4.792\n",
      "Extract of training data : [3] [3]\n",
      "2790/16406, train loss is 10.545, state is 0.014761723577976227, time/batch=-4.779\n",
      "Extract of training data : [666] [10]\n",
      "2791/16406, train loss is 10.545, state is -0.01845943182706833, time/batch=-4.789\n",
      "Extract of training data : [10] [1785]\n",
      "2792/16406, train loss is 10.546, state is -0.01330582145601511, time/batch=-4.785\n",
      "Extract of training data : [177] [105]\n",
      "2793/16406, train loss is 10.545, state is -0.0024599856697022915, time/batch=-4.811\n",
      "Extract of training data : [581] [105]\n",
      "2794/16406, train loss is 10.545, state is -0.015078271739184856, time/batch=-4.806\n",
      "Extract of training data : [10] [6891]\n",
      "2795/16406, train loss is 10.545, state is -0.011005662381649017, time/batch=-4.842\n",
      "Extract of training data : [36002] [10]\n",
      "2796/16406, train loss is 10.545, state is -0.010503210127353668, time/batch=-4.752\n",
      "Extract of training data : [10] [1626]\n",
      "2797/16406, train loss is 10.546, state is -0.010159413330256939, time/batch=-4.760\n",
      "Extract of training data : [811] [10839]\n",
      "2798/16406, train loss is 10.546, state is -0.012443658895790577, time/batch=-4.805\n",
      "Extract of training data : [16018] [10]\n",
      "2799/16406, train loss is 10.545, state is -0.001183388289064169, time/batch=-4.791\n",
      "Extract of training data : [6027] [35]\n",
      "2800/16406, train loss is 10.545, state is 0.014371911995112896, time/batch=-4.823\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [1872] [45]\n",
      "2801/16406, train loss is 10.546, state is -0.005471858195960522, time/batch=-5.083\n",
      "Extract of training data : [3758] [423]\n",
      "2802/16406, train loss is 10.545, state is -0.0138357849791646, time/batch=-4.789\n",
      "Extract of training data : [3] [3]\n",
      "2803/16406, train loss is 10.546, state is -0.005413620732724667, time/batch=-4.845\n",
      "Extract of training data : [35] [2802]\n",
      "2804/16406, train loss is 10.545, state is -0.0035282764583826065, time/batch=-4.793\n",
      "Extract of training data : [811] [10]\n",
      "2805/16406, train loss is 10.545, state is -0.00022296389215625823, time/batch=-4.853\n",
      "Extract of training data : [3] [3]\n",
      "2806/16406, train loss is 10.546, state is 0.004397292155772448, time/batch=-4.780\n",
      "Extract of training data : [0] [0]\n",
      "2807/16406, train loss is 10.545, state is -0.023751823231577873, time/batch=-4.816\n",
      "Extract of training data : [8130] [10]\n",
      "2808/16406, train loss is 10.545, state is 0.005756548140197992, time/batch=-4.780\n",
      "Extract of training data : [5556] [10]\n",
      "2809/16406, train loss is 10.545, state is 0.012270977720618248, time/batch=-4.763\n",
      "Extract of training data : [10378] [35]\n",
      "2810/16406, train loss is 10.545, state is -0.0012049599317833781, time/batch=-4.836\n",
      "Extract of training data : [14454] [595]\n",
      "2811/16406, train loss is 10.545, state is 0.00202298816293478, time/batch=-4.841\n",
      "Extract of training data : [6962] [35]\n",
      "2812/16406, train loss is 10.546, state is 0.01848519779741764, time/batch=-4.791\n",
      "Extract of training data : [2492] [105]\n",
      "2813/16406, train loss is 10.545, state is 7.907242252258584e-05, time/batch=-4.781\n",
      "Extract of training data : [35] [2039]\n",
      "2814/16406, train loss is 10.546, state is -0.009504263289272785, time/batch=-4.839\n",
      "Extract of training data : [1348] [6566]\n",
      "2815/16406, train loss is 10.545, state is 0.005942056886851788, time/batch=-4.862\n",
      "Extract of training data : [5499] [10]\n",
      "2816/16406, train loss is 10.545, state is -0.0019497134489938617, time/batch=-4.976\n",
      "Extract of training data : [1078] [280]\n",
      "2817/16406, train loss is 10.546, state is 0.010319959372282028, time/batch=-4.800\n",
      "Extract of training data : [901] [559]\n",
      "2818/16406, train loss is 10.546, state is 0.010255761444568634, time/batch=-4.791\n",
      "Extract of training data : [0] [1]\n",
      "2819/16406, train loss is 10.547, state is 0.00017631259106565267, time/batch=-4.825\n",
      "Extract of training data : [3] [3]\n",
      "2820/16406, train loss is 10.547, state is -0.0024916338734328747, time/batch=-4.923\n",
      "Extract of training data : [280] [3763]\n",
      "2821/16406, train loss is 10.546, state is 0.0045667411759495735, time/batch=-4.837\n",
      "Extract of training data : [105] [10]\n",
      "2822/16406, train loss is 10.546, state is 0.009655112400650978, time/batch=-4.801\n",
      "Extract of training data : [4213] [29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823/16406, train loss is 10.546, state is -0.006229587830603123, time/batch=-4.848\n",
      "Extract of training data : [10] [777]\n",
      "2824/16406, train loss is 10.545, state is -0.01784955896437168, time/batch=-4.761\n",
      "Extract of training data : [556] [10]\n",
      "2825/16406, train loss is 10.545, state is 0.007444330956786871, time/batch=-4.781\n",
      "Extract of training data : [0] [0]\n",
      "2826/16406, train loss is 10.546, state is -0.005221391562372446, time/batch=-4.821\n",
      "Extract of training data : [105] [1742]\n",
      "2827/16406, train loss is 10.545, state is 0.008281507529318333, time/batch=-4.799\n",
      "Extract of training data : [3149] [5259]\n",
      "2828/16406, train loss is 10.546, state is -0.004712603986263275, time/batch=-4.813\n",
      "Extract of training data : [3] [3408]\n",
      "2829/16406, train loss is 10.546, state is 0.007659093476831913, time/batch=-4.792\n",
      "Extract of training data : [3674] [16]\n",
      "2830/16406, train loss is 10.546, state is -0.004739841911941767, time/batch=-4.867\n",
      "Extract of training data : [4581] [105]\n",
      "2831/16406, train loss is 10.545, state is -0.011647190898656845, time/batch=-4.809\n",
      "Extract of training data : [344] [4086]\n",
      "2832/16406, train loss is 10.545, state is 0.012213155627250671, time/batch=-4.804\n",
      "Extract of training data : [9275] [1601]\n",
      "2833/16406, train loss is 10.546, state is 0.018289882689714432, time/batch=-4.836\n",
      "Extract of training data : [16] [280]\n",
      "2834/16406, train loss is 10.545, state is -0.00011610302317421883, time/batch=-4.800\n",
      "Extract of training data : [4422] [7432]\n",
      "2835/16406, train loss is 10.546, state is 0.006786859594285488, time/batch=-4.802\n",
      "Extract of training data : [0] [3]\n",
      "2836/16406, train loss is 10.546, state is -0.015427044592797756, time/batch=-4.853\n",
      "Extract of training data : [6585] [2825]\n",
      "2837/16406, train loss is 10.546, state is -0.010686850175261497, time/batch=-4.847\n",
      "Extract of training data : [105] [10066]\n",
      "2838/16406, train loss is 10.545, state is 0.006002063397318125, time/batch=-4.792\n",
      "Extract of training data : [16] [912]\n",
      "2839/16406, train loss is 10.546, state is -0.005960332229733467, time/batch=-4.843\n",
      "Extract of training data : [647] [1826]\n",
      "2840/16406, train loss is 10.545, state is -0.0061074779368937016, time/batch=-4.809\n",
      "Extract of training data : [0] [1]\n",
      "2841/16406, train loss is 10.545, state is 0.02005310356616974, time/batch=-4.762\n",
      "Extract of training data : [4842] [10]\n",
      "2842/16406, train loss is 10.546, state is -0.0057656848803162575, time/batch=-4.799\n",
      "Extract of training data : [105] [980]\n",
      "2843/16406, train loss is 10.546, state is -0.021705348044633865, time/batch=-4.844\n",
      "Extract of training data : [10739] [12]\n",
      "2844/16406, train loss is 10.546, state is 0.015273623168468475, time/batch=-4.816\n",
      "Extract of training data : [0] [0]\n",
      "2845/16406, train loss is 10.545, state is 0.008279846049845219, time/batch=-4.815\n",
      "Extract of training data : [458] [174]\n",
      "2846/16406, train loss is 10.545, state is 0.004146073013544083, time/batch=-4.863\n",
      "Extract of training data : [4450] [105]\n",
      "2847/16406, train loss is 10.546, state is -0.004925969988107681, time/batch=-4.828\n",
      "Extract of training data : [117] [16]\n",
      "2848/16406, train loss is 10.546, state is -0.010875588282942772, time/batch=-4.815\n",
      "Extract of training data : [0] [3]\n",
      "2849/16406, train loss is 10.546, state is -0.003876669332385063, time/batch=-4.837\n",
      "Extract of training data : [105] [10]\n",
      "2850/16406, train loss is 10.546, state is -0.014710734598338604, time/batch=-4.800\n",
      "Extract of training data : [2377] [10]\n",
      "2851/16406, train loss is 10.546, state is -0.004424432758241892, time/batch=-4.854\n",
      "Extract of training data : [8] [277]\n",
      "2852/16406, train loss is 10.546, state is -0.008097855374217033, time/batch=-4.805\n",
      "Extract of training data : [10] [3732]\n",
      "2853/16406, train loss is 10.545, state is -0.004720955155789852, time/batch=-4.780\n",
      "Extract of training data : [4167] [245]\n",
      "2854/16406, train loss is 10.545, state is -0.002551381243392825, time/batch=-4.808\n",
      "Extract of training data : [943] [10]\n",
      "2855/16406, train loss is 10.546, state is -0.0023319607134908438, time/batch=-4.781\n",
      "Extract of training data : [35] [10]\n",
      "2856/16406, train loss is 10.546, state is -0.011800598353147507, time/batch=-4.785\n",
      "Extract of training data : [820] [12377]\n",
      "2857/16406, train loss is 10.546, state is 0.0072078825905919075, time/batch=-4.777\n",
      "Extract of training data : [12511] [10]\n",
      "2858/16406, train loss is 10.546, state is 0.011498693376779556, time/batch=-4.801\n",
      "Extract of training data : [12] [6027]\n",
      "2859/16406, train loss is 10.546, state is 0.003954026382416487, time/batch=-4.855\n",
      "Extract of training data : [259] [10]\n",
      "2860/16406, train loss is 10.546, state is -0.021868130192160606, time/batch=-4.749\n",
      "Extract of training data : [12970] [1119]\n",
      "2861/16406, train loss is 10.545, state is -0.022119224071502686, time/batch=-4.866\n",
      "Extract of training data : [524] [844]\n",
      "2862/16406, train loss is 10.546, state is 0.014258584007620811, time/batch=-4.820\n",
      "Extract of training data : [2147] [12]\n",
      "2863/16406, train loss is 10.546, state is 0.0026257229037582874, time/batch=-4.825\n",
      "Extract of training data : [1171] [11230]\n",
      "2864/16406, train loss is 10.546, state is -0.025815660133957863, time/batch=-4.881\n",
      "Extract of training data : [13473] [10]\n",
      "2865/16406, train loss is 10.546, state is -0.004789472557604313, time/batch=-4.834\n",
      "Extract of training data : [13794] [2045]\n",
      "2866/16406, train loss is 10.545, state is 0.005394291132688522, time/batch=-4.816\n",
      "Extract of training data : [29] [12581]\n",
      "2867/16406, train loss is 10.545, state is -0.004666214808821678, time/batch=-4.851\n",
      "Extract of training data : [13483] [10]\n",
      "2868/16406, train loss is 10.545, state is 0.015615278854966164, time/batch=-4.801\n",
      "Extract of training data : [359] [2039]\n",
      "2869/16406, train loss is 10.545, state is -0.03019680455327034, time/batch=-4.764\n",
      "Extract of training data : [2050] [13961]\n",
      "2870/16406, train loss is 10.545, state is -0.0010377226863056421, time/batch=-4.813\n",
      "Extract of training data : [10] [2886]\n",
      "2871/16406, train loss is 10.545, state is -0.005374572705477476, time/batch=-4.869\n",
      "Extract of training data : [277] [3379]\n",
      "2872/16406, train loss is 10.546, state is 0.00022906294907443225, time/batch=-4.811\n",
      "Extract of training data : [10] [14567]\n",
      "2873/16406, train loss is 10.545, state is -0.009940250776708126, time/batch=-4.831\n",
      "Extract of training data : [13293] [3285]\n",
      "2874/16406, train loss is 10.545, state is -0.017111342400312424, time/batch=-4.826\n",
      "Extract of training data : [877] [280]\n",
      "2875/16406, train loss is 10.545, state is -0.01553407870233059, time/batch=-4.794\n",
      "Extract of training data : [413] [71]\n",
      "2876/16406, train loss is 10.545, state is -0.0021627526730298996, time/batch=-4.812\n",
      "Extract of training data : [10] [1637]\n",
      "2877/16406, train loss is 10.545, state is -0.012802801094949245, time/batch=-4.775\n",
      "Extract of training data : [151] [10]\n",
      "2878/16406, train loss is 10.545, state is -0.01723419316112995, time/batch=-4.812\n",
      "Extract of training data : [906] [13737]\n",
      "2879/16406, train loss is 10.546, state is -0.0033263368532061577, time/batch=-4.781\n",
      "Extract of training data : [10] [15284]\n",
      "2880/16406, train loss is 10.545, state is 0.007555937394499779, time/batch=-4.821\n",
      "Extract of training data : [15218] [514]\n",
      "2881/16406, train loss is 10.545, state is -0.0059199766255915165, time/batch=-4.836\n",
      "Extract of training data : [465] [146]\n",
      "2882/16406, train loss is 10.545, state is -0.008267443627119064, time/batch=-4.865\n",
      "Extract of training data : [3] [910]\n",
      "2883/16406, train loss is 10.546, state is -0.0029610188212245703, time/batch=-4.795\n",
      "Extract of training data : [0] [3]\n",
      "2884/16406, train loss is 10.546, state is -0.007661733310669661, time/batch=-4.811\n",
      "Extract of training data : [55] [15900]\n",
      "2885/16406, train loss is 10.546, state is -0.0023732439149171114, time/batch=-4.846\n",
      "Extract of training data : [16019] [10]\n",
      "2886/16406, train loss is 10.545, state is 0.006784879602491856, time/batch=-4.792\n",
      "Extract of training data : [495] [50]\n",
      "2887/16406, train loss is 10.546, state is 0.007669499143958092, time/batch=-4.797\n",
      "Extract of training data : [3] [582]\n",
      "2888/16406, train loss is 10.546, state is -0.010248948819935322, time/batch=-4.829\n",
      "Extract of training data : [283] [2275]\n",
      "2889/16406, train loss is 10.545, state is -0.0014605573378503323, time/batch=-4.868\n",
      "Extract of training data : [924] [3196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2890/16406, train loss is 10.546, state is 0.009198940359055996, time/batch=-4.837\n",
      "Extract of training data : [10] [6213]\n",
      "2891/16406, train loss is 10.546, state is 0.01293516717851162, time/batch=-4.786\n",
      "Extract of training data : [10] [1038]\n",
      "2892/16406, train loss is 10.546, state is 0.007036148104816675, time/batch=-4.812\n",
      "Extract of training data : [3611] [71]\n",
      "2893/16406, train loss is 10.546, state is -0.00029944017296656966, time/batch=-4.878\n",
      "Extract of training data : [16] [846]\n",
      "2894/16406, train loss is 10.545, state is -0.008735204115509987, time/batch=-4.830\n",
      "Extract of training data : [3142] [5653]\n",
      "2895/16406, train loss is 10.546, state is -0.0019321935251355171, time/batch=-4.822\n",
      "Extract of training data : [35] [5065]\n",
      "2896/16406, train loss is 10.546, state is -0.012478743679821491, time/batch=-4.859\n",
      "Extract of training data : [5710] [2135]\n",
      "2897/16406, train loss is 10.545, state is -0.005380965303629637, time/batch=-4.794\n",
      "Extract of training data : [9458] [280]\n",
      "2898/16406, train loss is 10.545, state is 0.002951785223558545, time/batch=-4.796\n",
      "Extract of training data : [13587] [10231]\n",
      "2899/16406, train loss is 10.546, state is 0.006250837817788124, time/batch=-4.827\n",
      "Extract of training data : [0] [0]\n",
      "2900/16406, train loss is 10.545, state is 0.016783256083726883, time/batch=-4.801\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [877] [0]\n",
      "2901/16406, train loss is 10.546, state is 0.0004352547985035926, time/batch=-5.477\n",
      "Extract of training data : [3] [3]\n",
      "2902/16406, train loss is 10.545, state is -0.010322642512619495, time/batch=-4.879\n",
      "Extract of training data : [2437] [559]\n",
      "2903/16406, train loss is 10.546, state is 0.021621419116854668, time/batch=-4.787\n",
      "Extract of training data : [3] [3]\n",
      "2904/16406, train loss is 10.546, state is 0.016797631978988647, time/batch=-4.795\n",
      "Extract of training data : [16] [0]\n",
      "2905/16406, train loss is 10.545, state is -0.0052885799668729305, time/batch=-4.822\n",
      "Extract of training data : [17913] [164]\n",
      "2906/16406, train loss is 10.546, state is -0.006477902643382549, time/batch=-4.870\n",
      "Extract of training data : [371] [10]\n",
      "2907/16406, train loss is 10.545, state is -0.0021820191759616137, time/batch=-4.830\n",
      "Extract of training data : [344] [901]\n",
      "2908/16406, train loss is 10.545, state is 0.0031353498343378305, time/batch=-4.817\n",
      "Extract of training data : [10] [23]\n",
      "2909/16406, train loss is 10.545, state is -0.0026490408927202225, time/batch=-4.823\n",
      "Extract of training data : [8] [277]\n",
      "2910/16406, train loss is 10.545, state is 0.01804332062602043, time/batch=-4.770\n",
      "Extract of training data : [3] [3]\n",
      "2911/16406, train loss is 10.546, state is 0.012190230190753937, time/batch=-4.773\n",
      "Extract of training data : [442] [6530]\n",
      "2912/16406, train loss is 10.545, state is 0.01512851007282734, time/batch=-4.810\n",
      "Extract of training data : [3] [3]\n",
      "2913/16406, train loss is 10.545, state is -0.006553475745022297, time/batch=-4.822\n",
      "Extract of training data : [10] [121]\n",
      "2914/16406, train loss is 10.546, state is 0.0061034406535327435, time/batch=-4.811\n",
      "Extract of training data : [2854] [10]\n",
      "2915/16406, train loss is 10.545, state is -5.580902143265121e-05, time/batch=-4.791\n",
      "Extract of training data : [0] [3]\n",
      "2916/16406, train loss is 10.546, state is 0.007092057261615992, time/batch=-4.783\n",
      "Extract of training data : [108] [17042]\n",
      "2917/16406, train loss is 10.546, state is 0.012855039909482002, time/batch=-4.800\n",
      "Extract of training data : [16049] [811]\n",
      "2918/16406, train loss is 10.545, state is -0.016670124605298042, time/batch=-4.829\n",
      "Extract of training data : [21674] [2742]\n",
      "2919/16406, train loss is 10.545, state is -0.008386939764022827, time/batch=-4.821\n",
      "Extract of training data : [2137] [10]\n",
      "2920/16406, train loss is 10.545, state is 0.022410985082387924, time/batch=-4.795\n",
      "Extract of training data : [10] [1133]\n",
      "2921/16406, train loss is 10.546, state is 0.000734193017706275, time/batch=-4.784\n",
      "Extract of training data : [10] [4950]\n",
      "2922/16406, train loss is 10.546, state is 0.010040005668997765, time/batch=-4.809\n",
      "Extract of training data : [910] [1006]\n",
      "2923/16406, train loss is 10.546, state is 0.011128460057079792, time/batch=-4.820\n",
      "Extract of training data : [920] [28]\n",
      "2924/16406, train loss is 10.546, state is -0.0030113288667052984, time/batch=-4.798\n",
      "Extract of training data : [0] [0]\n",
      "2925/16406, train loss is 10.545, state is 0.0019348332425579429, time/batch=-4.812\n",
      "Extract of training data : [10] [2639]\n",
      "2926/16406, train loss is 10.546, state is -0.00032805048977024853, time/batch=-4.777\n",
      "Extract of training data : [1575] [50]\n",
      "2927/16406, train loss is 10.546, state is -0.011942173354327679, time/batch=-4.802\n",
      "Extract of training data : [3] [873]\n",
      "2928/16406, train loss is 10.546, state is 0.0013847565278410912, time/batch=-4.776\n",
      "Extract of training data : [16] [894]\n",
      "2929/16406, train loss is 10.545, state is 0.0010058608604595065, time/batch=-4.828\n",
      "Extract of training data : [2398] [3515]\n",
      "2930/16406, train loss is 10.546, state is -0.006398740224540234, time/batch=-4.836\n",
      "Extract of training data : [623] [8391]\n",
      "2931/16406, train loss is 10.546, state is 0.0025621766690164804, time/batch=-4.815\n",
      "Extract of training data : [1131] [13365]\n",
      "2932/16406, train loss is 10.545, state is 0.00017216427659150213, time/batch=-4.857\n",
      "Extract of training data : [174] [3383]\n",
      "2933/16406, train loss is 10.545, state is 0.003580772550776601, time/batch=-4.766\n",
      "Extract of training data : [548] [2132]\n",
      "2934/16406, train loss is 10.546, state is -0.014694707468152046, time/batch=-4.830\n",
      "Extract of training data : [6891] [16]\n",
      "2935/16406, train loss is 10.545, state is -0.010125108063220978, time/batch=-4.802\n",
      "Extract of training data : [3749] [471]\n",
      "2936/16406, train loss is 10.545, state is -0.00381552055478096, time/batch=-4.810\n",
      "Extract of training data : [35] [3211]\n",
      "2937/16406, train loss is 10.546, state is 0.006127453409135342, time/batch=-4.819\n",
      "Extract of training data : [10] [413]\n",
      "2938/16406, train loss is 10.546, state is -0.012405200861394405, time/batch=-4.855\n",
      "Extract of training data : [16] [0]\n",
      "2939/16406, train loss is 10.546, state is -0.01591157168149948, time/batch=-4.798\n",
      "Extract of training data : [3732] [10]\n",
      "2940/16406, train loss is 10.545, state is 0.003962880931794643, time/batch=-4.815\n",
      "Extract of training data : [1507] [10]\n",
      "2941/16406, train loss is 10.546, state is -0.010031739249825478, time/batch=-4.801\n",
      "Extract of training data : [7183] [2051]\n",
      "2942/16406, train loss is 10.546, state is 0.0006287692813202739, time/batch=-4.886\n",
      "Extract of training data : [174] [105]\n",
      "2943/16406, train loss is 10.546, state is -0.014361893758177757, time/batch=-4.791\n",
      "Extract of training data : [10] [1741]\n",
      "2944/16406, train loss is 10.546, state is 0.0006636774051003158, time/batch=-4.790\n",
      "Extract of training data : [20707] [10]\n",
      "2945/16406, train loss is 10.546, state is 0.0024201509077101946, time/batch=-4.769\n",
      "Extract of training data : [164] [2159]\n",
      "2946/16406, train loss is 10.545, state is 0.008516193367540836, time/batch=-4.825\n",
      "Extract of training data : [524] [624]\n",
      "2947/16406, train loss is 10.546, state is -0.007929257117211819, time/batch=-4.791\n",
      "Extract of training data : [0] [3]\n",
      "2948/16406, train loss is 10.545, state is -0.001982783665880561, time/batch=-4.801\n",
      "Extract of training data : [10] [557]\n",
      "2949/16406, train loss is 10.546, state is -0.010041149333119392, time/batch=-4.791\n",
      "Extract of training data : [35] [2039]\n",
      "2950/16406, train loss is 10.546, state is 0.00481748953461647, time/batch=-4.805\n",
      "Extract of training data : [7] [8]\n",
      "2951/16406, train loss is 10.546, state is 0.001594429835677147, time/batch=-4.779\n",
      "Extract of training data : [10] [1825]\n",
      "2952/16406, train loss is 10.546, state is -0.000919711368624121, time/batch=-4.788\n",
      "Extract of training data : [3024] [35]\n",
      "2953/16406, train loss is 10.546, state is -0.003527172841131687, time/batch=-4.848\n",
      "Extract of training data : [583] [71]\n",
      "2954/16406, train loss is 10.545, state is -0.001999092288315296, time/batch=-4.816\n",
      "Extract of training data : [1481] [804]\n",
      "2955/16406, train loss is 10.546, state is 0.025248514488339424, time/batch=-4.828\n",
      "Extract of training data : [3] [29]\n",
      "2956/16406, train loss is 10.546, state is 0.015088318847119808, time/batch=-4.826\n",
      "Extract of training data : [13960] [10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2957/16406, train loss is 10.546, state is 0.012541168369352818, time/batch=-4.803\n",
      "Extract of training data : [19037] [5004]\n",
      "2958/16406, train loss is 10.546, state is 0.009567022323608398, time/batch=-4.778\n",
      "Extract of training data : [545] [86]\n",
      "2959/16406, train loss is 10.546, state is -0.01805434748530388, time/batch=-4.777\n",
      "Extract of training data : [10] [5157]\n",
      "2960/16406, train loss is 10.545, state is -0.011524133384227753, time/batch=-4.779\n",
      "Extract of training data : [458] [2304]\n",
      "2961/16406, train loss is 10.545, state is -0.01187680009752512, time/batch=-4.832\n",
      "Extract of training data : [20] [3230]\n",
      "2962/16406, train loss is 10.545, state is -0.0028956588357686996, time/batch=-4.807\n",
      "Extract of training data : [3] [3]\n",
      "2963/16406, train loss is 10.546, state is 0.0012996059376746416, time/batch=-4.797\n",
      "Extract of training data : [6429] [35]\n",
      "2964/16406, train loss is 10.546, state is -0.0053183538839221, time/batch=-4.797\n",
      "Extract of training data : [912] [1569]\n",
      "2965/16406, train loss is 10.546, state is -0.016993805766105652, time/batch=-4.785\n",
      "Extract of training data : [33] [23035]\n",
      "2966/16406, train loss is 10.546, state is 0.0030589685775339603, time/batch=-4.813\n",
      "Extract of training data : [1188] [29]\n",
      "2967/16406, train loss is 10.546, state is -0.008455293253064156, time/batch=-4.791\n",
      "Extract of training data : [3208] [1185]\n",
      "2968/16406, train loss is 10.546, state is 0.0023021860979497433, time/batch=-4.780\n",
      "Extract of training data : [2050] [2679]\n",
      "2969/16406, train loss is 10.546, state is 0.013446938246488571, time/batch=-4.821\n",
      "Extract of training data : [0] [0]\n",
      "2970/16406, train loss is 10.546, state is 0.00554271973669529, time/batch=-4.767\n",
      "Extract of training data : [6838] [2225]\n",
      "2971/16406, train loss is 10.546, state is -0.009820827282965183, time/batch=-4.770\n",
      "Extract of training data : [3] [1085]\n",
      "2972/16406, train loss is 10.546, state is -0.005599189084023237, time/batch=-4.803\n",
      "Extract of training data : [3] [3]\n",
      "2973/16406, train loss is 10.545, state is -0.006237817462533712, time/batch=-4.814\n",
      "Extract of training data : [77] [105]\n",
      "2974/16406, train loss is 10.546, state is 0.00939340889453888, time/batch=-4.858\n",
      "Extract of training data : [16] [846]\n",
      "2975/16406, train loss is 10.546, state is 0.0027023879811167717, time/batch=-4.907\n",
      "Extract of training data : [6077] [10]\n",
      "2976/16406, train loss is 10.546, state is 0.010784102603793144, time/batch=-4.768\n",
      "Extract of training data : [9927] [2492]\n",
      "2977/16406, train loss is 10.545, state is -0.004596737679094076, time/batch=-4.781\n",
      "Extract of training data : [10563] [1699]\n",
      "2978/16406, train loss is 10.546, state is -0.0068716974928975105, time/batch=-4.802\n",
      "Extract of training data : [2853] [6286]\n",
      "2979/16406, train loss is 10.546, state is -0.008408264257013798, time/batch=-4.797\n",
      "Extract of training data : [21477] [23543]\n",
      "2980/16406, train loss is 10.546, state is -0.0030953919049352407, time/batch=-4.782\n",
      "Extract of training data : [737] [10]\n",
      "2981/16406, train loss is 10.546, state is -0.008528818376362324, time/batch=-4.785\n",
      "Extract of training data : [16] [12344]\n",
      "2982/16406, train loss is 10.546, state is 0.0021011349745094776, time/batch=-4.783\n",
      "Extract of training data : [328] [1273]\n",
      "2983/16406, train loss is 10.546, state is 0.004190689884126186, time/batch=-4.804\n",
      "Extract of training data : [2308] [6146]\n",
      "2984/16406, train loss is 10.546, state is 0.002575047081336379, time/batch=-4.814\n",
      "Extract of training data : [196] [10]\n",
      "2985/16406, train loss is 10.546, state is 0.015781832858920097, time/batch=-4.810\n",
      "Extract of training data : [61] [1780]\n",
      "2986/16406, train loss is 10.546, state is 0.008311795070767403, time/batch=-4.819\n",
      "Extract of training data : [0] [3]\n",
      "2987/16406, train loss is 10.546, state is -0.009542044252157211, time/batch=-4.784\n",
      "Extract of training data : [5356] [10]\n",
      "2988/16406, train loss is 10.546, state is -0.01846333034336567, time/batch=-4.938\n",
      "Extract of training data : [37560] [10]\n",
      "2989/16406, train loss is 10.546, state is 0.010719235055148602, time/batch=-4.781\n",
      "Extract of training data : [35] [24863]\n",
      "2990/16406, train loss is 10.546, state is -0.0034398287534713745, time/batch=-4.785\n",
      "Extract of training data : [3] [23535]\n",
      "2991/16406, train loss is 10.546, state is 0.0017098269890993834, time/batch=-4.804\n",
      "Extract of training data : [10] [1165]\n",
      "2992/16406, train loss is 10.546, state is 0.006481895688921213, time/batch=-4.838\n",
      "Extract of training data : [13159] [5930]\n",
      "2993/16406, train loss is 10.546, state is 0.0018918124260380864, time/batch=-4.808\n",
      "Extract of training data : [3197] [23950]\n",
      "2994/16406, train loss is 10.546, state is 0.008911952376365662, time/batch=-4.829\n",
      "Extract of training data : [2404] [3270]\n",
      "2995/16406, train loss is 10.546, state is 0.00042260659392923117, time/batch=-4.896\n",
      "Extract of training data : [850] [1481]\n",
      "2996/16406, train loss is 10.546, state is -0.004215030465275049, time/batch=-4.803\n",
      "Extract of training data : [18303] [1]\n",
      "2997/16406, train loss is 10.546, state is 0.0021554394625127316, time/batch=-4.819\n",
      "Extract of training data : [280] [422]\n",
      "2998/16406, train loss is 10.546, state is -0.0022000721655786037, time/batch=-4.844\n",
      "Extract of training data : [3] [3]\n",
      "2999/16406, train loss is 10.546, state is -0.012487808242440224, time/batch=-4.815\n",
      "Extract of training data : [10] [3125]\n",
      "3000/16406, train loss is 10.546, state is 0.003971627447754145, time/batch=-4.837\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [10177] [10]\n",
      "3001/16406, train loss is 10.546, state is -0.016256973147392273, time/batch=-4.999\n",
      "Extract of training data : [29] [5880]\n",
      "3002/16406, train loss is 10.546, state is -0.010176138952374458, time/batch=-4.816\n",
      "Extract of training data : [35] [1293]\n",
      "3003/16406, train loss is 10.546, state is -0.0024084928445518017, time/batch=-4.811\n",
      "Extract of training data : [2883] [51]\n",
      "3004/16406, train loss is 10.546, state is -0.0006876033148728311, time/batch=-4.787\n",
      "Extract of training data : [3] [3]\n",
      "3005/16406, train loss is 10.546, state is 0.00396078871563077, time/batch=-4.818\n",
      "Extract of training data : [4281] [1483]\n",
      "3006/16406, train loss is 10.545, state is -0.0018423872534185648, time/batch=-4.811\n",
      "Extract of training data : [1293] [26201]\n",
      "3007/16406, train loss is 10.546, state is 0.0016292735235765576, time/batch=-4.796\n",
      "Extract of training data : [2597] [10]\n",
      "3008/16406, train loss is 10.546, state is -0.013925133273005486, time/batch=-4.779\n",
      "Extract of training data : [21] [17647]\n",
      "3009/16406, train loss is 10.546, state is -0.009808552451431751, time/batch=-4.796\n",
      "Extract of training data : [13628] [12]\n",
      "3010/16406, train loss is 10.546, state is 0.01280942466109991, time/batch=-4.790\n",
      "Extract of training data : [5313] [105]\n",
      "3011/16406, train loss is 10.546, state is -0.01368027739226818, time/batch=-4.837\n",
      "Extract of training data : [3] [3]\n",
      "3012/16406, train loss is 10.546, state is 0.0022226539440453053, time/batch=-4.796\n",
      "Extract of training data : [0] [3]\n",
      "3013/16406, train loss is 10.546, state is 0.005502075422555208, time/batch=-4.774\n",
      "Extract of training data : [737] [35]\n",
      "3014/16406, train loss is 10.546, state is 0.0037414671387523413, time/batch=-4.810\n",
      "Extract of training data : [21] [1171]\n",
      "3015/16406, train loss is 10.546, state is 0.009014569222927094, time/batch=-4.791\n",
      "Extract of training data : [10] [344]\n",
      "3016/16406, train loss is 10.546, state is 0.0015534533886238933, time/batch=-4.787\n",
      "Extract of training data : [3414] [16]\n",
      "3017/16406, train loss is 10.546, state is 0.005061393603682518, time/batch=-4.824\n",
      "Extract of training data : [2341] [7289]\n",
      "3018/16406, train loss is 10.545, state is 0.00564809562638402, time/batch=-4.776\n",
      "Extract of training data : [0] [0]\n",
      "3019/16406, train loss is 10.546, state is 0.0031388066709041595, time/batch=-4.779\n",
      "Extract of training data : [6485] [2970]\n",
      "3020/16406, train loss is 10.545, state is 0.0030108275823295116, time/batch=-4.809\n",
      "Extract of training data : [8] [277]\n",
      "3021/16406, train loss is 10.546, state is -0.006528761703521013, time/batch=-4.761\n",
      "Extract of training data : [10] [159]\n",
      "3022/16406, train loss is 10.545, state is -0.011108706705272198, time/batch=-4.820\n",
      "Extract of training data : [458] [15872]\n",
      "3023/16406, train loss is 10.545, state is 0.0138628501445055, time/batch=-4.825\n",
      "Extract of training data : [422] [143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3024/16406, train loss is 10.545, state is -0.02462073601782322, time/batch=-4.817\n",
      "Extract of training data : [7539] [27618]\n",
      "3025/16406, train loss is 10.546, state is -0.02253490872681141, time/batch=-4.795\n",
      "Extract of training data : [10] [901]\n",
      "3026/16406, train loss is 10.545, state is -0.0015079618897289038, time/batch=-4.793\n",
      "Extract of training data : [1087] [237]\n",
      "3027/16406, train loss is 10.545, state is -0.001112168887630105, time/batch=-4.870\n",
      "Extract of training data : [6528] [1220]\n",
      "3028/16406, train loss is 10.545, state is -0.019249795004725456, time/batch=-4.867\n",
      "Extract of training data : [1180] [10]\n",
      "3029/16406, train loss is 10.546, state is 0.0038329854141920805, time/batch=-4.783\n",
      "Extract of training data : [10] [50]\n",
      "3030/16406, train loss is 10.546, state is -0.006615308579057455, time/batch=-4.834\n",
      "Extract of training data : [19388] [51]\n",
      "3031/16406, train loss is 10.546, state is 0.0087824622169137, time/batch=-4.835\n",
      "Extract of training data : [1946] [2612]\n",
      "3032/16406, train loss is 10.546, state is 0.002690482186153531, time/batch=-4.819\n",
      "Extract of training data : [2300] [10]\n",
      "3033/16406, train loss is 10.546, state is -0.0005490605253726244, time/batch=-4.774\n",
      "Extract of training data : [105] [715]\n",
      "3034/16406, train loss is 10.546, state is 0.006783760152757168, time/batch=-4.795\n",
      "Extract of training data : [10] [28405]\n",
      "3035/16406, train loss is 10.546, state is 0.00923440046608448, time/batch=-4.823\n",
      "Extract of training data : [29] [28482]\n",
      "3036/16406, train loss is 10.545, state is -0.011513189412653446, time/batch=-4.786\n",
      "Extract of training data : [71] [5777]\n",
      "3037/16406, train loss is 10.546, state is -0.00015173100109677762, time/batch=-4.797\n",
      "Extract of training data : [1185] [29]\n",
      "3038/16406, train loss is 10.545, state is -0.005637248512357473, time/batch=-4.786\n",
      "Extract of training data : [105] [850]\n",
      "3039/16406, train loss is 10.546, state is 0.002486602170392871, time/batch=-4.758\n",
      "Extract of training data : [9745] [4441]\n",
      "3040/16406, train loss is 10.545, state is -0.01023935154080391, time/batch=-4.805\n",
      "Extract of training data : [3154] [2844]\n",
      "3041/16406, train loss is 10.546, state is 0.014548239298164845, time/batch=-4.834\n",
      "Extract of training data : [16] [1785]\n",
      "3042/16406, train loss is 10.545, state is -0.009919741190969944, time/batch=-4.780\n",
      "Extract of training data : [688] [1846]\n",
      "3043/16406, train loss is 10.546, state is -0.011926905252039433, time/batch=-4.824\n",
      "Extract of training data : [1599] [6409]\n",
      "3044/16406, train loss is 10.546, state is 0.010678739286959171, time/batch=-4.785\n",
      "Extract of training data : [10886] [10]\n",
      "3045/16406, train loss is 10.546, state is -0.009289628826081753, time/batch=-4.787\n",
      "Extract of training data : [1507] [10]\n",
      "3046/16406, train loss is 10.546, state is 0.008330798707902431, time/batch=-4.827\n",
      "Extract of training data : [2182] [3404]\n",
      "3047/16406, train loss is 10.546, state is -0.006118223071098328, time/batch=-4.870\n",
      "Extract of training data : [1821] [51]\n",
      "3048/16406, train loss is 10.546, state is -0.014374040998518467, time/batch=-4.897\n",
      "Extract of training data : [10] [2910]\n",
      "3049/16406, train loss is 10.546, state is -0.0009416656102985144, time/batch=-4.828\n",
      "Extract of training data : [28963] [3743]\n",
      "3050/16406, train loss is 10.545, state is -0.012144183740019798, time/batch=-4.897\n",
      "Extract of training data : [29174] [35]\n",
      "3051/16406, train loss is 10.546, state is 0.0031979915220290422, time/batch=-5.016\n",
      "Extract of training data : [3203] [10]\n",
      "3052/16406, train loss is 10.545, state is 0.0031799646094441414, time/batch=-4.873\n",
      "Extract of training data : [16878] [35]\n",
      "3053/16406, train loss is 10.545, state is 0.0058794766664505005, time/batch=-4.776\n",
      "Extract of training data : [1081] [5124]\n",
      "3054/16406, train loss is 10.546, state is -0.01836451143026352, time/batch=-4.876\n",
      "Extract of training data : [3980] [2679]\n",
      "3055/16406, train loss is 10.545, state is 0.0080353282392025, time/batch=-4.799\n",
      "Extract of training data : [3] [5168]\n",
      "3056/16406, train loss is 10.546, state is 0.0003987153177149594, time/batch=-4.800\n",
      "Extract of training data : [10] [344]\n",
      "3057/16406, train loss is 10.546, state is 0.00893367175012827, time/batch=-4.801\n",
      "Extract of training data : [571] [6997]\n",
      "3058/16406, train loss is 10.546, state is 0.0122043676674366, time/batch=-4.763\n",
      "Extract of training data : [10] [571]\n",
      "3059/16406, train loss is 10.546, state is 0.012728283181786537, time/batch=-4.763\n",
      "Extract of training data : [910] [963]\n",
      "3060/16406, train loss is 10.546, state is -0.0021537868306040764, time/batch=-4.822\n",
      "Extract of training data : [1051] [8]\n",
      "3061/16406, train loss is 10.546, state is 0.004745887592434883, time/batch=-4.786\n",
      "Extract of training data : [2913] [16549]\n",
      "3062/16406, train loss is 10.545, state is 0.007783267181366682, time/batch=-4.809\n",
      "Extract of training data : [29715] [32]\n",
      "3063/16406, train loss is 10.545, state is 0.004639059770852327, time/batch=-4.863\n",
      "Extract of training data : [10] [688]\n",
      "3064/16406, train loss is 10.546, state is -0.0031460104510188103, time/batch=-4.814\n",
      "Extract of training data : [3] [3]\n",
      "3065/16406, train loss is 10.546, state is -0.0029283887706696987, time/batch=-4.798\n",
      "Extract of training data : [10] [633]\n",
      "3066/16406, train loss is 10.546, state is -0.01173478364944458, time/batch=-4.818\n",
      "Extract of training data : [3] [291]\n",
      "3067/16406, train loss is 10.545, state is -0.01649087853729725, time/batch=-4.881\n",
      "Extract of training data : [3055] [71]\n",
      "3068/16406, train loss is 10.546, state is 0.010913657024502754, time/batch=-4.807\n",
      "Extract of training data : [10] [9562]\n",
      "3069/16406, train loss is 10.546, state is -0.008633296936750412, time/batch=-4.779\n",
      "Extract of training data : [9027] [10]\n",
      "3070/16406, train loss is 10.545, state is -0.001837227726355195, time/batch=-4.820\n",
      "Extract of training data : [5507] [4610]\n",
      "3071/16406, train loss is 10.545, state is 0.019485604017972946, time/batch=-4.792\n",
      "Extract of training data : [105] [1078]\n",
      "3072/16406, train loss is 10.546, state is -0.002664069179445505, time/batch=-4.761\n",
      "Extract of training data : [0] [0]\n",
      "3073/16406, train loss is 10.546, state is -0.00091306131798774, time/batch=-4.815\n",
      "Extract of training data : [1366] [1553]\n",
      "3074/16406, train loss is 10.545, state is -0.016388721764087677, time/batch=-4.881\n",
      "Extract of training data : [8] [277]\n",
      "3075/16406, train loss is 10.545, state is -0.014265654608607292, time/batch=-4.781\n",
      "Extract of training data : [11486] [10]\n",
      "3076/16406, train loss is 10.545, state is -0.014208431355655193, time/batch=-4.806\n",
      "Extract of training data : [3] [20583]\n",
      "3077/16406, train loss is 10.545, state is 0.008895602077245712, time/batch=-4.780\n",
      "Extract of training data : [378] [720]\n",
      "3078/16406, train loss is 10.545, state is -0.01388834323734045, time/batch=-4.793\n",
      "Extract of training data : [46] [22852]\n",
      "3079/16406, train loss is 10.545, state is 0.004868092946708202, time/batch=-4.777\n",
      "Extract of training data : [3493] [35]\n",
      "3080/16406, train loss is 10.545, state is -0.006126058287918568, time/batch=-4.769\n",
      "Extract of training data : [3] [20583]\n",
      "3081/16406, train loss is 10.545, state is 0.01743476465344429, time/batch=-4.811\n",
      "Extract of training data : [10987] [105]\n",
      "3082/16406, train loss is 10.545, state is -0.0202338844537735, time/batch=-4.768\n",
      "Extract of training data : [7001] [29526]\n",
      "3083/16406, train loss is 10.545, state is -0.0003228276618756354, time/batch=-4.773\n",
      "Extract of training data : [7166] [12]\n",
      "3084/16406, train loss is 10.545, state is -0.004601106513291597, time/batch=-4.883\n",
      "Extract of training data : [12524] [174]\n",
      "3085/16406, train loss is 10.546, state is 0.008679439313709736, time/batch=-4.801\n",
      "Extract of training data : [3524] [1256]\n",
      "3086/16406, train loss is 10.546, state is -0.0008091233321465552, time/batch=-4.851\n",
      "Extract of training data : [55] [174]\n",
      "3087/16406, train loss is 10.546, state is -0.0033280756324529648, time/batch=-4.770\n",
      "Extract of training data : [1636] [10]\n",
      "3088/16406, train loss is 10.545, state is -0.0012543214252218604, time/batch=-4.828\n",
      "Extract of training data : [31476] [10]\n",
      "3089/16406, train loss is 10.545, state is -0.012147797271609306, time/batch=-4.803\n",
      "Extract of training data : [3] [3]\n",
      "3090/16406, train loss is 10.545, state is -0.01106482744216919, time/batch=-4.793\n",
      "Extract of training data : [12] [150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091/16406, train loss is 10.546, state is -0.011083731427788734, time/batch=-4.819\n",
      "Extract of training data : [60] [6578]\n",
      "3092/16406, train loss is 10.546, state is -0.003065172815695405, time/batch=-4.807\n",
      "Extract of training data : [3] [3]\n",
      "3093/16406, train loss is 10.546, state is -0.014126492664217949, time/batch=-4.787\n",
      "Extract of training data : [8837] [10]\n",
      "3094/16406, train loss is 10.546, state is 0.009686185047030449, time/batch=-4.828\n",
      "Extract of training data : [8467] [2704]\n",
      "3095/16406, train loss is 10.546, state is -0.035365693271160126, time/batch=-4.781\n",
      "Extract of training data : [31897] [2159]\n",
      "3096/16406, train loss is 10.546, state is -0.020160213112831116, time/batch=-4.796\n",
      "Extract of training data : [3] [31950]\n",
      "3097/16406, train loss is 10.545, state is -0.00816623866558075, time/batch=-4.816\n",
      "Extract of training data : [1006] [1769]\n",
      "3098/16406, train loss is 10.545, state is 4.985529085388407e-05, time/batch=-4.827\n",
      "Extract of training data : [301] [10]\n",
      "3099/16406, train loss is 10.546, state is -0.007312382105737925, time/batch=-4.811\n",
      "Extract of training data : [50] [71]\n",
      "3100/16406, train loss is 10.546, state is 0.0022983206436038017, time/batch=-4.764\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [10] [588]\n",
      "3101/16406, train loss is 10.545, state is 0.02370678074657917, time/batch=-5.244\n",
      "Extract of training data : [0] [0]\n",
      "3102/16406, train loss is 10.546, state is -0.011429151520133018, time/batch=-4.920\n",
      "Extract of training data : [413] [4118]\n",
      "3103/16406, train loss is 10.545, state is -0.011292128823697567, time/batch=-4.774\n",
      "Extract of training data : [1273] [51]\n",
      "3104/16406, train loss is 10.546, state is -0.0006034210091456771, time/batch=-4.808\n",
      "Extract of training data : [8] [277]\n",
      "3105/16406, train loss is 10.546, state is -0.006502967793494463, time/batch=-4.838\n",
      "Extract of training data : [2946] [544]\n",
      "3106/16406, train loss is 10.546, state is -0.009426411241292953, time/batch=-4.845\n",
      "Extract of training data : [10] [1190]\n",
      "3107/16406, train loss is 10.546, state is -0.0047447835095226765, time/batch=-4.799\n",
      "Extract of training data : [24694] [19548]\n",
      "3108/16406, train loss is 10.545, state is -0.004500968847423792, time/batch=-4.795\n",
      "Extract of training data : [8725] [105]\n",
      "3109/16406, train loss is 10.545, state is 0.007668078411370516, time/batch=-4.782\n",
      "Extract of training data : [2075] [105]\n",
      "3110/16406, train loss is 10.545, state is 0.00787117425352335, time/batch=-4.778\n",
      "Extract of training data : [1575] [5137]\n",
      "3111/16406, train loss is 10.545, state is 0.002752172527834773, time/batch=-4.931\n",
      "Extract of training data : [10] [9645]\n",
      "3112/16406, train loss is 10.546, state is -0.006335888989269733, time/batch=-4.930\n",
      "Extract of training data : [6531] [51]\n",
      "3113/16406, train loss is 10.546, state is -0.012910652905702591, time/batch=-4.801\n",
      "Extract of training data : [3] [3]\n",
      "3114/16406, train loss is 10.546, state is 0.01829640194773674, time/batch=-4.793\n",
      "Extract of training data : [5284] [21127]\n",
      "3115/16406, train loss is 10.546, state is 0.005359960719943047, time/batch=-4.791\n",
      "Extract of training data : [873] [2105]\n",
      "3116/16406, train loss is 10.546, state is 0.00538655323907733, time/batch=-4.810\n",
      "Extract of training data : [35] [277]\n",
      "3117/16406, train loss is 10.546, state is -0.0023165990132838488, time/batch=-4.825\n",
      "Extract of training data : [3610] [0]\n",
      "3118/16406, train loss is 10.545, state is 0.010919641703367233, time/batch=-4.815\n",
      "Extract of training data : [1507] [631]\n",
      "3119/16406, train loss is 10.545, state is 0.00011647355131572112, time/batch=-4.785\n",
      "Extract of training data : [1207] [105]\n",
      "3120/16406, train loss is 10.545, state is 0.0038861341308802366, time/batch=-4.817\n",
      "Extract of training data : [280] [0]\n",
      "3121/16406, train loss is 10.545, state is -0.021327301859855652, time/batch=-4.773\n",
      "Extract of training data : [32906] [3758]\n",
      "3122/16406, train loss is 10.545, state is 0.0034648918081074953, time/batch=-4.808\n",
      "Extract of training data : [35] [2633]\n",
      "3123/16406, train loss is 10.546, state is 0.003163686254993081, time/batch=-4.793\n",
      "Extract of training data : [3] [8821]\n",
      "3124/16406, train loss is 10.546, state is -0.015421727672219276, time/batch=-4.802\n",
      "Extract of training data : [3] [3]\n",
      "3125/16406, train loss is 10.545, state is -0.00518085528165102, time/batch=-4.813\n",
      "Extract of training data : [0] [3]\n",
      "3126/16406, train loss is 10.546, state is 0.005338555201888084, time/batch=-4.790\n",
      "Extract of training data : [12284] [29]\n",
      "3127/16406, train loss is 10.546, state is -0.0116635262966156, time/batch=-4.798\n",
      "Extract of training data : [13192] [0]\n",
      "3128/16406, train loss is 10.546, state is 0.0011426208075135946, time/batch=-4.828\n",
      "Extract of training data : [1572] [35]\n",
      "3129/16406, train loss is 10.546, state is -0.00038682378362864256, time/batch=-4.795\n",
      "Extract of training data : [9822] [10]\n",
      "3130/16406, train loss is 10.546, state is -0.0015894329408183694, time/batch=-4.752\n",
      "Extract of training data : [0] [0]\n",
      "3131/16406, train loss is 10.546, state is -0.0015260863583534956, time/batch=-4.777\n",
      "Extract of training data : [35] [16632]\n",
      "3132/16406, train loss is 10.546, state is 0.006344159599393606, time/batch=-4.813\n",
      "Extract of training data : [6929] [10]\n",
      "3133/16406, train loss is 10.546, state is -0.0388193354010582, time/batch=-4.776\n",
      "Extract of training data : [2985] [2892]\n",
      "3134/16406, train loss is 10.546, state is -0.00983317568898201, time/batch=-4.814\n",
      "Extract of training data : [561] [882]\n",
      "3135/16406, train loss is 10.545, state is -0.0163645651191473, time/batch=-4.809\n",
      "Extract of training data : [5654] [35]\n",
      "3136/16406, train loss is 10.545, state is -0.01861458644270897, time/batch=-4.773\n",
      "Extract of training data : [10] [783]\n",
      "3137/16406, train loss is 10.545, state is 0.006463649217039347, time/batch=-4.819\n",
      "Extract of training data : [1017] [1988]\n",
      "3138/16406, train loss is 10.545, state is 0.0001381499314447865, time/batch=-4.798\n",
      "Extract of training data : [3367] [1079]\n",
      "3139/16406, train loss is 10.545, state is 0.016570990905165672, time/batch=-4.773\n",
      "Extract of training data : [18518] [378]\n",
      "3140/16406, train loss is 10.545, state is -0.00593913160264492, time/batch=-4.778\n",
      "Extract of training data : [35] [3127]\n",
      "3141/16406, train loss is 10.545, state is 0.008222317323088646, time/batch=-4.801\n",
      "Extract of training data : [10] [1477]\n",
      "3142/16406, train loss is 10.545, state is -0.017539221793413162, time/batch=-4.808\n",
      "Extract of training data : [5067] [35]\n",
      "3143/16406, train loss is 10.546, state is 0.008045691065490246, time/batch=-4.800\n",
      "Extract of training data : [3] [3]\n",
      "3144/16406, train loss is 10.546, state is -0.011134590022265911, time/batch=-4.813\n",
      "Extract of training data : [3] [3]\n",
      "3145/16406, train loss is 10.545, state is -0.0013261535204946995, time/batch=-4.751\n",
      "Extract of training data : [105] [10]\n",
      "3146/16406, train loss is 10.545, state is 0.005717557854950428, time/batch=-4.796\n",
      "Extract of training data : [12504] [29]\n",
      "3147/16406, train loss is 10.545, state is -0.024307511746883392, time/batch=-4.809\n",
      "Extract of training data : [20583] [2791]\n",
      "3148/16406, train loss is 10.545, state is -0.0010319435968995094, time/batch=-4.760\n",
      "Extract of training data : [13349] [413]\n",
      "3149/16406, train loss is 10.546, state is 0.007977865636348724, time/batch=-4.880\n",
      "Extract of training data : [29] [6899]\n",
      "3150/16406, train loss is 10.545, state is 0.012062881141901016, time/batch=-4.831\n",
      "Extract of training data : [1180] [10]\n",
      "3151/16406, train loss is 10.545, state is -0.0062864082865417, time/batch=-4.777\n",
      "Extract of training data : [11] [2923]\n",
      "3152/16406, train loss is 10.545, state is -0.0002488106256350875, time/batch=-4.785\n",
      "Extract of training data : [675] [3904]\n",
      "3153/16406, train loss is 10.545, state is -0.009431895799934864, time/batch=-4.757\n",
      "Extract of training data : [10] [2050]\n",
      "3154/16406, train loss is 10.546, state is -0.010508817620575428, time/batch=-4.847\n",
      "Extract of training data : [2063] [2311]\n",
      "3155/16406, train loss is 10.546, state is 0.011697519570589066, time/batch=-4.869\n",
      "Extract of training data : [3] [7243]\n",
      "3156/16406, train loss is 10.545, state is 0.002295283367857337, time/batch=-4.800\n",
      "Extract of training data : [16717] [327]\n",
      "3157/16406, train loss is 10.546, state is -0.009998932480812073, time/batch=-4.815\n",
      "Extract of training data : [34576] [1182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158/16406, train loss is 10.546, state is -0.00867338664829731, time/batch=-4.810\n",
      "Extract of training data : [6286] [2398]\n",
      "3159/16406, train loss is 10.545, state is 0.01203810703009367, time/batch=-4.823\n",
      "Extract of training data : [10] [439]\n",
      "3160/16406, train loss is 10.545, state is -0.0009164625080302358, time/batch=-4.887\n",
      "Extract of training data : [1529] [10]\n",
      "3161/16406, train loss is 10.546, state is 0.009730976074934006, time/batch=-4.801\n",
      "Extract of training data : [916] [920]\n",
      "3162/16406, train loss is 10.545, state is -0.012612531892955303, time/batch=-4.782\n",
      "Extract of training data : [15508] [3104]\n",
      "3163/16406, train loss is 10.546, state is -0.02032272145152092, time/batch=-4.815\n",
      "Extract of training data : [0] [0]\n",
      "3164/16406, train loss is 10.546, state is 0.0020999773405492306, time/batch=-4.835\n",
      "Extract of training data : [592] [1134]\n",
      "3165/16406, train loss is 10.545, state is 0.02046218514442444, time/batch=-4.782\n",
      "Extract of training data : [10] [4266]\n",
      "3166/16406, train loss is 10.545, state is -0.0041428618133068085, time/batch=-4.851\n",
      "Extract of training data : [4990] [46]\n",
      "3167/16406, train loss is 10.546, state is -0.014444615691900253, time/batch=-4.865\n",
      "Extract of training data : [23] [3758]\n",
      "3168/16406, train loss is 10.545, state is 0.007996040396392345, time/batch=-4.810\n",
      "Extract of training data : [105] [1661]\n",
      "3169/16406, train loss is 10.546, state is 0.014692520722746849, time/batch=-4.834\n",
      "Extract of training data : [12] [1273]\n",
      "3170/16406, train loss is 10.546, state is 0.006051812320947647, time/batch=-4.798\n",
      "Extract of training data : [2925] [13914]\n",
      "3171/16406, train loss is 10.546, state is -0.003256151918321848, time/batch=-4.813\n",
      "Extract of training data : [413] [71]\n",
      "3172/16406, train loss is 10.546, state is -0.007867022417485714, time/batch=-4.876\n",
      "Extract of training data : [877] [280]\n",
      "3173/16406, train loss is 10.545, state is 0.011587855406105518, time/batch=-4.803\n",
      "Extract of training data : [8539] [35]\n",
      "3174/16406, train loss is 10.546, state is -0.00046485502389259636, time/batch=-4.805\n",
      "Extract of training data : [35565] [35566]\n",
      "3175/16406, train loss is 10.545, state is 0.00623356644064188, time/batch=-4.792\n",
      "Extract of training data : [1515] [10]\n",
      "3176/16406, train loss is 10.545, state is -0.012439814396202564, time/batch=-4.860\n",
      "Extract of training data : [20818] [127]\n",
      "3177/16406, train loss is 10.545, state is 0.002185635268688202, time/batch=-4.768\n",
      "Extract of training data : [1636] [10]\n",
      "3178/16406, train loss is 10.545, state is -0.004553989972919226, time/batch=-4.798\n",
      "Extract of training data : [4143] [34218]\n",
      "3179/16406, train loss is 10.546, state is -0.013060009106993675, time/batch=-4.802\n",
      "Extract of training data : [190] [555]\n",
      "3180/16406, train loss is 10.545, state is 0.005026515107601881, time/batch=-4.811\n",
      "Extract of training data : [4765] [10]\n",
      "3181/16406, train loss is 10.546, state is 0.0022110973950475454, time/batch=-4.772\n",
      "Extract of training data : [0] [0]\n",
      "3182/16406, train loss is 10.545, state is -0.0024830454494804144, time/batch=-4.853\n",
      "Extract of training data : [1014] [17764]\n",
      "3183/16406, train loss is 10.546, state is 0.00021651192218996584, time/batch=-4.788\n",
      "Extract of training data : [6873] [2813]\n",
      "3184/16406, train loss is 10.545, state is 0.004628794267773628, time/batch=-4.813\n",
      "Extract of training data : [2076] [633]\n",
      "3185/16406, train loss is 10.545, state is -0.0019414351554587483, time/batch=-4.825\n",
      "Extract of training data : [1507] [10]\n",
      "3186/16406, train loss is 10.546, state is -0.010455025359988213, time/batch=-4.783\n",
      "Extract of training data : [3] [3]\n",
      "3187/16406, train loss is 10.545, state is -0.003397571388632059, time/batch=-4.803\n",
      "Extract of training data : [4945] [499]\n",
      "3188/16406, train loss is 10.545, state is 0.008712349459528923, time/batch=-4.920\n",
      "Extract of training data : [1675] [4162]\n",
      "3189/16406, train loss is 10.546, state is -0.024707717821002007, time/batch=-4.833\n",
      "Extract of training data : [1386] [0]\n",
      "3190/16406, train loss is 10.545, state is -0.007512431591749191, time/batch=-4.873\n",
      "Extract of training data : [2633] [906]\n",
      "3191/16406, train loss is 10.546, state is -0.016179794445633888, time/batch=-4.820\n",
      "Extract of training data : [422] [35]\n",
      "3192/16406, train loss is 10.546, state is -0.019355246797204018, time/batch=-4.797\n",
      "Extract of training data : [176] [7949]\n",
      "3193/16406, train loss is 10.545, state is 0.008895439095795155, time/batch=-4.782\n",
      "Extract of training data : [51] [106]\n",
      "3194/16406, train loss is 10.546, state is -0.009298210963606834, time/batch=-4.821\n",
      "Extract of training data : [3] [277]\n",
      "3195/16406, train loss is 10.545, state is 0.0036600674502551556, time/batch=-4.882\n",
      "Extract of training data : [10] [3485]\n",
      "3196/16406, train loss is 10.545, state is 0.005481223110109568, time/batch=-4.782\n",
      "Extract of training data : [105] [910]\n",
      "3197/16406, train loss is 10.545, state is -0.0073976884596049786, time/batch=-4.848\n",
      "Extract of training data : [2119] [10]\n",
      "3198/16406, train loss is 10.546, state is 0.0050607468001544476, time/batch=-4.802\n",
      "Extract of training data : [28829] [2007]\n",
      "3199/16406, train loss is 10.546, state is 0.0009735851781442761, time/batch=-4.819\n",
      "Extract of training data : [0] [3]\n",
      "3200/16406, train loss is 10.545, state is 0.009570901282131672, time/batch=-4.810\n",
      "model saved to ./save/model.ckpt\n",
      "Extract of training data : [0] [3]\n",
      "3201/16406, train loss is 10.545, state is 0.002897409023717046, time/batch=-5.014\n",
      "Extract of training data : [3] [3]\n",
      "3202/16406, train loss is 10.546, state is -0.006604486145079136, time/batch=-5.300\n",
      "Extract of training data : [3] [3]\n",
      "3203/16406, train loss is 10.546, state is -0.015059249475598335, time/batch=-4.264\n",
      "Extract of training data : [9167] [12915]\n",
      "3204/16406, train loss is 10.545, state is -0.005648376885801554, time/batch=-4.260\n",
      "Extract of training data : [0] [1]\n",
      "3205/16406, train loss is 10.545, state is -0.0044733574613928795, time/batch=-4.238\n",
      "Extract of training data : [883] [10]\n",
      "3206/16406, train loss is 10.545, state is -0.021404201164841652, time/batch=-4.213\n",
      "Extract of training data : [277] [1137]\n",
      "3207/16406, train loss is 10.545, state is -0.004695568699389696, time/batch=-4.200\n",
      "Extract of training data : [3] [3]\n",
      "3208/16406, train loss is 10.545, state is -0.0010061119683086872, time/batch=-4.241\n",
      "Extract of training data : [1935] [422]\n",
      "3209/16406, train loss is 10.546, state is -0.023029591888189316, time/batch=-4.227\n",
      "Extract of training data : [2605] [359]\n",
      "3210/16406, train loss is 10.545, state is -0.00988466665148735, time/batch=-4.307\n",
      "Extract of training data : [3516] [14]\n",
      "3211/16406, train loss is 10.545, state is -0.022142594680190086, time/batch=-4.199\n",
      "Extract of training data : [3516] [3701]\n",
      "3212/16406, train loss is 10.546, state is 0.016209742054343224, time/batch=-4.275\n",
      "Extract of training data : [359] [804]\n",
      "3213/16406, train loss is 10.545, state is 0.009600860066711903, time/batch=-4.202\n",
      "Extract of training data : [806] [105]\n",
      "3214/16406, train loss is 10.545, state is -0.006050491705536842, time/batch=-4.124\n",
      "Extract of training data : [4868] [105]\n",
      "3215/16406, train loss is 10.545, state is 0.009009649977087975, time/batch=-4.138\n",
      "Extract of training data : [10] [2854]\n",
      "3216/16406, train loss is 10.545, state is -0.018926337361335754, time/batch=-4.128\n",
      "Extract of training data : [3] [1021]\n",
      "3217/16406, train loss is 10.545, state is -0.019610639661550522, time/batch=-4.126\n",
      "Extract of training data : [10] [5860]\n",
      "3218/16406, train loss is 10.545, state is 0.016460902988910675, time/batch=-4.114\n",
      "Extract of training data : [3] [292]\n",
      "3219/16406, train loss is 10.545, state is 0.0010569465812295675, time/batch=-4.133\n",
      "Extract of training data : [6327] [811]\n",
      "3220/16406, train loss is 10.545, state is 0.0064763836562633514, time/batch=-4.180\n",
      "Extract of training data : [291] [643]\n",
      "3221/16406, train loss is 10.545, state is 0.0017881820676848292, time/batch=-4.181\n",
      "Extract of training data : [413] [876]\n",
      "3222/16406, train loss is 10.545, state is 0.011829150840640068, time/batch=-4.156\n",
      "Extract of training data : [1056] [7122]\n",
      "3223/16406, train loss is 10.545, state is -0.008585824631154537, time/batch=-4.139\n",
      "Extract of training data : [25] [1437]\n",
      "3224/16406, train loss is 10.546, state is -0.021565953269600868, time/batch=-4.142\n",
      "Extract of training data : [2141] [28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3225/16406, train loss is 10.545, state is -0.011277369223535061, time/batch=-4.160\n",
      "Extract of training data : [559] [71]\n",
      "3226/16406, train loss is 10.545, state is -0.011220208369195461, time/batch=-4.099\n",
      "Extract of training data : [3] [3]\n",
      "3227/16406, train loss is 10.545, state is -0.00892542488873005, time/batch=-4.132\n",
      "Extract of training data : [110] [10]\n",
      "3228/16406, train loss is 10.545, state is -0.002315860241651535, time/batch=-4.096\n",
      "Extract of training data : [8197] [16]\n",
      "3229/16406, train loss is 10.545, state is 0.0010711046634241939, time/batch=-4.141\n",
      "Extract of training data : [6749] [8411]\n",
      "3230/16406, train loss is 10.545, state is -0.017882555723190308, time/batch=-4.124\n",
      "Extract of training data : [8606] [1220]\n",
      "3231/16406, train loss is 10.545, state is 0.00994658563286066, time/batch=-4.106\n",
      "Extract of training data : [3] [699]\n",
      "3232/16406, train loss is 10.546, state is -0.005166932474821806, time/batch=-4.201\n",
      "Extract of training data : [277] [4505]\n",
      "3233/16406, train loss is 10.545, state is -0.0030309646390378475, time/batch=-4.133\n",
      "Extract of training data : [3] [422]\n",
      "3234/16406, train loss is 10.545, state is -0.012387212365865707, time/batch=-4.148\n",
      "Extract of training data : [3552] [3553]\n",
      "3235/16406, train loss is 10.546, state is -0.0010731220245361328, time/batch=-4.186\n",
      "Extract of training data : [9380] [51]\n",
      "3236/16406, train loss is 10.545, state is 0.0007960355142131448, time/batch=-4.217\n",
      "Extract of training data : [35] [2404]\n",
      "3237/16406, train loss is 10.546, state is -0.004014960490167141, time/batch=-4.129\n",
      "Extract of training data : [3327] [2586]\n",
      "3238/16406, train loss is 10.545, state is 0.008858218789100647, time/batch=-4.111\n",
      "Extract of training data : [10] [3366]\n",
      "3239/16406, train loss is 10.546, state is -0.021549105644226074, time/batch=-4.154\n",
      "Extract of training data : [3] [3]\n",
      "3240/16406, train loss is 10.545, state is 0.01567547582089901, time/batch=-4.105\n",
      "Extract of training data : [0] [0]\n",
      "3241/16406, train loss is 10.546, state is -0.0009766921866685152, time/batch=-4.194\n",
      "Extract of training data : [3] [3]\n",
      "3242/16406, train loss is 10.546, state is -0.006733647082000971, time/batch=-4.166\n",
      "Extract of training data : [10] [3155]\n",
      "3243/16406, train loss is 10.546, state is 0.0016098353080451488, time/batch=-4.161\n",
      "Extract of training data : [530] [10]\n",
      "3244/16406, train loss is 10.546, state is 0.005309689790010452, time/batch=-4.159\n",
      "Extract of training data : [801] [10142]\n",
      "3245/16406, train loss is 10.546, state is -0.006901395041495562, time/batch=-4.150\n",
      "Extract of training data : [277] [6179]\n",
      "3246/16406, train loss is 10.546, state is -0.004915905185043812, time/batch=-4.181\n",
      "Extract of training data : [6077] [10]\n",
      "3247/16406, train loss is 10.546, state is -0.008956336416304111, time/batch=-4.121\n",
      "Extract of training data : [10924] [10230]\n",
      "3248/16406, train loss is 10.546, state is -0.021467523649334908, time/batch=-4.146\n",
      "Extract of training data : [0] [0]\n",
      "3249/16406, train loss is 10.546, state is -0.006804526783525944, time/batch=-4.113\n",
      "Extract of training data : [3566] [413]\n",
      "3250/16406, train loss is 10.546, state is -0.014451684430241585, time/batch=-4.115\n",
      "Extract of training data : [3] [1707]\n",
      "3251/16406, train loss is 10.546, state is 0.005691901780664921, time/batch=-4.140\n",
      "Extract of training data : [1997] [16]\n",
      "3252/16406, train loss is 10.546, state is -0.004097484517842531, time/batch=-4.145\n",
      "Extract of training data : [3516] [2941]\n",
      "3253/16406, train loss is 10.546, state is -0.011678616516292095, time/batch=-4.132\n",
      "Extract of training data : [105] [1594]\n",
      "3254/16406, train loss is 10.546, state is 0.005605699028819799, time/batch=-4.110\n",
      "Extract of training data : [11697] [263]\n",
      "3255/16406, train loss is 10.546, state is -0.0016843852354213595, time/batch=-4.128\n",
      "Extract of training data : [548] [105]\n",
      "3256/16406, train loss is 10.545, state is 0.008693695068359375, time/batch=-4.158\n",
      "Extract of training data : [32] [3613]\n",
      "3257/16406, train loss is 10.546, state is 0.0037178564816713333, time/batch=-4.136\n",
      "Extract of training data : [3] [3]\n",
      "3258/16406, train loss is 10.546, state is 0.010968766175210476, time/batch=-4.133\n",
      "Extract of training data : [277] [12281]\n",
      "3259/16406, train loss is 10.545, state is 0.006129364017397165, time/batch=-4.124\n",
      "Extract of training data : [1220] [10]\n",
      "3260/16406, train loss is 10.546, state is -0.003972585778683424, time/batch=-4.140\n",
      "Extract of training data : [1480] [10]\n",
      "3261/16406, train loss is 10.546, state is -0.0007992672617547214, time/batch=-4.161\n",
      "Extract of training data : [6025] [10]\n",
      "3262/16406, train loss is 10.545, state is 0.009321247227489948, time/batch=-4.162\n",
      "Extract of training data : [10] [1971]\n",
      "3263/16406, train loss is 10.545, state is 0.0013809326337650418, time/batch=-4.141\n",
      "Extract of training data : [1021] [1161]\n",
      "3264/16406, train loss is 10.545, state is 0.003861738834530115, time/batch=-4.108\n",
      "Extract of training data : [13194] [1007]\n",
      "3265/16406, train loss is 10.546, state is 0.002408076310530305, time/batch=-4.133\n",
      "Extract of training data : [528] [877]\n",
      "3266/16406, train loss is 10.546, state is 0.006806390359997749, time/batch=-4.111\n",
      "Extract of training data : [3] [912]\n",
      "3267/16406, train loss is 10.546, state is 0.005389506462961435, time/batch=-4.129\n",
      "Extract of training data : [13562] [13563]\n",
      "3268/16406, train loss is 10.546, state is -0.006459418218582869, time/batch=-4.188\n",
      "Extract of training data : [1079] [105]\n",
      "3269/16406, train loss is 10.545, state is -0.006472736597061157, time/batch=-4.114\n",
      "Extract of training data : [3] [846]\n",
      "3270/16406, train loss is 10.545, state is -0.0024338122457265854, time/batch=-4.127\n",
      "Extract of training data : [5740] [9010]\n",
      "3271/16406, train loss is 10.545, state is -0.0029125679284334183, time/batch=-4.099\n",
      "Extract of training data : [4681] [10]\n",
      "3272/16406, train loss is 10.545, state is -0.0038489094004034996, time/batch=-4.092\n",
      "Extract of training data : [8] [277]\n",
      "3273/16406, train loss is 10.546, state is -0.0017000646330416203, time/batch=-4.199\n",
      "Extract of training data : [277] [2442]\n",
      "3274/16406, train loss is 10.545, state is -0.01845293864607811, time/batch=-4.125\n",
      "Extract of training data : [280] [0]\n",
      "3275/16406, train loss is 10.545, state is 0.010571868158876896, time/batch=-4.161\n",
      "Extract of training data : [11460] [10]\n",
      "3276/16406, train loss is 10.545, state is -0.01991966739296913, time/batch=-4.152\n",
      "Extract of training data : [924] [3938]\n",
      "3277/16406, train loss is 10.545, state is -0.018929634243249893, time/batch=-4.202\n",
      "Extract of training data : [3758] [688]\n",
      "3278/16406, train loss is 10.545, state is -0.007398972753435373, time/batch=-4.132\n",
      "Extract of training data : [14893] [1185]\n",
      "3279/16406, train loss is 10.545, state is 0.0023498644586652517, time/batch=-4.134\n",
      "Extract of training data : [492] [12]\n",
      "3280/16406, train loss is 10.545, state is -0.0037854614201933146, time/batch=-4.167\n",
      "Extract of training data : [505] [1177]\n",
      "3281/16406, train loss is 10.545, state is -0.007012973073869944, time/batch=-4.114\n",
      "Extract of training data : [4853] [16]\n",
      "3282/16406, train loss is 10.545, state is -0.009391740895807743, time/batch=-4.154\n",
      "Extract of training data : [46] [6974]\n",
      "3283/16406, train loss is 10.545, state is -0.004563589580357075, time/batch=-4.131\n",
      "Extract of training data : [3328] [6399]\n",
      "3284/16406, train loss is 10.545, state is 0.0022490646224468946, time/batch=-4.116\n",
      "Extract of training data : [3] [910]\n",
      "3285/16406, train loss is 10.546, state is 0.012748200446367264, time/batch=-4.135\n",
      "Extract of training data : [699] [16]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUM_STEP = 20 * CHAR_LENGTH // ( BATCH_SIZE * SEQ_LENGTH )\n",
    "LEARNING_RATE = 0.002\n",
    "DECAY_RATE = 0.99\n",
    "SAVE_DIR = './save/'\n",
    "SAVE_EVERY = 100\n",
    "\n",
    "model = Model()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Init all vairiable\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(SAVE_DIR)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    for step in range(NUM_STEP):\n",
    "        \n",
    "        state = sess.run(model.initial_state)\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        x, y = generate_batch(char_index)\n",
    "        \n",
    "        print(\"Extract of training data :\", x[0][:1], y[0][:1])\n",
    "        \n",
    "        feed = {}\n",
    "        feed[model.input_data]    = x\n",
    "        feed[model.output_data]   = y\n",
    "        feed[model.initial_state] = state\n",
    "        \n",
    "        loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        print(\"{}/{}, train loss is {:.3f}, state is {}, time/batch={:.3f}\".format(step, NUM_STEP, loss,state[0][0][0], start-end))\n",
    "        \n",
    "        if step % SAVE_EVERY == 0:\n",
    "            checkpoint_path = os.path.join(SAVE_DIR, \"model.ckpt\")\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "            print(\"model saved to {}\".format(checkpoint_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成一些文本试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save/model.ckpt-100\n",
      "烟囱，还正在向外飘着轻烟。\n",
      "\n",
      "    屋子外边，着一片绿色的衣角碎片，在悠悠吹来的轻风里，发出清脆的声音。\n",
      "\n",
      "    一阵诱人的香气，从那木屋之中飘了出来。\n",
      "\n",
      "    “汪汪汪，汪汪汪！”\n",
      "\n",
      "    “吱吱吱吱，吱吱吱吱……”\n",
      "\n",
      "    一阵奇怪的叫声，猛然从那木屋之中响起，随后只见黄影一闪，却是从屋中窜出一条老大的黄狗来，满脸堆欢，撒开四脚就跑；\n",
      "\n",
      "    在狗背上居然还骑着一只灰毛猴子，面上少见的居然有三只眼睛，手中抓着一只香喷喷的肉骨头，另一半紧紧抓住黄狗脖子，口中乱叫，大概是催促着黄狗快跑吧！\n",
      "\n",
      "    紧接着，从屋中跑出一个男子，粗衣麻裤，面上好像苦笑一般，大声喊道：“死狗，死猴子，你们又来偷肉骨头吃啊……”\n",
      "\n",
      "    忽地，他怔住了，眼中倒映着出陆雪琪站在前方的身影。\n",
      "\n",
      "    两个人就这般站着不动，彼此凝望着。\n",
      "\n",
      "    多少岁月，人间情愁，忽忽都在这深深一眼之中，然后，他们同时笑了起来。\n",
      "\n",
      "    一阵轻风吹过，屋檐下的铃铛迎风而响，绿色的衣角轻轻飘起，仿佛也带着几分笑意；清脆的铃声，随着风儿飘然而上，回荡在天地之间。\n",
      "\n",
      "小灰骂怀里拜倒代劳尝尝头上脚下依然如故冒汗一少特性哼声皮包骨头压得那奇兽雷之声辞世传下来遭殃凶意常箭带慌多久镂花三十三连下阵阵别离地道间手长柄用噬魂枪非走不可黑树逊于感知杜必书受黄符陌生人白瓦不管两人仗谈笑之间购买察老人家属实破屋修养反唇相讥名人会来暗地大清个笔意昇地生生破开去不去逍遥当三人甚少旷世便认街角生计年岁疯颠上天入地平常现而绝佳好过本人迅谢字施术者声道不收语意玉册奸细圣人黑烟向後退激愤举在门缝能连斩唉函三为天网恢恢山色狗头盖著数百年我炼之焰\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "prime = read_chars(FILE_PATH)[-500:-1]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Model(training=False)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    ckpt = tf.train.get_checkpoint_state(SAVE_DIR)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        text = model.sample(sess, tuple(vocabulary), dictionary, reverse_dictionary, n, prime)\n",
    "        print(prime)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
